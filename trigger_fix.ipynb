{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import functions_matching as fm\n",
    "import snakemake_scripts.sub_preprocess_S1 as s1\n",
    "import snakemake_scripts.sub_preprocess_S2 as s2\n",
    "from functions_misc import interp_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_selector(ref_path, file_info):\n",
    "    \"\"\"functions that selects the preprocessing function for the first step, either dlc or not\"\"\"\n",
    "    # check if the input has a dlc path or not\n",
    "    if (len(file_info['dlc_path']) > 0 and file_info['dlc_path'] != 'N/A') or \\\n",
    "            os.path.isfile(file_info['avi_path'].replace('.avi', '_dlc.h5')):\n",
    "        # assemble the path here, in case the file wasn't in the database\n",
    "        dlc_path = file_info['avi_path'].replace('.avi', '_dlc.h5')\n",
    "        # select function depending on the rig\n",
    "        if files['rig'] in ['VWheel', 'VWheelWF'] :\n",
    "            # use the eye specific function\n",
    "            traces, corner_out, frame_b = s1.run_preprocess_eye(ref_path, dlc_path, file_info)\n",
    "        else:\n",
    "            # if there's a dlc file, use this preprocessing\n",
    "            traces, corner_out, frame_b = s1.run_dlc_preprocess(ref_path, dlc_path, file_info)\n",
    "    else:\n",
    "        # if not, use the legacy non-dlc preprocessing\n",
    "        output_path, traces = s1.run_preprocess(ref_path, file_info)\n",
    "        # set corners to empty\n",
    "        corner_out = []\n",
    "        # set frame bounds to empty\n",
    "        frame_b = []\n",
    "    return traces, corner_out, frame_b\n",
    "\n",
    "\n",
    "def check_frame_code(frame_code, error_limit=5):\n",
    "    last_change = 0\n",
    "    count = 0\n",
    "    # error_start = 0\n",
    "    start_frame = 0\n",
    "    error_end = 0\n",
    "    end_frame = 0\n",
    "    error_segment = []\n",
    "\n",
    "    for idx, (frame_a, frame_b) in enumerate(zip(frame_code[:-1], frame_code[1:])):\n",
    "        idx += 1\n",
    "        count += 1\n",
    "\n",
    "        # If we are repeating, but within acceptable limits, continue\n",
    "        if (frame_b == frame_a) and (count <= error_limit):\n",
    "            # Do nothing\n",
    "            pass\n",
    "\n",
    "        # If we find a change in frame number within the acceptable repeat length, reset the count and record the last change\n",
    "        elif (frame_b != frame_a) and (count <= error_limit):\n",
    "            last_change = idx\n",
    "            count = 0\n",
    "\n",
    "        # If the frame is repeated for more than n frames, start recording the error region\n",
    "        elif (frame_b == frame_a) and (count > error_limit):\n",
    "            # Do nothing\n",
    "            pass\n",
    "\n",
    "        elif (frame_b != frame_a)  and (count > error_limit):\n",
    "            error_end = idx\n",
    "            start_frame = frame_a\n",
    "            end_frame = frame_b\n",
    "            \n",
    "            error_segment.append([last_change, start_frame, error_end, end_frame])\n",
    "            \n",
    "            count = 0\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    return np.array(error_segment)\n",
    "   \n",
    "\n",
    "def generate_trigger_sequence(start_num, max_val=3):\n",
    "    seq_list = []\n",
    "    for i in np.arange(max_val + 1):\n",
    "        if i == 0:\n",
    "            seq_list.append(start_num)\n",
    "        else:\n",
    "            if seq_list[i-1] < max_val:\n",
    "                seq_list.append(seq_list[i-1] + 1)\n",
    "            else:\n",
    "                seq_list.append(0)\n",
    "    return seq_list\n",
    "\n",
    "\n",
    "def fix_lost_sync_triggers(error_segments, trigger_code):\n",
    "    for err_seg in error_segments:\n",
    "        start_idx  = err_seg[0]\n",
    "        start_frame = err_seg[1]\n",
    "        end_idx = err_seg[2]\n",
    "        end_frame = err_seg[3]\n",
    "        length = end_idx - start_idx\n",
    "\n",
    "        r = 4    # Repeat factor (empirically determined)\n",
    "        seq = generate_trigger_sequence(start_frame)\n",
    "        repeat_seq = np.repeat(seq, r)\n",
    "\n",
    "        # Generate a vector of \"triggers\" that matches the theoretical sequence\n",
    "        replacement_seq = np.tile(repeat_seq, np.ceil(length/len(seq)/r).astype(int))[:length]\n",
    "\n",
    "        replacement_seq_end = replacement_seq[-1]\n",
    "        if replacement_seq_end in [0, 1, 2]:\n",
    "            # Consider this good\n",
    "            if (replacement_seq_end == end_frame) or (replacement_seq_end == end_frame - 1):\n",
    "                trigger_code[start_idx:end_idx] = replacement_seq\n",
    "            else:\n",
    "                # Hacky hacky\n",
    "                replacement_seq[-1:] = end_frame - 1\n",
    "                trigger_code[start_idx:end_idx] = replacement_seq\n",
    "        if replacement_seq_end == 3:\n",
    "            if (replacement_seq_end == end_frame) or (end_frame == 0):\n",
    "                trigger_code[start_idx:end_idx] = replacement_seq\n",
    "            else:\n",
    "                replacement_seq[-1:] = 0\n",
    "                trigger_code[start_idx:end_idx] = replacement_seq\n",
    "\n",
    "    return trigger_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_path = r\"C:\\Users\\matt\\Desktop\\prey_capture_test\\08_02_2023_10_47_38_syncVWheelWF_MM_230705_b_fixed1_gabor.csv\"\n",
    "track_path = r\"C:\\Users\\matt\\Desktop\\prey_capture_test\\08_02_2023_10_47_38_VWheelWF_MM_230705_b_fixed1_gabor.txt\"\n",
    "screen_path = r\"C:\\Users\\matt\\Desktop\\prey_capture_test\\08_02_2023_10_47_38_VWheelWF_MM_230705_b_fixed1_gabor.h5\"\n",
    "dlc_path = r\"C:\\Users\\matt\\Desktop\\prey_capture_test\\08_02_2023_10_47_38_VWheelWF_MM_230705_b_fixed1_gabor_dlc.h5\"\n",
    "avi_path = r\"C:\\Users\\matt\\Desktop\\prey_capture_test\\08_02_2023_10_47_38_VWheelWF_MM_230705_b_fixed1_gabor.avi\"\n",
    "calcium_path = r\"C:\\Users\\matt\\Desktop\\prey_capture_test\\08_02_2023_10_47_38_VWheelWF_MM_230705_b_fixed1_gabor_calcium.hdf5\"\n",
    "\n",
    "files = {'sync_path':sync_path,\n",
    "        'track_path': track_path,\n",
    "        'screen_path':screen_path,\n",
    "        'dlc_path':dlc_path,\n",
    "        'avi_path': avi_path,\n",
    "        'rig': 'VWheelWF',\n",
    "        'imaging': 'wirefree',\n",
    "        'date': '2023-08-02T10:47:38Z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data for the trial structure and parameters\n",
    "trials = pd.read_hdf(files['screen_path'], key='trial_set')\n",
    "params = pd.read_hdf(files['screen_path'], key='params')\n",
    "\n",
    "# run the first stage of preprocessing\n",
    "filtered_traces, corners, frame_bounds = preprocess_selector(files['avi_path'], files)\n",
    "\n",
    "# compute the eye metrics\n",
    "filtered_traces = fm.match_eye(filtered_traces)\n",
    "\n",
    "# get the wheel info\n",
    "filtered_traces = fm.match_wheel(files, filtered_traces)\n",
    "\n",
    "# get the motive tracking data\n",
    "motive_traces, reference_coordinates, obstacle_coordinates = \\\n",
    "    s1.extract_motive(files['track_path'], files['rig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_duration_stats(df, trial_key, time_key):\n",
    "    grouped_trials = df[df[trial_key] > 0].groupby(trial_key)\n",
    "    trial_durations = grouped_trials.apply(lambda x: x[time_key].to_list()[-1] - x[time_key].to_list()[0])\n",
    "    print(trial_durations.min(), trial_durations.max(), trial_durations.mean())\n",
    "    return np.array((trial_durations.min(), trial_durations.max(), trial_durations.mean()))\n",
    "\n",
    "duration_stats = get_trial_duration_stats(motive_traces, 'trial_num', 'time_m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explode match_motive_2 to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align them temporally based on the sync file\n",
    "# kinematics_data = fm.match_motive_2(motive_traces, files['sync_path'], filtered_traces)\n",
    "\n",
    "# def match_motive_2(motive_traces, sync_path, kinematics_data):\n",
    "\"\"\"Match the motive and video traces based on the sync file, updated to second gen rig\"\"\"\n",
    "kinematics_data = filtered_traces\n",
    "\n",
    "# find the first motive frame\n",
    "first_motive = np.argwhere(motive_traces.loc[:, 'trial_num'].to_numpy() == 0)[0][0]\n",
    "# exclude the last frame if it managed to include a single frame of 0\n",
    "last_motive = -1 if motive_traces.loc[motive_traces.shape[0] - 1, 'trial_num'] == 0 else motive_traces.shape[0]\n",
    "# trim the motive frames to the start and end of the experiment\n",
    "trimmed_traces = motive_traces.iloc[first_motive:last_motive, :].reset_index(drop=True)\n",
    "# TODO: remove this for regular trials, only here for 21.2.2022 ones\n",
    "if np.max(trimmed_traces.loc[:, 'color_factor']) > 81:\n",
    "    trimmed_traces.loc[:, 'color_factor'] = trimmed_traces.loc[:, 'color_factor'] / 255\n",
    "# normalize the number to 0 1 2 3 range\n",
    "trimmed_traces.loc[:, 'color_factor'] = np.array([int('0b' + format(int(el) - 1, '#09b')[2] +\n",
    "                                                        format(int(el) - 1, '#09b')[4], 2)\n",
    "                                                    if el > 0 else 0 for el in trimmed_traces.loc[:, 'color_factor']])\n",
    "\n",
    "# load the sync data\n",
    "sync_data = pd.read_csv(sync_path, names=['Time', 'projector_frames', 'camera_frames',\n",
    "                                            'sync_trigger', 'mini_frames', 'wheel_frames', 'projector_frames_2'],\n",
    "                        index_col=False)\n",
    "# get the camera frames (as the indexes from sync_frames are referenced for the uncut sync_data, see match_dlc)\n",
    "frame_times_cam_sync = sync_data.loc[kinematics_data['sync_frames'].to_numpy(), 'Time'].to_numpy()\n",
    "\n",
    "# get the start and end triggers\n",
    "sync_start = np.argwhere(sync_data.loc[:, 'sync_trigger'].to_numpy() == 1)[0][0] - 1\n",
    "sync_end = np.argwhere(sync_data.loc[:, 'sync_trigger'].to_numpy() == 2)[0][0]\n",
    "\n",
    "# trim the sync data to the experiment\n",
    "sync_data = sync_data.iloc[sync_start:sync_end, :].reset_index(drop=True)\n",
    "\n",
    "# get the motive frame times\n",
    "# TODO: probs remove this later, since all trials should be on the new rig with the 2bit frame encoding\n",
    "if np.any(np.isnan(sync_data['projector_frames_2'])):\n",
    "    # get the frame indexes\n",
    "    idx_code = np.argwhere(np.abs(np.diff(np.round(sync_data.loc[:, 'projector_frames'] / 4))) > 0).squeeze() + 1\n",
    "    # get the frame times\n",
    "    frame_times_motive_sync = sync_data.loc[idx_code, 'Time'].to_numpy()\n",
    "    # if the number of frames doesn't match, trim from the end\n",
    "    if trimmed_traces.shape[0] > frame_times_motive_sync.shape[0]:\n",
    "        trimmed_traces = trimmed_traces.iloc[-frame_times_motive_sync.shape[0]:, :]\n",
    "    elif trimmed_traces.shape[0] < frame_times_motive_sync.shape[0]:\n",
    "        frame_times_motive_sync = frame_times_motive_sync[-trimmed_traces.shape[0]:]\n",
    "\n",
    "else:\n",
    "    # This is all from sync file\n",
    "    # binarize both frame streams\n",
    "    frames_0 = np.round(sync_data.loc[:, 'projector_frames'] / 4).astype(int) * 2\n",
    "    frames_1 = np.round(sync_data.loc[:, 'projector_frames_2'] / 4).astype(int)\n",
    "    # assemble the actual sequence\n",
    "    frame_code = (frames_0 | frames_1).to_numpy()\n",
    "\n",
    "    # NEED TO FIND WHERE CONSECUTIVE CODES EXCEED THRESHOLD AND FIX\n",
    "    # Found that in general, the sync frame code dwells for 3 or 4 frames per code. We can generate a sequnce bewteen the start and end codes that should somewhat match the real triggers (sketchy as fuck but oh well)\n",
    "    error_segments_sync = check_frame_code(frame_code, error_limit=7)\n",
    "    frame_code = fix_lost_sync_triggers(error_segments_sync, frame_code)\n",
    "    error_segments_sync_2 = check_frame_code(frame_code, error_limit=7)\n",
    "\n",
    "    # TODO: turn this into a function\n",
    "    fixed_code = frame_code.copy()\n",
    "\n",
    "    # for all the frames\n",
    "    for idx, frame in enumerate(frame_code[1:-1]):\n",
    "        idx += 1\n",
    "        # if it's the same number as before, skip\n",
    "        if frame == fixed_code[idx - 1]:\n",
    "            continue\n",
    "        # if the numbers before and after are equal\n",
    "        if fixed_code[idx - 1] == frame_code[idx + 1]:\n",
    "            # replace this position by the repeated number cause it's likely a mistake\n",
    "            fixed_code[idx] = frame_code[idx - 1]\n",
    "            continue\n",
    "        # if not, start filtering\n",
    "        # first check for 0-2, cause 3 is a special case\n",
    "        if fixed_code[idx - 1] in [0, 1, 2]:\n",
    "            if frame != fixed_code[idx - 1] + 1:\n",
    "                fixed_code[idx] = fixed_code[idx - 1] + 1\n",
    "                continue\n",
    "        else:\n",
    "            if frame != 0:\n",
    "                fixed_code[idx] = 0\n",
    "                continue\n",
    "\n",
    "    # get the motive-based frame code in sync\n",
    "    idx_code = np.argwhere(np.abs(np.diff(fixed_code)) > 0).squeeze() + 1\n",
    "    motive_code = fixed_code[idx_code]\n",
    "    # if the frame numbers don't match, find the first motive color number and match that\n",
    "    last_number = trimmed_traces.loc[trimmed_traces.shape[0] - 1, 'color_factor']\n",
    "    # trim the idx based on the last appearance of the last_number in motive_code\n",
    "    trim_idx = np.argwhere(motive_code == last_number)[-1][0] + 1\n",
    "    idx_code = idx_code[-(trimmed_traces.shape[0] + 1):trim_idx]\n",
    "    # if idx_code.shape[0] < trimmed_traces.shape[0]:\n",
    "    #\n",
    "    #     # get the difference in frames\n",
    "    #     delta_frames = trimmed_traces.shape[0] - idx_code.shape[0]\n",
    "    #     # get trimmed traces trimmed\n",
    "    #     idx_code = idx_code[delta_frames:]\n",
    "    # display_code = fixed_code[idx_code]\n",
    "    \n",
    "    # get the frame times\n",
    "    frame_times_motive_sync = sync_data.loc[idx_code, 'Time'].to_numpy()\n",
    "    \n",
    "    # trim the motive frames to be contained within the camera frames\n",
    "    if frame_times_motive_sync[0] < frame_times_cam_sync[0]:\n",
    "        start_idx = np.argwhere(frame_times_motive_sync > frame_times_cam_sync[0])[0][0]\n",
    "        frame_times_motive_sync = frame_times_motive_sync[start_idx:]\n",
    "        idx_code = idx_code[start_idx:]\n",
    "        trimmed_traces = trimmed_traces.iloc[start_idx:, :].reset_index(drop=True)\n",
    "    \n",
    "    if frame_times_motive_sync[-1] > frame_times_cam_sync[-1]:\n",
    "        end_idx = np.argwhere(frame_times_motive_sync < frame_times_cam_sync[-1])[-1][0] + 1\n",
    "        frame_times_motive_sync = frame_times_motive_sync[:end_idx]\n",
    "        idx_code = idx_code[:end_idx]\n",
    "        trimmed_traces = trimmed_traces.iloc[:end_idx, :].reset_index(drop=True)\n",
    "\n",
    "    if trimmed_traces.shape[0] > frame_times_motive_sync.shape[0]:\n",
    "        delta_frames = trimmed_traces.shape[0] - frame_times_motive_sync.shape[0]\n",
    "        trimmed_traces = trimmed_traces.iloc[delta_frames:, :].reset_index(drop=True)\n",
    "\n",
    "# interpolate the camera traces to match the unity frames\n",
    "matched_camera = kinematics_data.drop(['time_vector', 'mouse', 'datetime', 'sync_frames'],\n",
    "                                        axis=1).apply(interp_trace, raw=False, args=(frame_times_cam_sync,\n",
    "                                                                                    frame_times_motive_sync))\n",
    "\n",
    "# add the correct time vector from the interpolated traces\n",
    "matched_camera['time_vector'] = frame_times_motive_sync\n",
    "matched_camera['mouse'] = kinematics_data.loc[kinematics_data.index[0], 'mouse']\n",
    "matched_camera['datetime'] = kinematics_data.loc[kinematics_data.index[0], 'datetime']\n",
    "# correct the frame indexes to work with the untrimmed sync file\n",
    "idx_code += sync_start\n",
    "matched_camera['sync_frames'] = idx_code\n",
    "\n",
    "# concatenate both data frames\n",
    "full_dataframe = pd.concat([matched_camera, trimmed_traces.drop(['time_m', 'color_factor'], axis=1)], axis=1)\n",
    "\n",
    "# reset the time vector\n",
    "old_time = full_dataframe['time_vector']\n",
    "full_dataframe['time_vector'] = np.array([el - old_time[0] for el in old_time])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(211)\n",
    "# # ax.scatter(sync_data.loc[:, 'Time'], sync_data.loc[:, 'projector_frames'])\n",
    "# ax.scatter(sync_data.loc[:, 'Time'], sync_data.loc[:, 'camera_frames'])\n",
    "# ax.scatter(sync_data.loc[:, 'Time'], np.round(sync_data.loc[:, 'projector_frames']/4)*4)\n",
    "# ax.scatter(frame_times_motive_sync, np.ones_like(frame_times_motive_sync))\n",
    "#\n",
    "# fig2 = plt.figure()\n",
    "# ax = fig2.add_subplot(211)\n",
    "# # ax.plot(np.diff(motive_traces.loc[:, 'time_m']))\n",
    "# ax.plot(frame_times_motive_sync[1:], np.diff(frame_times_motive_sync))\n",
    "#\n",
    "# fig3 = plt.figure()\n",
    "# ax = fig3.add_subplot(211)\n",
    "# ax.plot(sync_data.loc[1:, 'Time'], np.diff(frame_code))\n",
    "# ax.plot(sync_data.loc[1:, 'Time'], np.diff(fixed_code))\n",
    "#\n",
    "# fig4 = plt.figure()\n",
    "# ax = fig4.add_subplot(211)\n",
    "# # ax.plot(sync_data.loc[:, 'Time'], sync_data.loc[:, 'projector_frames'])\n",
    "# ax.plot(sync_data.loc[:, 'Time'], sync_data.loc[:, 'sync_trigger'])\n",
    "# ax.scatter(frame_times_motive_sync, np.ones_like(frame_times_motive_sync))\n",
    "#\n",
    "#\n",
    "# fig5 = plt.figure()\n",
    "# ax = fig5.add_subplot(211)\n",
    "# ax.plot(trimmed_traces.loc[:, 'time_m'], trimmed_traces.loc[:, 'trial_num'])\n",
    "# ax.plot(trimmed_traces.loc[:, 'time_m'], trimmed_traces.loc[:, 'sync_trigger'])\n",
    "#\n",
    "# fig6 = plt.figure()\n",
    "# ax = fig6.add_subplot(111)\n",
    "# ax.plot(np.diff(motive_code), marker='o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematics_data = full_dataframe.copy()\n",
    "duration_stats_motive = get_trial_duration_stats(motive_traces, 'trial_num', 'time_m')\n",
    "duration_stats_kinem = get_trial_duration_stats(kinematics_data, 'trial_num', 'time_vector')\n",
    "np.allclose(duration_stats_motive, duration_stats_kinem, rtol=1e-1, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's not the kinematics matching that's throwing the error, it's `match_calcium_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ERROR ALSO HERE\n",
    "# THIS ONE COMES FROM THE MINISCOPE TRIGGERS FAILING (???)\n",
    "matched_calcium, roi_info = fm.match_calcium_2(calcium_path, files['sync_path'], kinematics_data, trials=trials)\n",
    "duration_stats_matched_ca = get_trial_duration_stats(matched_calcium, 'trial_num', 'time_vector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duration_stats_motive)\n",
    "print(duration_stats_kinem)\n",
    "print(duration_stats_matched_ca)\n",
    "np.allclose(duration_stats_kinem, duration_stats_matched_ca,  rtol=1e-1, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explode 'match_calcium_2' to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_frame_triggers(triggers_in, threshold=1.5):\n",
    "    \"\"\"Interpolate missing triggers in the sequence based on the median interval\"\"\"\n",
    "    # allocate the output\n",
    "    triggers_out = list(triggers_in)\n",
    "    # get the intervals\n",
    "    intervals = np.diff(triggers_in)\n",
    "    # get the median interval\n",
    "    median_interval = np.median(intervals)\n",
    "    # get the slope of the triggers (this should be roughly linear) as an integer\n",
    "    mean_interval = np.round(np.mean(intervals))\n",
    "    # get the indexes of the intervals that violate threshold times the median or more (since they are continuous)\n",
    "    long_interval_idx = np.argwhere(intervals > threshold * median_interval).flatten()\n",
    "    # cycle through the intervals\n",
    "    for idx in long_interval_idx:\n",
    "        # determine the number of frames to interpolate\n",
    "        frame_number = int(np.round(intervals[idx] / mean_interval) - 1)\n",
    "        # generate and add them to the list\n",
    "        for idx2 in np.arange(frame_number):\n",
    "            triggers_out.append(triggers_out[idx] + mean_interval * (idx2 + 1))\n",
    "    # sort the list and output\n",
    "    triggers_out = np.sort(np.array(triggers_out))\n",
    "    return triggers_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the calcium data (cells x time), transpose to get time x cells\n",
    "with h5py.File(calcium_path, mode='r') as f:\n",
    "    calcium_data = np.array(f['calcium_data']).T\n",
    "    # if there are no ROIs, skip\n",
    "    if (type(calcium_data) == np.ndarray) and (calcium_data == 'no_ROIs'):\n",
    "        print('NO ROIs')\n",
    "    roi_info = np.array(f['roi_info'])\n",
    "# check if there are nans in the columns, if so, also skip\n",
    "if kinematics_data.columns[0] == 'badFile':\n",
    "    print(f'File {os.path.basename(calcium_path)} not matched due to NaNs')\n",
    "\n",
    "# load the sync data\n",
    "sync_data = pd.read_csv(sync_path, header=None)\n",
    "if sync_data.shape[1] == 3:\n",
    "    sync_data.columns = ['Time', 'mini_frames', 'camera_frames']\n",
    "elif sync_data.shape[1] == 6:\n",
    "    # TODO: only for files from 21.02.2022\n",
    "    sync_data.columns = ['Time', 'projector_frames', 'camera_frames',\n",
    "                            'sync_trigger', 'mini_frames', 'wheel_frames']\n",
    "else:\n",
    "    sync_data.columns = ['Time', 'projector_frames', 'camera_frames',\n",
    "                            'sync_trigger', 'mini_frames', 'wheel_frames', 'projector_frames_2']\n",
    "\n",
    "# get the camera frame times\n",
    "frame_idx_camera_sync = kinematics_data['sync_frames'].to_numpy().astype(int)\n",
    "frame_times_camera_sync = sync_data.loc[frame_idx_camera_sync, 'Time'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# Sometimes there are weird segments where the mini frame triggers aren't recorded in the middle of a session. \n",
    "# These are large gaps that are obvious\n",
    "# get the miniscope frame indexes from the sync file\n",
    "mini_frame_triggers = np.round(sync_data.loc[:, 'mini_frames']).astype(int)\n",
    "plt.plot(mini_frame_triggers)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate missing triggers (based on experience)\n",
    "frame_idx_mini_sync = np.argwhere(np.diff(mini_frame_triggers) > 0).squeeze() + 1\n",
    "# first fix big gaps\n",
    "frame_idx_mini_sync = np.round(interpolate_frame_triggers(frame_idx_mini_sync, threshold=100))\n",
    "# first for smaller gaps  \n",
    "frame_idx_mini_sync = np.round(interpolate_frame_triggers(frame_idx_mini_sync))\n",
    "\n",
    "\n",
    "# # find where there are large gaps in the mini recording\n",
    "# nonzero_mini_triggers = np.argwhere(mini_frame_triggers != 0).squeeze()\n",
    "# end_frame = nonzero_mini_triggers[-1]\n",
    "# zero_frames = np.argwhere(mini_frame_triggers == 0).squeeze()\n",
    "# zero_frames = zero_frames[zero_frames < end_frame]\n",
    "# breaks = consecutive(zero_frames)\n",
    "# break_lens = np.array([len(gap) for gap in breaks])\n",
    "# threshold = np.percentile(break_lens, 99.9)\n",
    "# gaps_to_interp = np.argwhere(break_lens > threshold).squeeze()\n",
    "# # for gap_idx in gaps_to_interp:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# correct for the calcium starting before and/or ending after the behavior\n",
    "if frame_idx_mini_sync[0] < frame_idx_camera_sync[0]:\n",
    "    start_idx = np.argwhere(frame_idx_mini_sync > frame_idx_camera_sync[0])[0][0]\n",
    "    frame_idx_mini_sync = frame_idx_mini_sync[start_idx:]\n",
    "    calcium_data = calcium_data[start_idx:, :]\n",
    "if frame_idx_mini_sync[-1] > frame_idx_camera_sync[-1]:\n",
    "    end_idx = np.argwhere(frame_idx_mini_sync < frame_idx_camera_sync[-1])[-1][0] + 1\n",
    "    frame_idx_mini_sync = frame_idx_mini_sync[:end_idx]\n",
    "    calcium_data = calcium_data[:end_idx, :]\n",
    "# get the delta frames with the calcium\n",
    "delta_frames = frame_idx_mini_sync.shape[0] - calcium_data.shape[0]\n",
    "# remove extra detections coming from terminating the calcium mid frame (I think)\n",
    "if delta_frames > 0:\n",
    "    print(f'There were {delta_frames} triggers more than frames on file {os.path.basename(calcium_path)}')\n",
    "    frame_idx_mini_sync = frame_idx_mini_sync[:-delta_frames]\n",
    "elif delta_frames < 0:\n",
    "    print(f'There were {-delta_frames} more frames than triggers on file {os.path.basename(calcium_path)}')\n",
    "    calcium_data = calcium_data[:delta_frames, :]\n",
    "# trim calcium according to the frames left within the behavior\n",
    "calcium_data = calcium_data[frame_idx_mini_sync > frame_idx_camera_sync[0], :]\n",
    "# and then remove frames before the behavior starts\n",
    "frame_idx_mini_sync = frame_idx_mini_sync[frame_idx_mini_sync > frame_idx_camera_sync[0]]\n",
    "\n",
    "# get the actual mini times\n",
    "frame_times_mini_sync = sync_data.loc[frame_idx_mini_sync, 'Time'].to_numpy()\n",
    "\n",
    "# interpolate the bonsai traces to match the mini frames\n",
    "matched_bonsai = kinematics_data.drop(['time_vector', 'sync_frames', 'mouse', 'datetime'],\n",
    "                                        axis=1).apply(interp_trace, raw=False, args=(frame_times_camera_sync,\n",
    "                                                                                    frame_times_mini_sync))\n",
    "if trials is not None:\n",
    "\n",
    "    # repair the trial_num column\n",
    "    matched_bonsai.loc[:, 'trial_num'] = np.round(matched_bonsai.loc[:, 'trial_num'])\n",
    "\n",
    "    # now that the trials are reassigned, add the trial data\n",
    "    matched_bonsai = assign_trial_parameters(matched_bonsai, trials)\n",
    "\n",
    "else:\n",
    "    # round the quadrant vector as it should be discrete\n",
    "    quadrant_columns = [el for el in matched_bonsai.columns if ('_quadrant' in el)]\n",
    "    for el in quadrant_columns:\n",
    "        matched_bonsai[el] = np.round(matched_bonsai[el])\n",
    "    # same for the hunt trace\n",
    "    if 'hunt_trace' in matched_bonsai.columns:\n",
    "        matched_bonsai.loc[:, 'hunt_trace'] = np.round(matched_bonsai.loc[:, 'hunt_trace'])\n",
    "\n",
    "# add the correct time vector from the interpolated traces, plus mouse and datetime\n",
    "matched_bonsai['time_vector'] = frame_times_mini_sync\n",
    "matched_bonsai['mouse'] = kinematics_data.loc[0, 'mouse']\n",
    "matched_bonsai['datetime'] = kinematics_data.loc[0, 'datetime']\n",
    "\n",
    "# print a single dataframe with the calcium matched positions and timestamps\n",
    "cell_column_names = ['_'.join(('cell', f'{el:04d}')) for el in range(calcium_data.shape[1])]\n",
    "calcium_dataframe = pd.DataFrame(calcium_data, columns=cell_column_names)\n",
    "# concatenate both data frames\n",
    "full_dataframe = pd.concat([matched_bonsai, calcium_dataframe], axis=1)\n",
    "\n",
    "# reset the time vector\n",
    "old_time = full_dataframe['time_vector']\n",
    "full_dataframe.loc[:, 'time_vector'] = np.array([el - old_time[0] for el in old_time])\n",
    "\n",
    "# turn the roi info into a dataframe\n",
    "roi_info = pd.DataFrame(roi_info, columns=['centroid_x', 'centroid_y',\n",
    "                                            'bbox_left', 'bbox_top', 'bbox_width', 'bbox_height', 'area'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prey_capture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
