{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677b6a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.3...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut as dlc\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# From paths.py\n",
    "import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f701c365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3345f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all videos in the data directory with VTuning in the name\n",
    "all_videos = glob.glob(paths.vrexperiment_path + os.sep + \"*VWheel*.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb3a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.DownSampleVideo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb58578",
   "metadata": {},
   "source": [
    "# If Project already created, run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b1da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config path\n",
    "config_path = r\"D:\\DLC_projects\\vwheel_pupil_DLC_22\\VWheel-Matt-2022-04-11\\config.yaml\"\n",
    "\n",
    "# Read config file\n",
    "cfg = dlc.auxiliaryfunctions.read_config(config_path)\n",
    "\n",
    "# Get project directory\n",
    "project_directory = cfg['project_path']\n",
    "\n",
    "# Get list of local videos as found in the config\n",
    "project_video_list = [vid for vid in cfg[\"video_sets\"]]\n",
    "\n",
    "test_video_dir = os.path.join(project_directory, \"test-videos\")\n",
    "test_vids = glob.glob(test_video_dir + os.sep + \"*VWheel*.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc685072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't created a new project, run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_new_project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 5 videos to train on\n",
    "remote_video_list = []\n",
    "for i in range(5):\n",
    "    remote_video_list.append(random.choice(all_videos))\n",
    "\n",
    "dlc.create_new_project(\"VWheel\", \"Matt\", remote_video_list, working_directory=r\"D:\\DLC_projects\\vwheel_pupil\", copy_videos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config and path info\n",
    "config_path = paths.config_path_VWheel\n",
    "cfg = dlc.auxiliaryfunctions.read_config(config_path)\n",
    "project_directory = cfg['project_path']\n",
    "project_video_list = [vid for vid in cfg[\"video_sets\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447bb7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick videos to test the network that are not part of the training set and copy to the project directory\n",
    "test_video_dir = os.path.join(project_directory, \"test-videos\")\n",
    "if not os.path.isdir(test_video_dir):\n",
    "    os.mkdir(test_video_dir)\n",
    "\n",
    "    # Randomly pick five videos outside of the training set to thest the network on\n",
    "    test_vids = []\n",
    "    while(len(test_vids) < 5):\n",
    "        vid = random.choice(all_videos)\n",
    "        if vid not in project_video_list:\n",
    "            dest = shutil.copy2(vid, test_video_dir)\n",
    "            test_vids.append(dest)\n",
    "\n",
    "else:\n",
    "    test_vids = glob.glob(test_video_dir + os.sep + \"*VWheel*.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555e39a",
   "metadata": {},
   "source": [
    "# Add extra videos (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If adding new videos, do that here by randomly selecting some not in the original data set or the test set\n",
    "# For this particular case, we want videos that are older than March 4th 2022\n",
    "from datetime import datetime\n",
    "from os.path import sep\n",
    "valid_extras = [vid for vid in all_videos if datetime.strptime(vid.split(sep)[-1].split('_VWheel')[0], \"%m_%d_%Y_%H_%M_%S\") > datetime(2022, 3, 5)]\n",
    "\n",
    "extra_vids = []\n",
    "while(len(extra_vids) < 5):\n",
    "    vid = random.choice(valid_extras)\n",
    "    if vid not in project_video_list or test_vids:\n",
    "        extra_vids.append(vid)\n",
    "        \n",
    "dlc.add_new_videos(config_path, extra_vids, copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf2717",
   "metadata": {},
   "source": [
    "# Extract and label frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.extract_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract frames from the videos\n",
    "# will go through all of the videos on the list, so if many videos, it might take a while\n",
    "dlc.extract_frames(config_path, mode='automatic', algo='kmeans', crop=False, userfeedback=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d95110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "# label frames\n",
    "# generates folders in the labeled-data folder with the video name\n",
    "dlc.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a836df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Matt.\n",
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\labeled-data\\03_08_2022_11_38_40_VWheel_MM_220119_a_fixed0_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\labeled-data\\03_08_2022_10_59_36_VWheel_MM_220117_a_fixed0_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\labeled-data\\03_09_2022_11_52_23_VWheel_MM_220118_a_fixed2_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\labeled-data\\03_07_2022_15_52_19_VWheel_MM_220119_a_fixed0_dorictest_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\labeled-data\\03_09_2022_12_30_24_VWheel_MM_220119_a_fixed2_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\labeled-data\\03_09_2022_13_23_51_VWheel_MM_220120_a_fixed2_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\labeled-data\\03_08_2022_12_59_32_VWheel_MM_220120_a_fixed0_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\labeled-data\\03_09_2022_11_14_14_VWheel_MM_220117_a_fixed2_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check the labels\n",
    "# generates folders in the labeled-data folder with the video name but the actual labels printed on the pics\n",
    "dlc.check_labels(config_path, draw_skeleton=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c698a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_training_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d1d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "# create the training set\n",
    "# also creates the Pose.yaml in the dlc-models/train dataset, which contains the setting for training, i.e. take a look\n",
    "dlc.create_training_dataset(config_path, augmenter_type='imgaug');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad5a2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13]],\n",
      " 'all_joints_names': ['pupilCenter',\n",
      "                      'pupilRight',\n",
      "                      'pupilLeft',\n",
      "                      'pupilTop',\n",
      "                      'pupilBottom',\n",
      "                      'eyeCornerNasal',\n",
      "                      'LED',\n",
      "                      'eyelidTop',\n",
      "                      'eyelidBottom',\n",
      "                      'pupilTopLeft',\n",
      "                      'pupilTopRight',\n",
      "                      'pupilBottomRight',\n",
      "                      'pupilBottomLeft',\n",
      "                      'eyeCornerTemporal'],\n",
      " 'alpha_r': 0.02,\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_VWheelApr11\\\\VWheel_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_VWheelApr11\\\\Documentation_data-VWheel_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 14,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\DLC_projects\\\\vwheel_pupil\\\\VWheel-Matt-2022-04-11',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DLC_projects\\\\vwheel_pupil\\\\VWheel-Matt-2022-04-11\\\\dlc-models\\\\iteration-4\\\\VWheelApr11-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Display_iters overwritten as 50000\n",
      "Save_iters overwritten as 50000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\DLC_projects\\\\vwheel_pupil\\\\VWheel-Matt-2022-04-11\\\\dlc-models\\\\iteration-4\\\\VWheelApr11-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13]], 'all_joints_names': ['pupilCenter', 'pupilRight', 'pupilLeft', 'pupilTop', 'pupilBottom', 'eyeCornerNasal', 'LED', 'eyelidTop', 'eyelidBottom', 'pupilTopLeft', 'pupilTopRight', 'pupilBottomRight', 'pupilBottomLeft', 'eyeCornerTemporal'], 'alpha_r': 0.02, 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_VWheelApr11\\\\VWheel_Matt95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_VWheelApr11\\\\Documentation_data-VWheel_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 14, 'pos_dist_thresh': 17, 'project_path': 'D:\\\\DLC_projects\\\\vwheel_pupil\\\\VWheel-Matt-2022-04-11', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 50000 loss: 0.0029 lr: 0.02\n",
      "iteration: 100000 loss: 0.0011 lr: 0.02\n",
      "iteration: 150000 loss: 0.0009 lr: 0.02\n",
      "iteration: 200000 loss: 0.0008 lr: 0.02\n",
      "iteration: 250000 loss: 0.0007 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9656768b07b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    273\u001b[0m         [_, loss_val, summary] = sess.run(\n\u001b[0;32m    274\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         )\n\u001b[0;32m    277\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "dlc.train_network(config_path, gputouse=0, allow_growth=True,\n",
    "                  max_snapshots_to_keep=10, displayiters=5e3, saveiters=50e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e98935f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13]],\n",
      " 'all_joints_names': ['pupilCenter',\n",
      "                      'pupilRight',\n",
      "                      'pupilLeft',\n",
      "                      'pupilTop',\n",
      "                      'pupilBottom',\n",
      "                      'eyeCornerNasal',\n",
      "                      'LED',\n",
      "                      'eyelidTop',\n",
      "                      'eyelidBottom',\n",
      "                      'pupilTopLeft',\n",
      "                      'pupilTopRight',\n",
      "                      'pupilBottomRight',\n",
      "                      'pupilBottomLeft',\n",
      "                      'eyeCornerTemporal'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_VWheelApr11\\\\VWheel_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 14,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DLC_projects\\\\vwheel_pupil\\\\VWheel-Matt-2022-04-11\\\\dlc-models\\\\iteration-4\\\\VWheelApr11-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11/evaluation-results/  already exists!\n",
      "Running  DLC_resnet_50_VWheelApr11shuffle1_250000  with # of trainingiterations: 250000\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [00:10,  8.37it/s]\n",
      "  0%|                                                                                           | 0/92 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-250000\n",
      "Results for 250000  training iterations: 95 1 train error: 2.35 pixels. Test error: 3.46  pixels.\n",
      "With pcutoff of 0.6  train error: 1.56 pixels. Test error: 3.33 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:36<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "dlc.evaluate_network(config_path, Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b15f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.analyze_videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf67e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13]],\n",
      " 'all_joints_names': ['pupilCenter',\n",
      "                      'pupilRight',\n",
      "                      'pupilLeft',\n",
      "                      'pupilTop',\n",
      "                      'pupilBottom',\n",
      "                      'eyeCornerNasal',\n",
      "                      'LED',\n",
      "                      'eyelidTop',\n",
      "                      'eyelidBottom',\n",
      "                      'pupilTopLeft',\n",
      "                      'pupilTopRight',\n",
      "                      'pupilBottomRight',\n",
      "                      'pupilBottomLeft',\n",
      "                      'eyeCornerTemporal'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_VWheelApr11\\\\VWheel_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 14,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DLC_projects\\\\vwheel_pupil\\\\VWheel-Matt-2022-04-11\\\\dlc-models\\\\iteration-4\\\\VWheelApr11-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-250000 for model D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\dlc-models\\iteration-4\\VWheelApr11-trainset95shuffle1\n",
      "Starting analysis in dynamic cropping mode with parameters: (True, 0.1, 100)\n",
      "Switching batchsize to 1, num_outputs (per animal) to 1 and TFGPUinference to False (all these features are not supported in this mode).\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/19906 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\test-videos\\03_09_2022_11_14_14_VWheel_MM_220117_a_fixed2.avi\n",
      "D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\test-videos  already exists!\n",
      "Loading  D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\test-videos\\03_09_2022_11_14_14_VWheel_MM_220117_a_fixed2.avi\n",
      "Duration of video [s]:  796.24 , recorded with  25.0 fps!\n",
      "Overall # of frames:  19906  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20099it [08:19, 40.21it/s]                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DLC_projects\\vwheel_pupil\\VWheel-Matt-2022-04-11\\test-videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    }
   ],
   "source": [
    "dlc.analyze_videos(config_path, test_vids, dynamic=(True, .1, 50), gputouse=0)\n",
    "dlc.create_labeled_video(config_path, test_vids, fastmode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8cd496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  jump  found  76  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "yes/noy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 44.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video 03_09_2022_11_14_14_VWheel_MM_220117_a_fixed2  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  796.24 , recorded @  25.0 fps!\n",
      "Overall # of frames:  19906 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 796.24  seconds.\n",
      "Extracting and downsampling... 76  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [00:01, 57.72it/s]\n",
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [2427, 2666, 134, 2691, 15861, 16128, 3903, 2418, 2323, 3843]\n",
      "Creating the symbolic link of the video\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\03_09_2022_11_14_14_VWheel_MM_220117_a_fixed2.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "# extract outlier frames\n",
    "# dlc.extract_outlier_frames(config_path, project_video_list, outlieralgorithm='uncertain', p_bound=0.6)\n",
    "dlc.extract_outlier_frames(config_path, test_vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6a17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\gui\\refinement.py:733: FutureWarning: inplace is deprecated and will be removed in a future version.\n",
      "  [self.scorer.replace(self.scorer, self.humanscorer)], level=0, inplace=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336f6274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 3.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "# Merge the dataset, then move to check labels and retrain\n",
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.analyze_videos(config_path, test_vids)\n",
    "dlc.create_labeled_video(config_path, test_vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a170d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used if need to reconstruct labeling h5 files from csvs\n",
    "dlc.convertcsv2h5(config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
