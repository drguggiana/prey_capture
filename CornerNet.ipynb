{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN for corner finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "import PIL\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate images to training, validation and test sets\n",
    "\n",
    "# define the path to the pics\n",
    "pic_path = r'J:\\Drago Guggiana Nilo\\Prey_capture\\Corner_pics\\Video\\pics'\n",
    "# define the paths to the divided datasets\n",
    "train_path = r'J:\\Drago Guggiana Nilo\\Prey_capture\\Corner_pics\\Video\\train'\n",
    "val_path = r'J:\\Drago Guggiana Nilo\\Prey_capture\\Corner_pics\\Video\\val'\n",
    "test_path = r'J:\\Drago Guggiana Nilo\\Prey_capture\\Corner_pics\\Video\\test'\n",
    "\n",
    "\n",
    "if os.path.isdir(train_path) is False:\n",
    "    os.makedirs(train_path)\n",
    "    os.makedirs(val_path)\n",
    "    os.makedirs(test_path)\n",
    "    \n",
    "    for c in random.sample(os.listdir(pic_path), 35):\n",
    "        shutil.move(os.path.join(pic_path, c), train_path)\n",
    "    \n",
    "    for c in random.sample(os.listdir(pic_path), 10):\n",
    "        shutil.move(os.path.join(pic_path, c), val_path)\n",
    "    \n",
    "    for c in random.sample(os.listdir(pic_path), 5):\n",
    "        shutil.move(os.path.join(pic_path, c), test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"Corner\":\"LL\"}' '{\"Corner\":\"LR\"}' '{\"Corner\":\"TL\"}' '{\"Corner\":\"TR\"}']\n",
      "(35, 8)\n"
     ]
    }
   ],
   "source": [
    "# parse the annotations\n",
    "# define the path to the annotations\n",
    "annotation_path = r'J:\\Drago Guggiana Nilo\\Prey_capture\\Corner_pics\\Video\\via_project_28Aug2020_14h57m_csv.csv'\n",
    "\n",
    "# read them as a dataframe\n",
    "annotations = pd.read_csv(annotation_path)\n",
    "\n",
    "# split them based on the data splits\n",
    "# get a list of the train samples\n",
    "train_list = os.listdir(train_path)\n",
    "\n",
    "# allocate memory for the labels\n",
    "# train_label = [el['filename'] for el in annotations.iterrows()]# if el['filename'] in train_list]\n",
    "train_labels = []\n",
    "\n",
    "annotated_names = annotations['filename'].to_numpy()\n",
    "\n",
    "# get the unique labels\n",
    "unique_labels = np.unique(annotations['region_attributes'])\n",
    "# remove the empty\n",
    "unique_labels = np.array([el for el in unique_labels if el != '{}'])\n",
    "print(unique_labels)\n",
    "for el in train_list:\n",
    "    \n",
    "    # get the current labels\n",
    "    current_labels = annotations.loc[annotated_names==el,'region_attributes'].to_numpy()\n",
    "    \n",
    "    # if the file is not on the list, skip\n",
    "    if len(current_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # allocate memory for the current coordinates\n",
    "    current_coordinates = []\n",
    "                \n",
    "    # get the labels for this pic\n",
    "    for label in unique_labels:\n",
    "        \n",
    "        # if it's in the list for this file\n",
    "        if label in current_labels:\n",
    "            \n",
    "            # get the entry with the coordinates\n",
    "            current_entry = annotations.loc[(annotated_names==el),:]\n",
    "            current_entry = current_entry.loc[current_labels==label,'region_shape_attributes'].to_numpy()[0]\n",
    "            current_entry = json.loads(current_entry.replace(\"'\", \"/\"))\n",
    "            \n",
    "            # load the corresponding x and y values in the labels\n",
    "            current_coordinates.append([current_entry['cx'], current_entry['cy']])\n",
    "            \n",
    "        else: \n",
    "            current_coordinates.append([np.nan, np.nan])\n",
    "\n",
    "\n",
    "#     print(current_coordinates)\n",
    "    # append to the main list\n",
    "    train_labels.append(np.concatenate(current_coordinates))\n",
    "\n",
    "# turn the list into an array\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programdata\\miniconda3\\envs\\cellfinder\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image_dataset.py:142: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if labels != 'inferred':\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`labels` argument should be a list/tuple of integer labels, of the same size as the number of image files in the target directory. If you wish to infer the labels from the subdirectory names in the target directory, pass `labels=\"inferred\"`. If you wish to get a dataset that only contains images (no labels), pass `label_mode=None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-69903bd3ebda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m   batch_size=5)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# # for all the images in the training list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\miniconda3\\envs\\cellfinder\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m       raise ValueError(\n\u001b[1;32m--> 145\u001b[1;33m           \u001b[1;34m'`labels` argument should be a list/tuple of integer labels, of '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m           \u001b[1;34m'the same size as the number of image files in the target '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m           \u001b[1;34m'directory. If you wish to infer the labels from the subdirectory '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `labels` argument should be a list/tuple of integer labels, of the same size as the number of image files in the target directory. If you wish to infer the labels from the subdirectory names in the target directory, pass `labels=\"inferred\"`. If you wish to get a dataset that only contains images (no labels), pass `label_mode=None`."
     ]
    }
   ],
   "source": [
    "# preprocess the images\n",
    "\n",
    "# allocate memory to store them\n",
    "train_images = []\n",
    "\n",
    "\n",
    "# train_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#   train_path,\n",
    "#   labels=train_labels,\n",
    "#   image_size=(320, 256),\n",
    "#   batch_size=5)\n",
    "\n",
    "# # for all the images in the training list\n",
    "# for image in train_list:\n",
    "    \n",
    "    # load the image\n",
    "    current_image = PIL.Image.open(os.path.join(train_path,image))\n",
    "    # resize\n",
    "    current_image = tensorflow.image.resize(current_image, [320, 256])\n",
    "    # scale\n",
    "    current_image = tensorflow.image.per_image_standardization(current_image)\n",
    "    # save\n",
    "    train_images.append(current_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the validation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e9da7b0f145c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m model = Sequential([\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Activate GPU for this, otherwise the convnet will take forever to train with Theano.\n",
    "\n",
    "# TODO: Make one run with very deep network (~10 layers).\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# TODO: Maybe remove pooling bc it takes away the spatial information.\n",
    "\n",
    "model = Sequential([\n",
    "        Convolution2D(32, 6, 6, input_shape=X.shape[1:], dim_ordering='tf', activation='relu'), \n",
    "        MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(64, filter_size, filter_size, dim_ordering='tf', activation='relu'), \n",
    "        MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, dim_ordering='tf', activation='relu'), \n",
    "# #         MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, dim_ordering='tf', activation='relu'), \n",
    "# #         MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Flatten(), \n",
    "        Dropout(0.4), \n",
    "        Dense(256, activation='relu'), \n",
    "        Dropout(0.4), \n",
    "        Dense(y.shape[-1])\n",
    "    ])\n",
    "\n",
    "model.compile('adadelta', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(x=train_images, y=train_labels, validation_data=validation_data, batch_size=5, epochs=30, shuffle=True verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
