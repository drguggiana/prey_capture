{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook works with the Vprey project and it's current config.yaml file.\n",
    "\n",
    "**Note**: It will also create the project if not already specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut as dlc\n",
    "import paths\n",
    "import os\n",
    "# define the config_path\n",
    "config_path = paths.config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_data_directory = r\"J:\\Drago Guggiana Nilo\\Prey_capture\\VRExperiment\"\n",
    "\n",
    "video_list = [r\"06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi\",\n",
    "              r\"06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi\",\n",
    "              r\"06_23_2020_15_03_01_DG_200526_c_succ.avi\",\n",
    "              r\"06_30_2020_14_41_22_DG_200526_b_test_lowFR.avi\",\n",
    "              r\"06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi\",\n",
    "              r\"06_22_2020_12_24_42_DG_200526_b_succ.avi\",\n",
    "              r\"06_22_2020_11_25_50_DG_200526_a_test.avi\",\n",
    "              r\"03_12_2020_15_35_46_MM_200128_a_succ.avi\",\n",
    "              r\"03_05_2020_16_26_13_MM_200128_a_succ.avi\", \n",
    "              r\"11_10_2019_23_46_06_DG_190417_a_fail.avi\",\n",
    "              r\"08_07_2019_18_05_49_DG_190416_a_succ.avi\",\n",
    "              r\"08_03_2019_17_34_12_DG_190416_a_succ.avi\",\n",
    "              r\"07_08_2020_16_10_58_DG_200526_b_succ_blackCr.avi\",\n",
    "              r\"07_08_2020_12_04_55_DG_200526_a_succ_blackCr.avi\",\n",
    "              r\"07_08_2020_11_43_42_DG_200526_a_test_blackCr.avi\",\n",
    "              r\"07_08_2020_16_09_13_DG_200526_b_test_nonrewarded_blackCr.avi\",\n",
    "              r\"07_08_2020_16_06_56_DG_200526_b_test_nonrewarded_blackCr.avi\"\n",
    "             ]\n",
    "remote_video_list = [os.path.join(remote_data_directory, vid) for vid in video_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_new_project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\"\n",
      "Created \"D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\"\n",
      "Created \"D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\training-datasets\"\n",
      "Created \"D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\dlc-models\"\n",
      "Copying the videos\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_23_2020_15_03_01_DG_200526_c_succ.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_30_2020_14_41_22_DG_200526_b_test_lowFR.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_22_2020_12_24_42_DG_200526_b_succ.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_22_2020_11_25_50_DG_200526_a_test.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\03_12_2020_15_35_46_MM_200128_a_succ.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\03_05_2020_16_26_13_MM_200128_a_succ.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\11_10_2019_23_46_06_DG_190417_a_fail.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\08_07_2019_18_05_49_DG_190416_a_succ.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\08_03_2019_17_34_12_DG_190416_a_succ.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\07_08_2020_16_10_58_DG_200526_b_succ_blackCr.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\07_08_2020_12_04_55_DG_200526_a_succ_blackCr.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\07_08_2020_11_43_42_DG_200526_a_test_blackCr.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\07_08_2020_16_09_13_DG_200526_b_test_nonrewarded_blackCr.avi\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\07_08_2020_16_06_56_DG_200526_b_test_nonrewarded_blackCr.avi\n",
      "Generated \"D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\config.yaml\"\n",
      "\n",
      "A new project with name VPrey-Matt-2020-07-13 is created at D:\\dlc_vr_arena and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13\\\\config.yaml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the project if not already done\n",
    "\n",
    "dlc.create_new_project(\"VPrey\", \"Matt\", remote_video_list, working_directory=r\"D:\\dlc_vr_arena\", copy_videos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "# If adding new videos, do that here\n",
    "extras = []\n",
    "extra_vids = [os.path.join(remote_data_directory, vid) for vid in extras]\n",
    "dlc.add_new_videos(config_path, extra_vids, copy_videos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of local videos as foundin the config\n",
    "test_video_list = []\n",
    "\n",
    "cfg = dlc.auxiliaryfunctions.read_config(config_path)\n",
    "\n",
    "for video in cfg[\"video_sets\"]:\n",
    "    project_video_list.append(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `dlc.extract_frames` not found.\n"
     ]
    }
   ],
   "source": [
    "dlc.extract_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 173.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 45.2  seconds.\n",
      "Extracting and downsampling... 1356  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1356it [00:04, 282.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 180.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 30.5  seconds.\n",
      "Extracting and downsampling... 915  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "915it [00:03, 276.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 173.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 23.3  seconds.\n",
      "Extracting and downsampling... 699  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [00:02, 278.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 181.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 78.8  seconds.\n",
      "Extracting and downsampling... 2364  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2364it [00:08, 281.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 164.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 22.23  seconds.\n",
      "Extracting and downsampling... 667  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "667it [00:02, 279.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 155.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 83.13  seconds.\n",
      "Extracting and downsampling... 2494  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2494it [00:08, 285.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 181.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 168.6  seconds.\n",
      "Extracting and downsampling... 5058  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5058it [00:17, 288.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 182.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 18.73  seconds.\n",
      "Extracting and downsampling... 562  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "562it [00:01, 283.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 180.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 53.1  seconds.\n",
      "Extracting and downsampling... 1593  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1593it [00:05, 284.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 179.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 187.1  seconds.\n",
      "Extracting and downsampling... 5613  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5613it [00:19, 282.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 173.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 20.47  seconds.\n",
      "Extracting and downsampling... 614  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "614it [00:02, 280.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 181.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 17.03  seconds.\n",
      "Extracting and downsampling... 511  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "511it [00:01, 279.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:00, 181.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 17.4  seconds.\n",
      "Extracting and downsampling... 522  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "522it [00:01, 272.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 164.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 19.57  seconds.\n",
      "Extracting and downsampling... 587  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "587it [00:02, 277.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 178.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 36.77  seconds.\n",
      "Extracting and downsampling... 1103  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1103it [00:03, 286.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 192.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 30.03  seconds.\n",
      "Extracting and downsampling... 901  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [00:03, 290.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:00, 200.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 35.1  seconds.\n",
      "Extracting and downsampling... 1053  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1053it [00:03, 286.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "# extract frames from the videos\n",
    "# will go through all of the videos on the list, so if many videos, it might take a while\n",
    "dlc.extract_frames(config_path, mode='automatic', algo='kmeans', crop=\"GUI\", userfeedback=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "# label frames\n",
    "# generates folders in the labeled-data folder with the video name\n",
    "dlc.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Matt.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\06_23_2020_15_03_01_DG_200526_c_succ_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\06_30_2020_14_41_22_DG_200526_b_test_lowFR_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\06_22_2020_12_24_42_DG_200526_b_succ_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\06_22_2020_11_25_50_DG_200526_a_test_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\03_12_2020_15_35_46_MM_200128_a_succ_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\03_05_2020_16_26_13_MM_200128_a_succ_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\11_10_2019_23_46_06_DG_190417_a_fail_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\08_07_2019_18_05_49_DG_190416_a_succ_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\08_03_2019_17_34_12_DG_190416_a_succ_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\07_08_2020_16_10_58_DG_200526_b_succ_blackCr_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\07_08_2020_12_04_55_DG_200526_a_succ_blackCr_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\07_08_2020_11_43_42_DG_200526_a_test_blackCr_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\07_08_2020_16_09_13_DG_200526_b_test_nonrewarded_blackCr_labeled.\n",
      "They are stored in the following folder: D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\labeled-data\\07_08_2020_16_06_56_DG_200526_b_test_nonrewarded_blackCr_labeled.\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "# check the labels\n",
    "# generates folders in the labeled-data folder with the video name but the actual labels printed on the pics\n",
    "dlc.check_labels(config_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_training_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\training-datasets\\iteration-0\\UnaugmentedDataSet_VPreyJul13  already exists!\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\dlc-models\\iteration-0\\VPreyJul13-trainset95shuffle1  already exists!\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\dlc-models\\iteration-0\\VPreyJul13-trainset95shuffle1/train  already exists!\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\dlc-models\\iteration-0\\VPreyJul13-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "# create the training set\n",
    "# also creates the Pose.yaml in the dlc-models/train dataset, which contains the setting for training, i.e. take a look\n",
    "dlc.create_training_dataset(config_path, augmenter_type='default');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['head', 'body_center', 'tail_base', 'cricket'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_VPreyJul13\\\\VPrey_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_VPreyJul13\\\\Documentation_data-VPrey_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13\\\\dlc-models\\\\iteration-0\\\\VPreyJul13-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Display_iters overwritten as 50000\n",
      "Save_iters overwritten as 50000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13\\\\dlc-models\\\\iteration-0\\\\VPreyJul13-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['head', 'body_center', 'tail_base', 'cricket'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_VPreyJul13\\\\VPrey_Matt95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_VPreyJul13\\\\Documentation_data-VPrey_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'output_stride': 16, 'deconvolutionstride': 2}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 50000 loss: 0.0033 lr: 0.02\n",
      "iteration: 100000 loss: 0.0016 lr: 0.02\n",
      "iteration: 150000 loss: 0.0013 lr: 0.02\n",
      "iteration: 200000 loss: 0.0011 lr: 0.02\n",
      "iteration: 250000 loss: 0.0010 lr: 0.02\n",
      "iteration: 300000 loss: 0.0009 lr: 0.02\n",
      "iteration: 350000 loss: 0.0008 lr: 0.02\n",
      "iteration: 400000 loss: 0.0008 lr: 0.02\n",
      "iteration: 450000 loss: 0.0007 lr: 0.002\n",
      "iteration: 500000 loss: 0.0006 lr: 0.002\n",
      "iteration: 550000 loss: 0.0006 lr: 0.002\n",
      "iteration: 600000 loss: 0.0006 lr: 0.002\n",
      "iteration: 650000 loss: 0.0006 lr: 0.002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-9656768b07b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[1;32m--> 190\u001b[1;33m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "dlc.train_network(config_path, max_snapshots_to_keep=10, displayiters=50000, saveiters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['head', 'body_center', 'tail_base', 'cricket'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_VPreyJul13\\\\VPrey_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_VPreyJul13\\\\Documentation_data-VPrey_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13\\\\dlc-models\\\\iteration-0\\\\VPreyJul13-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13/evaluation-results/  already exists!\n",
      "D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\evaluation-results\\iteration-0\\VPreyJul13-trainset95shuffle1  already exists!\n",
      "Running  DLC_resnet50_VPreyJul13shuffle1_650000  with # of trainingiterations: 650000\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\dlc-models\\iteration-0\\VPreyJul13-trainset95shuffle1\\train\\snapshot-650000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "338it [00:30, 11.24it/s]\n",
      "  0%|                                                                                          | 0/338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-650000\n",
      "Results for 650000  training iterations: 95 1 train error: 1.51 pixels. Test error: 10.65  pixels.\n",
      "With pcutoff of 0.6  train error: 1.51 pixels. Test error: 2.46 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 338/338 [03:15<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "dlc.evaluate_network(config_path,Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['head', 'body_center', 'tail_base', 'cricket'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_VPreyJul13\\\\VPrey_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_VPreyJul13\\\\Documentation_data-VPrey_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-13\\\\dlc-models\\\\iteration-0\\\\VPreyJul13-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-650000 for model D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\dlc-models\\iteration-0\\VPreyJul13-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\dlc-models\\iteration-0\\VPreyJul13-trainset95shuffle1\\train\\snapshot-650000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1356 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi\n",
      "Duration of video [s]:  45.2 , recorded with  30.0 fps!\n",
      "Overall # of frames:  1356  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1365it [01:50, 11.39it/s]                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1365it [01:51, 12.24it/s]\n",
      "  0%|                                                                                          | 0/915 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos...\n",
      "Starting to analyze %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-13\\videos\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi\n",
      "Duration of video [s]:  30.5 , recorded with  30.0 fps!\n",
      "Overall # of frames:  915  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▉                                                                  | 160/915 [00:11<00:54, 13.75it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7b3ab7dcb6ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject_video_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\u001b[0m in \u001b[0;36manalyze_videos\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, gputouse, save_as_csv, destfolder, batchsize, crop, get_nframesfrommetadata, TFGPUinference, dynamic)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;31m#looping over videos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mVideos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mDLCscorer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAnalyzeVideo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDLCscorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDLCscorerlegacy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainFraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpdindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_as_csv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestfolder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTFGPUinference\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\u001b[0m in \u001b[0;36mAnalyzeVideo\u001b[1;34m(video, DLCscorer, DLCscorerlegacy, trainFraction, cfg, dlc_cfg, sess, inputs, outputs, pdindex, save_as_csv, destfolder, TFGPUinference, dynamic)\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mTFGPUinference\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                     \u001b[0mPredictedData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGetPoseF_GTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnframes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m                     \u001b[0mPredictedData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGetPoseF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnframes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\u001b[0m in \u001b[0;36mGetPoseF_GTF\u001b[1;34m(cfg, dlc_cfg, sess, inputs, outputs, cap, nframes, batchsize)\u001b[0m\n\u001b[0;32m    377\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_ind\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                     \u001b[1;31m#pose = predict.getposeNP(frames,dlc_cfg, sess, inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                     \u001b[0mpose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpose_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m                     \u001b[0mpose\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpose\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#change order to have x,y,confidence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mpose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#bring into batchsize times x,y,conf etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dlc.analyze_videos(config_path, project_video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                                | 7/1356 [00:00<00:20, 66.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi and data.\n",
      "1356\n",
      "Duration of video [s]:  45.2 , recorded with  30.0 fps!\n",
      "Overall # of frames:  1356 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                          | 84/1356 [00:00<00:12, 101.04it/s]C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py:114: FutureWarning: circle is deprecated in favor of disk.circle will be removed in version 0.19\n",
      "  rr, cc = circle(yc,xc,dotsize,shape=(ny,nx))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1356/1356 [00:12<00:00, 105.76it/s]\n",
      "  1%|▋                                                                                 | 7/915 [00:00<00:13, 66.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi and data.\n",
      "915\n",
      "Duration of video [s]:  30.5 , recorded with  30.0 fps!\n",
      "Overall # of frames:  915 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 915/915 [00:08<00:00, 107.81it/s]\n",
      "  1%|▊                                                                                 | 7/699 [00:00<00:10, 68.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\06_23_2020_15_03_01_DG_200526_c_succ.avi and data.\n",
      "699\n",
      "Duration of video [s]:  23.3 , recorded with  30.0 fps!\n",
      "Overall # of frames:  699 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 699/699 [00:06<00:00, 107.61it/s]\n",
      "  0%|▏                                                                                | 7/2364 [00:00<00:35, 66.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi and data.\n",
      "2364\n",
      "Duration of video [s]:  78.8 , recorded with  30.0 fps!\n",
      "Overall # of frames:  2364 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2364/2364 [00:21<00:00, 109.07it/s]\n",
      "  1%|▊                                                                                 | 7/667 [00:00<00:09, 69.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi and data.\n",
      "667\n",
      "Duration of video [s]:  22.23 , recorded with  30.0 fps!\n",
      "Overall # of frames:  667 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 667/667 [00:06<00:00, 108.09it/s]\n",
      "  1%|█▏                                                                                | 8/562 [00:00<00:07, 74.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\03_12_2020_15_35_46_MM_200128_a_succ.avi and data.\n",
      "562\n",
      "Duration of video [s]:  18.73 , recorded with  30.0 fps!\n",
      "Overall # of frames:  562 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 562/562 [00:04<00:00, 116.38it/s]\n",
      "  0%|                                                                                 | 8/5613 [00:00<01:14, 75.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Labeled video already created.\n",
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\11_10_2019_23_46_06_DG_190417_a_fail.avi and data.\n",
      "5613\n",
      "Duration of video [s]:  187.1 , recorded with  30.0 fps!\n",
      "Overall # of frames:  5613 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5613/5613 [00:51<00:00, 109.23it/s]\n",
      "  1%|▉                                                                                 | 7/614 [00:00<00:08, 67.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\08_07_2019_18_05_49_DG_190416_a_succ.avi and data.\n",
      "614\n",
      "Duration of video [s]:  20.47 , recorded with  30.0 fps!\n",
      "Overall # of frames:  614 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 614/614 [00:05<00:00, 105.94it/s]\n",
      "  1%|█                                                                                 | 7/511 [00:00<00:07, 68.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos ['D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_17_06_13_DG_200526_d_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_15_06_59_DG_200526_b_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_23_2020_15_03_01_DG_200526_c_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_30_2020_14_41_22_DG_200526_b_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\06_26_2020_16_25_35_DG_200526_c_succ_lowFR.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_12_2020_15_35_46_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\03_05_2020_16_26_13_MM_200128_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\11_10_2019_23_46_06_DG_190417_a_fail.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_07_2019_18_05_49_DG_190416_a_succ.avi', 'D:\\\\dlc_vr_arena\\\\VPrey-Matt-2020-07-01\\\\videos\\\\08_03_2019_17_34_12_DG_190416_a_succ.avi']\n",
      "Loading  D:\\dlc_vr_arena\\VPrey-Matt-2020-07-01\\videos\\08_03_2019_17_34_12_DG_190416_a_succ.avi and data.\n",
      "511\n",
      "Duration of video [s]:  17.03 , recorded with  30.0 fps!\n",
      "Overall # of frames:  511 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 511/511 [00:04<00:00, 107.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# use the path defined above\n",
    "dlc.create_labeled_video(config_path, project_video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract outlier frames\n",
    "dlc.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  uncerrtain  found  0  putative outlier frames.\n",
      "Do you want to proceed with extracting  30  of those?\n",
      "yes/noyes\n",
      "Frames from video 06_30_2020_17_06_13_DG_200526_d_succ_lowFR  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  45.2 , recorded @  30.0 fps!\n",
      "Overall # of frames:  1356 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 45.2  seconds.\n",
      "Let's select frames indices: []\n",
      "No frames were extracted.\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n",
      "It seems the video has not been analyzed yet, or the video is not found! You can only refine the labels after the a video is analyzed. Please run 'analyze_video' first. Or, please double check your video file path\n"
     ]
    }
   ],
   "source": [
    "# extract outlier frames\n",
    "dlc.extract_outlier_frames(config_path, project_video_list, outlieralgorithm='uncerrtain', p_bound=0.8)\n",
    "# deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All-NaN slice encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\refinement.py\u001b[0m in \u001b[0;36mOnKeyPressed\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0mpos_rel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_abs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mpos_rel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpos_rel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Recall y-axis is inverted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanargmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpos_rel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m             \u001b[0mclosest_dp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m             msg = wx.MessageBox('Do you want to remove the label %s ?' % closest_dp.bodyParts, 'Remove!',\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36mnanargmin\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All-NaN slice encountered\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All-NaN slice encountered"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 2.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "# Merge the dataset, then move to check labels and retrain\n",
    "\n",
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLC-GPU] *",
   "language": "python",
   "name": "conda-env-DLC-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
