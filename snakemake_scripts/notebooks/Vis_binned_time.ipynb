{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate behavioral binned time averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture'))\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')\n",
    "from bokeh.resources import INLINE\n",
    "\n",
    "import paths\n",
    "import functions_bondjango as bd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functions_plotting as fp\n",
    "import functions_data_handling as fd\n",
    "from scipy.stats import sem\n",
    "import sklearn.decomposition as decomp\n",
    "import umap\n",
    "import sklearn.mixture as mix\n",
    "from scipy.stats import sem\n",
    "\n",
    "# define the name to be used for the saved figures\n",
    "save_name = 'acrossTrials'\n",
    "line_width = 5"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# load the data\n",
    "# get the data paths\n",
    "try:\n",
    "    data_path = snakemake.input[0]\n",
    "except NameError:\n",
    "    # define the search string\n",
    "    search_string = 'result:succ, lighting:normal, rig:miniscope, =analysis_type:aggBin'\n",
    "    # query the database for data to plot\n",
    "    data_all = bd.query_database('analyzed_data', search_string)\n",
    "    data_path = data_all[0]['analysis_path']\n",
    "print(data_path)\n",
    "\n",
    "# load the data\n",
    "data = fd.aggregate_loader(data_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot example traces\n",
    "\n",
    "# define the target parameter\n",
    "target_parameters = ['mouse_cricket_distance', 'cricket_speed','mouse_speed']\n",
    "# allocate a list for the plots\n",
    "plot_list = []\n",
    "\n",
    "# for all the parameters\n",
    "for target in target_parameters:\n",
    "    # load the parameter\n",
    "    parameter = data[[target,'trial_id']].copy()\n",
    "    # group the single traces\n",
    "    grouped_parameter = parameter.groupby(['trial_id']).agg(list)\n",
    "    grouped_parameter = np.array([el for el in grouped_parameter[target]])\n",
    "\n",
    "    # plot all traces\n",
    "    \n",
    "    [sorted_traces,_,_] = fp.sort_traces(grouped_parameter)\n",
    "    \n",
    "    image = hv.Image(sorted_traces, ['Binned Time','Trial #'], \n",
    "                     [target.replace('_', ' ')], bounds=[0, 0, grouped_parameter.shape[1], grouped_parameter.shape[0]])\n",
    "    image.opts(width=fp.pix(5.8), height=fp.pix(5.8), toolbar=None, \n",
    "                        hooks=[fp.margin], fontsize=fp.font_sizes['small'], \n",
    "                        xticks=3, yticks=3,\n",
    "                        colorbar=True, cmap='viridis', \n",
    "               colorbar_opts={'major_label_text_align': 'left'})\n",
    "            \n",
    "\n",
    "    # assemble the save path\n",
    "    save_path = os.path.join(paths.figures_path,save_name+'_'+target+'.png')\n",
    "    hv.save(image,save_path)\n",
    "    \n",
    "    \n",
    "    plot_list.append(image)\n",
    "    \n",
    "    \n",
    "\n",
    "#     # calculate the mean and sem\n",
    "#     trace_mean = np.mean(grouped_parameter, axis=0)\n",
    "#     trace_sem = sem(grouped_parameter, axis=0)\n",
    "#     x_vector = np.arange(trace_mean.shape[0])\n",
    "#     plot_list.append(hv.Curve((x_vector, trace_mean), 'Time', target)*\\\n",
    "#                      hv.Spread((x_vector, trace_mean, trace_sem), 'Time', vdims=[target, 'error']))\n",
    "\n",
    "hv.Layout(plot_list)\n",
    "    \n",
    "    \n",
    "    \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot the duration of the trial for each trial\n",
    "\n",
    "# load the parameter\n",
    "parameter = data[['mouse_cricket_distance','trial_id']].copy()\n",
    "# group the single traces\n",
    "grouped_parameter = parameter.groupby(['trial_id']).agg(list)\n",
    "grouped_parameter = np.array([el for el in grouped_parameter['mouse_cricket_distance']])\n",
    "\n",
    "# plot all traces\n",
    "\n",
    "[_,_,cluster_idx] = fp.sort_traces(grouped_parameter)\n",
    "\n",
    "times = data[['time_vector','trial_id']].copy()\n",
    "times = times.groupby(['trial_id']).agg(list)\n",
    "# allocate a list for the durations\n",
    "duration_list = []\n",
    "\n",
    "# for all the trials\n",
    "for trial in times['time_vector']:\n",
    "    \n",
    "    duration_list.append(trial[-1])\n",
    "\n",
    "# turn the durations into an array\n",
    "duration_list = np.array(duration_list)\n",
    "\n",
    "# allocate a list for the duration averages\n",
    "print(np.max(cluster_idx)+1)\n",
    "duration_averages = np.zeros((np.max(cluster_idx)+1, 2))\n",
    "# for all the clusters\n",
    "for clu in cluster_idx:\n",
    "    duration_averages[clu, 0] = np.mean(duration_list[cluster_idx==clu])\n",
    "    duration_averages[clu, 1] = sem(duration_list[cluster_idx==clu])\n",
    "    \n",
    "    \n",
    "# plot the results\n",
    "clu_vector = np.arange(np.max(cluster_idx)+1)\n",
    "errorbar = hv.ErrorBars((clu_vector, duration_averages[:, 0], duration_averages[:, 1])) * \\\n",
    "hv.Bars((clu_vector, duration_averages[:, 0]))\n",
    "errorbar\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# define the target parameter and PCA\n",
    "target_parameter = 'mouse_cricket_distance'\n",
    "\n",
    "# load the parameter\n",
    "parameter = data[[target_parameter,'trial_id']].copy()\n",
    "# group the single traces\n",
    "target_data = parameter.groupby(['trial_id']).agg(list).to_numpy()\n",
    "target_data = np.array([el for sublist in target_data for el in sublist])\n",
    "\n",
    "# PCA the data before clustering\n",
    "pca = decomp.PCA()\n",
    "transformed_data = pca.fit_transform(target_data)\n",
    "# fp.plot_2d([[pca.explained_variance_ratio_]])\n",
    "\n",
    "curve = hv.Curve(np.cumsum(pca.explained_variance_ratio_)/np.sum(pca.explained_variance_ratio_))\n",
    "curve.opts(tools=['hover'])\n",
    "# define the number of PCs to use\n",
    "pc_number = 7\n",
    "\n",
    "curve"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cluster the data\n",
    "\n",
    "# define the vector of components\n",
    "# component_vector = [2, 3, 4, 5, 10, 20, 30]\n",
    "component_vector = [2, 3, 4, 5, 10, 20]\n",
    "# allocate memory for the results\n",
    "gmms = []\n",
    "# for all the component numbers\n",
    "for comp in component_vector:\n",
    "    # # define the number of components\n",
    "    # n_components = 10\n",
    "    gmm = mix.GaussianMixture(n_components=comp, covariance_type='diag', n_init=50)\n",
    "    gmm.fit(transformed_data[:, :pc_number+1])\n",
    "    gmms.append(gmm.bic(transformed_data[:, :pc_number+1]))\n",
    "\n",
    "# select the minimum bic number of components\n",
    "n_components = np.array(component_vector)[np.argmin(gmms)]\n",
    "# predict the cluster indexes\n",
    "gmm = mix.GaussianMixture(n_components=n_components, covariance_type='diag', n_init=50)\n",
    "cluster_idx = gmm.fit_predict(transformed_data[:, :pc_number+1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# discard singletons\n",
    "# turn cluster_idx in a float\n",
    "cluster_idx = cluster_idx.astype(float)\n",
    "# get the IDs\n",
    "clu_unique = np.unique(cluster_idx)\n",
    "for clu in clu_unique:\n",
    "    # get the number of traces in the cluster\n",
    "    number_traces = sum(cluster_idx==clu)\n",
    "    # if it's less than 5, eliminate the cluster\n",
    "    if number_traces < 5:\n",
    "        cluster_idx[cluster_idx==clu] = np.nan\n",
    "    \n",
    "# plot the BIC\n",
    "hv.Curve((component_vector, gmms))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# UMAP\n",
    "\n",
    "# embed the data via UMAP\n",
    "reducer = umap.UMAP(min_dist=0.5, n_neighbors=10)\n",
    "embedded_data = reducer.fit_transform(transformed_data[:, :pc_number+1])\n",
    "# embedded_data = reducer.fit_transform(target_data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# use AHC on the data\n",
    "\n",
    "# load the parameter\n",
    "parameter = data[['mouse_cricket_distance','trial_id']].copy()\n",
    "# group the single traces\n",
    "grouped_parameter = parameter.groupby(['trial_id']).agg(list)\n",
    "grouped_parameter = np.array([el for el in grouped_parameter['mouse_cricket_distance']])\n",
    "\n",
    "# plot all traces\n",
    "\n",
    "[_,_,cluster_idx] = fp.sort_traces(grouped_parameter)\n",
    "\n",
    "# [_,_,cluster_idx] = fp.sort_traces(transformed_data[:, :pc_number+1])\n",
    "[_,_,cluster_idx] = fp.sort_traces(grouped_parameter)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot the embedding\n",
    "# umap_data = np.concatenate((embedded_data,np.expand_dims(cluster_idx, axis=1)),axis=1)\n",
    "\n",
    "# umap_data = np.concatenate((embedded_data,np.expand_dims(duration_list, axis=1)),axis=1)\n",
    "umap_data = np.concatenate((embedded_data,np.expand_dims(cluster_idx, axis=1),\n",
    "                            np.expand_dims(duration_list, axis=1)),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# fp.plot_scatter([[embedded_data]])\n",
    "umap_plot = hv.Scatter(umap_data, vdims=['Dim 2','cluster', 'duration'], kdims=['Dim 1'])\n",
    "umap_plot.opts(color='cluster', colorbar=True, cmap='Category10', size='duration')\n",
    "\n",
    "umap_plot.opts(opts.Scatter(width=fp.pix(6), height=fp.pix(6.14), toolbar=None, \n",
    "                        hooks=[fp.margin], fontsize=fp.font_sizes['small'], xticks=3, yticks=3),\n",
    "            opts.Overlay(legend_position='right', text_font='Arial'))\n",
    "\n",
    "# duration_plot = hv.Scatter(umap_data, vdims=['Dim 2','cluster'], kdims=['Dim 1'])\n",
    "\n",
    "# assemble the save path\n",
    "save_path = os.path.join(paths.figures_path,save_name+'_umap.png')\n",
    "hv.save(umap_plot,save_path)\n",
    "\n",
    "umap_plot"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
