{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5551915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture'))\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture\\mine_pub'))\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')\n",
    "from bokeh.resources import INLINE\n",
    "\n",
    "import paths\n",
    "import functions_plotting as fp\n",
    "from functions_plotting import format_figure as ff\n",
    "import functions_bondjango as bd\n",
    "import functions_loaders as fl\n",
    "import snakemake_scripts.tc_calculate as tc\n",
    "import processing_parameters\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import scipy.stats as stat\n",
    "import scipy.signal as signal\n",
    "import sklearn.decomposition as decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2887629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the figure config\n",
    "importlib.reload(fp)\n",
    "importlib.reload(processing_parameters)\n",
    "# define the target saving path\n",
    "save_path = os.path.join(paths.figures_path, 'Behavior_representation')\n",
    "\n",
    "# define the printing mode\n",
    "save_mode = True\n",
    "# define the target document\n",
    "target_document = 'paper'\n",
    "# set up the figure theme\n",
    "fp.set_theme()\n",
    "# load the label dict\n",
    "label_dict = processing_parameters.label_dictionary\n",
    "variable_list = processing_parameters.variable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ea12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(processing_parameters)\n",
    "importlib.reload(fl)\n",
    "\n",
    "# get the paths from the database using search_list\n",
    "all_paths, all_queries = fl.query_search_list()\n",
    "# print(all_paths)\n",
    "\n",
    "data_list = []\n",
    "# load the data\n",
    "for path, queries in zip(all_paths, all_queries):\n",
    "    \n",
    "    data, _, _  = fl.load_preprocessing(path, queries)\n",
    "    data_list.append(data)\n",
    "\n",
    "# print(all_paths)\n",
    "print(f'Number of trials: {len(data_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the range of trials to use for the calculation\n",
    "\n",
    "# list the available mouse and date pairs\n",
    "unique_dates_mice = np.unique([(el.loc[0, 'mouse'], el.loc[0, 'datetime'][:10]) for el in data_list[0]], axis=0)\n",
    "# print(unique_dates_mice)\n",
    "# define the target day and mouse\n",
    "target_mouse = 'DG_210202_a'\n",
    "target_date = '2021-04-30'\n",
    "# extract the trials\n",
    "target_trials = [el for el in data_list[0] if (target_mouse in el.loc[0, 'mouse']) & (target_date in el.loc[0, 'datetime'])]\n",
    "print(len(target_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the behavior\n",
    "\n",
    "variable_list = processing_parameters.variable_list\n",
    "# for all the data, keep only the behavioral variables of interest\n",
    "data_behavior = []\n",
    "\n",
    "for el in target_trials:\n",
    "#     for el2 in el:\n",
    "    try:\n",
    "        data_behavior.append(el[variable_list].reset_index(drop=True))\n",
    "    except KeyError:\n",
    "        continue\n",
    "# concatenate the data\n",
    "# data_behavior = pd.concat(data_behavior, axis=0).to_numpy()\n",
    "# print(data_behavior.shape)\n",
    "print(len(data_behavior))\n",
    "\n",
    "behavior_columns = variable_list\n",
    "# raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target trial\n",
    "target_trial = 1\n",
    "ticks = [(idx+0.5, label_dict[el]) for idx, el in enumerate(variable_list)]\n",
    "\n",
    "plot = hv.Raster(data_behavior[target_trial].to_numpy().T)\n",
    "plot.opts(width=1200, height=600, cmap='Viridis', tools=['hover'], yticks=ticks)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply PCA to the behavior\n",
    "\n",
    "# allocate a list for the transformation matrices\n",
    "matrix_list = []\n",
    "# for all the trials, get the transformation matrices\n",
    "for trial in data_behavior:\n",
    "    pca = decomp.PCA()\n",
    "    pca.fit(trial)\n",
    "    matrix_list.append(pca.components_)\n",
    "    \n",
    "# average the transformation matrix\n",
    "average_transform = np.mean(matrix_list, axis=0)\n",
    "# print(pca.get_params())\n",
    "# raise ValueError\n",
    "\n",
    "# allocate a list for the output\n",
    "pca_behavior = []\n",
    "# for all the trials, transform the trials\n",
    "for trial in data_behavior:\n",
    "    pca = decomp.PCA()\n",
    "    pca.fit(trial)\n",
    "    pca.components_ = average_transform\n",
    "#     pca.mean_ = 0\n",
    "#     pca = pca.set_params({'components_': average_transform})\n",
    "    \n",
    "    pca_output = pca.transform(trial)\n",
    "    pca_output = pd.DataFrame(pca_output, columns=['pc'+str(el) for el in np.arange(pca_output.shape[1])])\n",
    "    pca_behavior.append(pca_output.reset_index(drop=True))\n",
    "# save the column names\n",
    "pca_columns = pca_output.columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_list = []\n",
    "\n",
    "for el in matrix_list:\n",
    "    plot = hv.Raster(el)\n",
    "    plot.opts(cmap='Viridis')\n",
    "    plot_list.append(plot)\n",
    "    \n",
    "layout = hv.Layout(plot_list).cols(4)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f90a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latents\n",
    "\n",
    "# allocate a list for the output\n",
    "vame_behavior = []\n",
    "# for all the trials\n",
    "for trial in target_trials:\n",
    "    # get the relevant columns\n",
    "    target_columns = [el for el in trial.columns if 'latent' in el]\n",
    "    if len(target_columns) == 0:\n",
    "        continue\n",
    "    vame_behavior.append(trial[target_columns].reset_index(drop=True))\n",
    "# save the columns\n",
    "vame_columns = target_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ef8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the latents, PCs and behaviors\n",
    "\n",
    "# allocate the output\n",
    "combined_data = []\n",
    "\n",
    "for idx, trial in enumerate(data_behavior):\n",
    "    \n",
    "    # get the calcium information\n",
    "    original_trial = target_trials[idx]\n",
    "    cells = [el for el in original_trial.columns if 'cell' in el]\n",
    "    calcium = original_trial[cells].reset_index(drop=True)\n",
    "#     print(vame_behavior[idx])\n",
    "    combined_data.append(pd.concat([trial, pca_behavior[idx], vame_behavior[idx], calcium], axis=1))\n",
    "# combine the column names\n",
    "overall_columns = [behavior_columns, pca_columns, vame_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# calculate the TCs in all three decompositions\n",
    "importlib.reload(tc)\n",
    "\n",
    "# get the number of bins\n",
    "bin_num = processing_parameters.bin_number\n",
    "# define the pairs to quantify\n",
    "variable_names = np.concatenate(overall_columns)\n",
    "# variable_names = ['pc0', 'pc1']\n",
    "\n",
    "# clip the calcium traces\n",
    "clipped_data = tc.clip_calcium(combined_data)\n",
    "\n",
    "# parse the features (bin number is for spatial bins in this one)\n",
    "features, calcium = tc.parse_features(clipped_data, variable_names, bin_number=10)\n",
    "\n",
    "# concatenate all the trials\n",
    "features = pd.concat(features)\n",
    "calcium = np.concatenate(calcium)\n",
    "\n",
    "# get the number of cells\n",
    "cell_num = calcium.shape[1]\n",
    "\n",
    "# get the TCs and their responsivity\n",
    "tcs_half, tcs_full, tcs_resp, tc_count, tc_bins = tc.extract_tcs_responsivity(features, calcium, variable_names,\n",
    "                                                                              cell_num, percentile=95,\n",
    "                                                                              bin_number=bin_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the tunings\n",
    "\n",
    "overall_fractions = []\n",
    "overall_points = []\n",
    "for idx in np.arange(3):\n",
    "    # allocate memory for the fractions\n",
    "    fraction_list = []\n",
    "    variable_list = overall_columns[idx]\n",
    "    \n",
    "    points_dict = []\n",
    "    # for all the targets\n",
    "    for target_feature in variable_list:\n",
    "        # load the data\n",
    "    #     data = []\n",
    "    #     for file in data_path:\n",
    "    #         try:\n",
    "    #             data.append(pd.read_hdf(file, target_feature))\n",
    "    #         except KeyError:\n",
    "    #             continue\n",
    "#         print(target_feature)\n",
    "        analysis_df = pd.DataFrame(tcs_resp[target_feature], columns=['none1', 'none2', 'Qual_index', 'Qual_test'])\n",
    "\n",
    "    #     data = pd.concat(data, axis=0)\n",
    "        # plot average histograms\n",
    "    #     analysis_df = data[['Qual_test', 'day', 'animal']]\n",
    "\n",
    "        # generate a binary vector with cells passing both criteria\n",
    "    #     both = ((analysis_df.loc[:, 'Resp_test']>0) & (analysis_df.loc[:, 'Cons_test']>0)).to_numpy()\n",
    "        both = (analysis_df.loc[:, 'Qual_test']>0).to_numpy()\n",
    "        # insert this as a column in the dataframe\n",
    "        analysis_df.insert(analysis_df.shape[1], 'Pass_fraction', both) \n",
    "\n",
    "    #     sums = analysis_df.groupby(['day'], as_index=False)['Pass_fraction'].sum()\n",
    "#         counts = analysis_df.groupby(['day'], as_index=False)['Pass_fraction'].mean()\n",
    "        counts = analysis_df.mean(axis=0)\n",
    "        if target_feature in label_dict.keys():\n",
    "            counts['Feature'] = label_dict[target_feature]\n",
    "        else:\n",
    "            counts['Feature'] = target_feature\n",
    "#         counts.loc[:, 'Feature'] = label_dict[target_feature]\n",
    "\n",
    "\n",
    "        fraction_list.append(counts[['Feature', 'Pass_fraction', 'Qual_index']])\n",
    "        \n",
    "#         points_dict[target_feature] = analysis_df['']\n",
    "        points_dict.append(analysis_df['Qual_index'].to_numpy())\n",
    "        \n",
    "    \n",
    "    overall_fractions.append(pd.concat(fraction_list, axis=1).transpose())\n",
    "    overall_points.append(pd.DataFrame(np.array(points_dict).T, columns=variable_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f278da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_fractions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bc98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the averages\n",
    "plot_list = []\n",
    "# for all the methods\n",
    "for idx in np.arange(3):\n",
    "        \n",
    "    plot = hv.Scatter(overall_fractions[idx], kdims='Feature', vdims='Pass_fraction')\n",
    "    plot.opts(width=400, height=400, xrotation=45, ylim=(0, 1))\n",
    "    plot_list.append(plot)\n",
    "layout = hv.Layout(plot_list).cols(3).opts(shared_axes=False)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0eba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the averages\n",
    "plot_list = []\n",
    "# for all the methods\n",
    "for idx in np.arange(3):\n",
    "        \n",
    "    plot = hv.Scatter(overall_fractions[idx], kdims='Feature', vdims='Qual_index')\n",
    "    plot.opts(width=400, height=400, xrotation=45, ylim=(-0.1, 0.1))\n",
    "    plot_list.append(plot)\n",
    "layout = hv.Layout(plot_list).cols(3).opts(shared_axes=False)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation structures\n",
    "\n",
    "# plot the averages\n",
    "plot_list = []\n",
    "# for all the methods\n",
    "for idx in np.arange(3):\n",
    "    current_correlation = overall_points[idx].to_numpy()\n",
    "    current_correlation[np.isnan(current_correlation)] = 0\n",
    "#     if target_feature in label_dict.keys():\n",
    "#         counts['Feature'] = label_dict[target_feature]\n",
    "#     else:\n",
    "#         counts['Feature'] = target_feature\n",
    "    \n",
    "    ticks = [(idx2+0.5, el) for idx2, el in enumerate(overall_columns[idx])]\n",
    "#     print(ticks)\n",
    "#     raise ValueError\n",
    "    current_correlation, _ = stat.spearmanr(current_correlation, nan_policy='omit')\n",
    "    plot = hv.Raster(current_correlation)\n",
    "#     plot = hv.Scatter(overall_fractions[idx], kdims='Feature', vdims='Qual_index')\n",
    "    plot.opts(width=400, height=600, xrotation=45, tools=['hover'], xticks=ticks, ylabel='', xlabel='')\n",
    "    plot_list.append(plot)\n",
    "layout = hv.Layout(plot_list).cols(3).opts(shared_axes=False)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the encoding model in all three decompositions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c116ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform classification on all three of the decompositions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prey_capture] *",
   "language": "python",
   "name": "conda-env-.conda-prey_capture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
