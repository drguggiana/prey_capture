{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d08368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture'))\n",
    "\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')\n",
    "from bokeh.resources import INLINE\n",
    "\n",
    "import paths\n",
    "import importlib\n",
    "import functions_plotting as fp\n",
    "import functions_bondjango as bd\n",
    "import processing_parameters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import scipy.stats as stat\n",
    "import datetime\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fp)\n",
    "importlib.reload(processing_parameters)\n",
    "# set up the figure theme\n",
    "fp.set_theme()\n",
    "label_dict = processing_parameters.label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the desired files and their associated regressions\n",
    "\n",
    "# # define the target variable\n",
    "# target_variable = 'cricket_0_mouse_distance'\n",
    "\n",
    "# load the latents for each file with their attributes\n",
    "# %%time\n",
    "# Load the desired files\n",
    "importlib.reload(processing_parameters)\n",
    "\n",
    "# load the constants from the regression calculation\n",
    "time_shifts = processing_parameters.time_shifts\n",
    "shift_dict = {el: idx for idx, el in enumerate(time_shifts)}\n",
    "shift_number = len(time_shifts)\n",
    "shuffles = processing_parameters.regression_shuffles\n",
    "\n",
    "# load the variable list\n",
    "variable_list = processing_parameters.variable_list\n",
    "# assemble the dataframe columns\n",
    "reals = ['real_'+str(el) for el in time_shifts]\n",
    "shuffle_means = ['smean_'+str(el) for el in time_shifts]\n",
    "shuffle_sems = ['ssem_'+str(el) for el in time_shifts]\n",
    "columns = reals + shuffle_means + shuffle_sems + ['mouse', 'day']\n",
    "\n",
    "# get the search list\n",
    "search_list = processing_parameters.search_list\n",
    "\n",
    "# allocate a list for all paths (need to preload to get the dates)\n",
    "all_paths = []\n",
    "all_results = []\n",
    "# for all the search strings\n",
    "for search_string in search_list:\n",
    "\n",
    "    # query the database for data to plot\n",
    "    data_all = bd.query_database('analyzed_data', search_string)\n",
    "#         data_all = [el for el in data_all if 'preproc' in el['slug']]\n",
    "    data_path = [el['analysis_path'] for el in data_all if '_combinedanalysis' in el['slug']]\n",
    "    data_result = [el['result'] for el in data_all if '_combinedanalysis' in el['slug']]\n",
    "    all_paths.append(data_path)\n",
    "    all_results.append(data_result)\n",
    "# get the dates present\n",
    "data_dates = np.unique([os.path.basename(el)[:10] for el in np.concatenate(all_paths)])\n",
    "print(f'Dates present: {data_dates}')\n",
    "\n",
    "# allocate memory for the resulting dataframe\n",
    "data = {}\n",
    "weights = {}\n",
    "day_list = []\n",
    "animal_list = []\n",
    "# for all the list items\n",
    "for idx0, data_path in enumerate(all_paths):\n",
    "\n",
    "    # for all the files\n",
    "    for idx1, files in enumerate(data_path):\n",
    "        \n",
    "        # get the animal and date from the slug\n",
    "        name_parts = os.path.basename(files).split('_')\n",
    "        animal = '_'.join(name_parts[7:10])\n",
    "        day = '_'.join(name_parts[:3])\n",
    "        day = datetime.datetime.strptime(day, '%m_%d_%Y')\n",
    "        # skip if the animal and day are already evaluated, \n",
    "        # since the CC is the same for the whole day\n",
    "        if (animal in animal_list and day in day_list):\n",
    "            continue\n",
    "        else:\n",
    "            animal_list.append(animal)\n",
    "            day_list.append(day)\n",
    "        # load the data\n",
    "        with h5py.File(files, 'r') as h:\n",
    "            # for all the target variables\n",
    "            for target_variable in variable_list:\n",
    "                # create an empty list only if it's the same time this variable runs\n",
    "                if target_variable not in data.keys():\n",
    "                    data[target_variable] = []\n",
    "                    weights[target_variable] = []\n",
    "                # allocate memory for the real and shuffled regressions\n",
    "                real_array = np.zeros((shift_number, 1))\n",
    "                shuffle_array = np.zeros((shift_number, shuffles))\n",
    "                real_weight = []\n",
    "                shuffle_weight = []\n",
    "\n",
    "                # for all the keys (will iterate through shifts and reps for shuffle)\n",
    "                for key in h['/regression'].keys():\n",
    "\n",
    "                    # skip if it's not a cc key or is not the target variable\n",
    "                    if (target_variable not in key):\n",
    "                        continue\n",
    "                    # get the time shift and shuffle\n",
    "                    key_parts = key.split('_')\n",
    "                    shift = int([el[5:] for el in key_parts if 'shift' in el][0])\n",
    "                    if 'cc' in key:\n",
    "\n",
    "                        if 'real' in key_parts:\n",
    "                             # save the values\n",
    "                            real_array[shift_dict[shift]] = np.array(h['/regression/'+key])\n",
    "                        else:\n",
    "                            shuffle = int([el[7:] for el in key_parts if 'shuffle' in el][0])\n",
    "                            shuffle_array[shift_dict[shift], shuffle-1] = np.array(h['/regression/'+key])\n",
    "                    elif ('coefficients' in key and shift == 0):\n",
    "                        if 'real' in key_parts:\n",
    "                            real_weight = np.array(h['/regression/'+key])\n",
    "                        else:\n",
    "                            shuffle_weight.append(np.array(h['/regression/'+key]))    \n",
    "                    else:\n",
    "                        continue\n",
    "                # average the shuffles and get the sem\n",
    "                shuffle_mean = np.mean(shuffle_array, axis=1)\n",
    "                shuffle_sem = stat.sem(shuffle_array, axis=1)\n",
    "                # add the columns to the main list\n",
    "                data[target_variable].append(list(real_array[:, 0]) + list(shuffle_mean) + list(shuffle_sem) + [animal, day])\n",
    "\n",
    "                if isinstance(real_weight, list):\n",
    "                    continue\n",
    "                weight_mean = np.mean(shuffle_weight, axis=0)\n",
    "                weight_sem = stat.sem(shuffle_weight, axis=0)\n",
    "\n",
    "                # store the weights\n",
    "                weights[target_variable].append(list(real_weight) + list(weight_mean) + list(weight_sem) + [animal, day])\n",
    "\n",
    "            \n",
    "# for all the variables once more\n",
    "for target_variable in variable_list:\n",
    "    # turn the overall list into a dataframe\n",
    "    data[target_variable] = pd.DataFrame(data[target_variable], columns=columns)\n",
    "    # turn the weights into a dictionary\n",
    "    weights[target_variable] = {(el[-2], el[-1]): el[:-2] for el in weights[target_variable]}\n",
    "#     # get the weight columns\n",
    "#     number_cells = int((len(weights[target_variable][0]) - 2)/3)\n",
    "#     real_columns = ['real_' + str(el) for el in np.arange(number_cells)]\n",
    "#     smean_columns = ['smean_' + str(el) for el in np.arange(number_cells)]\n",
    "#     ssem_columns = ['ssem_' + str(el) for el in np.arange(number_cells)]\n",
    "#     weight_columns = real_columns + smean_columns + ssem_columns + ['mouse', 'day']\n",
    "#     # turn the list into a dataframe\n",
    "#     weights[target_variable] = pd.DataFrame(weights[target_variable], columns=weight_columns)\n",
    "\n",
    "print(data)\n",
    "#             dataframe = pd.concat([behavior, latents], axis=1)\n",
    "#                 # add the results to the dataframe\n",
    "#                 dataframe.loc[:, 'result'] = all_results[idx0][idx1]\n",
    "\n",
    "                # store\n",
    "#                 pre_data.append((files, dataframe))\n",
    "#                 include_counter += 1\n",
    "\n",
    "                    \n",
    "# print(f'Number of matched trials: {unique[np.argmax(counts)].sum()}')\n",
    "# print(f'Number of trials without latents: {exclude_counter}')\n",
    "# print(f'Number of trials with latents: {include_counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average kernel per animal compared to shuffle\n",
    "\n",
    "overlay_list = []\n",
    "# for all the target variables\n",
    "for target_variable in variable_list:\n",
    "    # average across days for each animal\n",
    "    averages = data[target_variable].groupby(['mouse',], as_index=False)[reals+shuffle_means+shuffle_sems].mean()\n",
    "    sems = data[target_variable].groupby(['mouse',], as_index=False)[reals+shuffle_means+shuffle_sems].sem().fillna(0)\n",
    "\n",
    "    # allocate a list for the plots\n",
    "    plot_list = []\n",
    "    # for all the mice\n",
    "    for idx, (mouse, df)  in enumerate(averages.groupby(['mouse'])):\n",
    "        real_plot = hv.Curve((time_shifts, df.loc[:, reals].to_numpy().flatten()))\n",
    "        real_plot.opts(width=400, height=400, title=target_variable)\n",
    "        real_sem = hv.Spread((time_shifts, df.loc[:, reals].to_numpy().flatten(), sems.loc[idx, reals].to_numpy().flatten()))\n",
    "        real_sem.opts(color='red')\n",
    "        shuffle_plot = hv.Curve((time_shifts, df.loc[:, shuffle_means].to_numpy().flatten()))\n",
    "        shuffle_plot.opts(color='black')\n",
    "        shuffle_error = hv.Spread((time_shifts, df.loc[:, shuffle_means].to_numpy().flatten(), sems.loc[idx, shuffle_means].to_numpy().flatten()))\n",
    "        shuffle_error.opts(color='black')\n",
    "\n",
    "        plot_list.append(real_plot*real_sem*shuffle_plot*shuffle_error)\n",
    "    \n",
    "\n",
    "    overlay_list.append(hv.Overlay(plot_list))\n",
    "\n",
    "hv.Layout(overlay_list).cols(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de415f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across mice and time\n",
    "\n",
    "overlay_list = []\n",
    "# for all the target variables\n",
    "for target_variable in variable_list:\n",
    "    # average across days for each animal\n",
    "#     averages = data[target_variable].groupby(, as_index=False)[reals+shuffle_means+shuffle_sems].mean()\n",
    "    averages = data[target_variable].loc[:, reals+shuffle_means+shuffle_sems].mean(axis=0)\n",
    "    sems = data[target_variable].loc[:, reals+shuffle_means+shuffle_sems].sem(axis=0)\n",
    "    \n",
    "    real_plot = hv.Curve((time_shifts, averages.loc[reals].to_numpy().flatten()))\n",
    "    real_sem = hv.Spread((time_shifts, averages.loc[reals].to_numpy().flatten(), sems.loc[reals].to_numpy().flatten()))\n",
    "    real_plot.opts(width=400, height=400, title=target_variable)\n",
    "    shuffle_plot = hv.Curve((time_shifts, averages.loc[shuffle_means].to_numpy().flatten()))\n",
    "    shuffle_error = hv.Spread((time_shifts, averages.loc[shuffle_means].to_numpy().flatten(), sems.loc[shuffle_means].to_numpy().flatten()))\n",
    "\n",
    "    overlay_list.append(real_plot*real_sem*shuffle_plot*shuffle_error)\n",
    "    \n",
    "\n",
    "\n",
    "hv.Layout(overlay_list).cols(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distributions per variable\n",
    "\n",
    "# define the target time point\n",
    "tpoint = 0\n",
    "real_list = []\n",
    "shuffle_list = []\n",
    "\n",
    "# def format_whisker()\n",
    "\n",
    "# define the variables to include\n",
    "include_variables = variable_list[:-1]\n",
    "# for all the variables\n",
    "for target_variable in include_variables:\n",
    "    # get only the 0 lag value for each day\n",
    "    real_data = data[target_variable].loc[:, ['real_'+str(tpoint)]]\n",
    "    real_data['Feature'] = label_dict[target_variable]\n",
    "    real_list.append(real_data)\n",
    "    \n",
    "    shuffle_data = data[target_variable].loc[:, ['smean_'+str(tpoint)]]\n",
    "    shuffle_data = shuffle_data.rename({'smean_'+str(tpoint): 'real_'+str(tpoint)}, axis=1)\n",
    "    shuffle_data['Feature'] = label_dict[target_variable]+' shuffle'\n",
    "    real_list.append(shuffle_data)\n",
    "    \n",
    "    x_mwu = real_data.loc[:, 'real_'+str(tpoint)].to_numpy()\n",
    "    x_mwu = x_mwu[~np.isnan(x_mwu)]\n",
    "    y_mwu = shuffle_data.loc[:, 'real_'+str(tpoint)].to_numpy()\n",
    "    y_mwu = y_mwu[~np.isnan(y_mwu)]\n",
    "    test = stat.mannwhitneyu(x_mwu, y_mwu)\n",
    "    print(test)\n",
    "\n",
    "violin0 = hv.BoxWhisker(pd.concat(real_list, axis=0), ['Feature'], ['real_'+str(tpoint)])\n",
    "violin0.opts(width=1400, height=800, xrotation=45, ylabel='CC (a.u.)')\n",
    "violin0\n",
    "# violin1 = hv.Violin(pd.concat(shuffle_list, axis=0), ['Feature'], ['smean_'+str(tpoint)])\n",
    "# violin1.opts(width=800, height=800, xrotation=45)\n",
    "\n",
    "# (violin0*violin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9280062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the CC over time\n",
    "\n",
    "# initialize a list for the plots\n",
    "time_plot = []\n",
    "\n",
    "# define the target timepoint\n",
    "tpoint = 10\n",
    "# for all the variables\n",
    "for target_variable in variable_list:\n",
    "    temp_list = []\n",
    "    # for all the mice\n",
    "    for mouse, df_ori in data[target_variable].groupby(['mouse']):\n",
    "        # copy to not mess the original dataframe\n",
    "        df = df_ori.copy()\n",
    "        df = df.sort_values(['day'], axis=0).reset_index(drop=True)\n",
    "        # get the delta time\n",
    "        delta_time = [(el-df['day'][0]).days for el in df['day']]\n",
    "\n",
    "        real_plot = hv.Curve((delta_time, df.loc[:, 'real_'+str(tpoint)]))\n",
    "        real_plot.opts(title=target_variable, width=400, height=400, xlabel='Time (days)', ylabel='CC (a.u.)')\n",
    "        shuffle_plot = hv.Curve((delta_time, df.loc[:, 'smean_'+str(tpoint)]))\n",
    "        shuffle_error = hv.Spread((delta_time, df.loc[:, 'smean_'+str(tpoint)], df.loc[:, 'ssem_'+str(tpoint)]))\n",
    "        \n",
    "        \n",
    "\n",
    "        temp_list.append(real_plot*shuffle_plot*shuffle_error)\n",
    "#         temp_list.append(real_plot)\n",
    "    time_plot.append(hv.Overlay(temp_list))\n",
    "\n",
    "hv.Layout(time_plot).cols(3)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the weight distributions\n",
    "# put all the cells in a single dataframe with variables vs cells\n",
    "# print(weights['cricket_0_mouse_distance'].keys())\n",
    "\n",
    "# need to iterate through the variables, and concatenate the weights in order per day\n",
    "\n",
    "# allocate memory for the output dataframe\n",
    "output_df = []\n",
    "\n",
    "# for all the variables\n",
    "for idx, target_feature in enumerate(weights.keys()):\n",
    "    # get the data\n",
    "    current_feature = weights[target_feature]\n",
    "    temp_list = []\n",
    "    # iterate through the items\n",
    "    for mouse, day in current_feature.keys():\n",
    "#         print(mouse)\n",
    "#         print(day)\n",
    "#         print(current_feature[mouse, day])\n",
    "        # build a data frame from the day, mouse and weights\n",
    "        df = pd.DataFrame(current_feature[mouse, day], columns=[target_feature])\n",
    "        if idx == 0:\n",
    "#             df['mouse'] = mouse\n",
    "#             df['day'] = day\n",
    "#             df['feature'] = target_feature\n",
    "            df.insert(0, 'mouse', mouse)\n",
    "            df.insert(0, 'day', day)        \n",
    "        # store and continue accumulating\n",
    "        temp_list.append(df)\n",
    "    \n",
    "    temp_df = pd.concat(temp_list, axis=0).reset_index(drop=True)\n",
    "    output_df.append(temp_df)\n",
    "# concatenate into a single dataframe\n",
    "output_df = pd.concat(output_df, axis=1)\n",
    "\n",
    "\n",
    "# eliminate rows with nans\n",
    "output_df = output_df.iloc[~np.any(np.isnan(output_df.drop(['mouse', 'day'], axis=1).to_numpy()), axis=1), :]\n",
    "print(output_df.columns)\n",
    "print(output_df.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d96a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# perform a umap decomposition of the weights across variables\n",
    "\n",
    "# format the data\n",
    "umap_data = output_df.drop(['mouse', 'day'], axis=1).to_numpy()\n",
    "\n",
    "# run the decomposition\n",
    "reducer = umap.UMAP(min_dist=0.5, n_neighbors=30)\n",
    "embedded_data = reducer.fit_transform(umap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea3dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the decomposition\n",
    "\n",
    "# define the interval between points\n",
    "interv = 5\n",
    "\n",
    "umap_list = []\n",
    "# target_key = 'cricket_0_mouse_distance'\n",
    "# for all the variables\n",
    "for target_key in variable_list:\n",
    "    # if target_key in ['mouse', 'day']:\n",
    "    counts, raw_labels = np.unique(output_df.loc[:, target_key].to_numpy(), return_inverse=True)\n",
    "    raw_labels = (raw_labels - raw_labels.min())/(raw_labels.max() - raw_labels.min())\n",
    "    # else:\n",
    "    #     counts, raw_labels = np.unique(output_df.loc[:, target_key].to_numpy(), return_inverse=True)\n",
    "    #     raw_labels = output_df.loc[:, target_key].to_numpy()\n",
    "\n",
    "    compiled_labels = np.expand_dims(raw_labels, axis=1)\n",
    "\n",
    "    umap_data = np.concatenate((embedded_data,compiled_labels),axis=1)\n",
    "\n",
    "    compiled_labels = compiled_labels[::interv]\n",
    "    umap_data = umap_data[::interv, :]\n",
    "\n",
    "\n",
    "    umap_plot = hv.Scatter(umap_data, vdims=['Dim 2', target_key], kdims=['Dim 1'])\n",
    "    umap_plot.opts(color=target_key, colorbar=True, cmap='Spectral', size=3, title=target_key)\n",
    "\n",
    "    umap_plot.opts(height=600, width=800)\n",
    "    umap_list.append(umap_plot)\n",
    "\n",
    "hv.Layout(umap_list).cols(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prey_capture] *",
   "language": "python",
   "name": "conda-env-.conda-prey_capture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
