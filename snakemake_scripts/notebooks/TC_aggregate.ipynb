{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d34baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture'))\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from bokeh.io import export_svgs, export_png\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation import histogram\n",
    "hv.extension('bokeh')\n",
    "from bokeh.resources import INLINE\n",
    "\n",
    "import functions_bondjango as bd\n",
    "import functions_plotting as fp\n",
    "import paths\n",
    "\n",
    "import importlib\n",
    "import processing_parameters\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "import umap\n",
    "import scipy.stats as stat\n",
    "from rastermap import Rastermap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the figure config\n",
    "importlib.reload(fp)\n",
    "importlib.reload(processing_parameters)\n",
    "# define the target saving path\n",
    "save_path = os.path.join(paths.figures_path, 'TC_aggregate')\n",
    "\n",
    "# define the printing mode (REMEMBER TO CHECK IT'S NOT IN MANUAL IN THE ACTUAL CELL)\n",
    "save_mode = True\n",
    "# define the target document\n",
    "target_document = 'paper'\n",
    "# set up the figure theme\n",
    "fp.set_theme()\n",
    "# load the label dict\n",
    "label_dict = processing_parameters.label_dictionary\n",
    "variable_list = processing_parameters.variable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b818a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tc_consolidate file\n",
    "importlib.reload(processing_parameters)\n",
    "\n",
    "# get the search query\n",
    "search_consolidate = processing_parameters.search_consolidate\n",
    "\n",
    "# query the database for data to plot\n",
    "data_path = bd.query_database('analyzed_data', search_consolidate)\n",
    "# data_path = [el['analysis_path'] for el in data_path if 'test' not in el['analysis_path']][0]\n",
    "data_path = [el['analysis_path'] for el in data_path if 'test' not in el['analysis_path']]\n",
    "pprint(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target feature and load it\n",
    "# target_feature = 'mouse_x__mouse_y'\n",
    "# target_feature = 'cricket_0_mouse_distance__cricket_0_delta_heading'\n",
    "# target_feature = 'cricket_0_x__cricket_0_y'\n",
    "# target_feature = 'mouse_speed'\n",
    "target_feature = 'cricket_0_mouse_distance'\n",
    "# target_feature = 'latent_0__latent_1'\n",
    "\n",
    "data = []\n",
    "# load the data\n",
    "for path in data_path:\n",
    "# data = pd.read_hdf(data_path, target_feature)\n",
    "    try:\n",
    "        data.append(pd.read_hdf(path, target_feature))\n",
    "        print(f'Dimensions of the data (cells by feature): {data[-1].shape}')\n",
    "    except KeyError:\n",
    "        continue\n",
    "data = pd.concat(data, axis=0)\n",
    "\n",
    "# define a dictionary for the combined labels\n",
    "combo_labels = {\n",
    "    'mouse_x__mouse_y': 'Mouse Position',\n",
    "    'cricket_0_mouse_distance__cricket_0_delta_heading': 'Prey angle and distance',\n",
    "    'cricket_0_x__cricket_0_y': 'Prey position', \n",
    "    'mouse_speed__cricket_0_speed': 'Mouse and prey speed'\n",
    "}\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ded118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fraction of selective cells over animals and time\n",
    "# select the test columns and the day and animal ones\n",
    "analysis_df = data[['Resp_test', 'Cons_test', 'day', 'animal']]\n",
    "# generate a binary vector with cells passing both criteria\n",
    "both = ((analysis_df.loc[:, 'Resp_test']>0) & (analysis_df.loc[:, 'Cons_test']>0)).to_numpy()\n",
    "# insert this as a column in the dataframe\n",
    "analysis_df.insert(analysis_df.shape[1], 'Pass_fraction', both) \n",
    "# group by animals and day\n",
    "sums = analysis_df.groupby(['animal', 'day'], as_index=False)['Pass_fraction'].mean()\n",
    "# allocate space for the dates\n",
    "date_list = []\n",
    "# convert all the dates to intervals\n",
    "for date in sums.loc[:, 'day']:\n",
    "    new_day = datetime.datetime.strptime(date, '%m_%d_%Y')\n",
    "    date_list.append(new_day)\n",
    "# replace the day column\n",
    "sums['day'] = date_list\n",
    "# allocate memory for the delta time df\n",
    "df_list = []\n",
    "# for all animals\n",
    "for idx, (animal, df) in enumerate(sums.groupby(['animal'])):\n",
    "    # reset the index of the sub dataframe\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # get the delta time\n",
    "    delta_time = [(el-df['day'][0]).days for el in df['day']]\n",
    "    df['day'] = delta_time\n",
    "    # build the label\n",
    "    label = 'M'+str(idx)\n",
    "    # generate the plot\n",
    "    plot = hv.Curve(df[['day', 'Pass_fraction']], label=label)\n",
    "    plot.opts(ylim=(-0.01, 1))\n",
    "    # format the plot\n",
    "    plot = fp.format_figure(plot, width=600, height=400)\n",
    "\n",
    "    # store\n",
    "    df_list.append(plot)\n",
    "\n",
    "# build the overlay and display\n",
    "out_plot = hv.Overlay(df_list).opts(show_legend=True, legend_position='top')\n",
    "\n",
    "# display the figure\n",
    "out_plot\n",
    "\n",
    "# assemble the file name\n",
    "# save_name = os.path.join(save_path, '_'.join(('pass_fraction', target_feature)) + '.png')\n",
    "# save the figure\n",
    "# _ = fp.save_figure(out_plot, save_name, fig_width=6, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e0aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot responsivity and consistency over animals and time\n",
    "\n",
    "analysis_df = data[['Resp_index', 'Cons_index', 'day', 'animal']]\n",
    "analysis_df.loc[np.isnan(analysis_df.loc[:, 'Resp_index'].to_numpy()), 'Resp_index'] = 0\n",
    "analysis_df.loc[np.isinf(analysis_df.loc[:, 'Resp_index'].to_numpy()), 'Resp_index'] = 0\n",
    "analysis_df.loc[np.isnan(analysis_df.loc[:, 'Cons_index'].to_numpy()), 'Cons_index'] = 0\n",
    "analysis_df.loc[np.isinf(analysis_df.loc[:, 'Cons_index'].to_numpy()), 'Cons_index'] = 0\n",
    "\n",
    "# include only cells that are significant\n",
    "analysis_df = analysis_df.iloc[both, :]\n",
    "\n",
    "sums = analysis_df.groupby(['day', 'animal'], as_index=False)[['day', 'Resp_index', 'Cons_index']].mean()\n",
    "\n",
    "# allocate space for the dates\n",
    "date_list = []\n",
    "# convert all the dates to intervals\n",
    "for date in sums.loc[:, 'day']:\n",
    "    new_day = datetime.datetime.strptime(date, '%m_%d_%Y')\n",
    "    date_list.append(new_day)\n",
    "# replace the day column\n",
    "sums.loc[:, 'day'] = date_list\n",
    "# allocate memory for the delta time df\n",
    "resp_list = []\n",
    "cons_list = []\n",
    "# for all animals\n",
    "for idx, (animal, df) in enumerate(sums.groupby(['animal'])):\n",
    "    # reset the index of the sub dataframe\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # get the delta time\n",
    "    delta_time = [(el-df['day'][0]).days for el in df['day']]\n",
    "    df.loc[:, 'day'] = delta_time\n",
    "    \n",
    "#     df = df.iloc[both, :]\n",
    "    # build the label\n",
    "    label = 'M'+str(idx)\n",
    "    # plot and save\n",
    "    resp_plot = hv.Curve(df[['day', 'Resp_index']], label=label)\n",
    "    resp_plot.opts(ylim=(1, 6))\n",
    "    resp_plot = fp.format_figure(resp_plot, width=600, height=400)\n",
    "    cons_plot = hv.Curve(df[['day', 'Cons_index']], label=label)\n",
    "    cons_plot.opts(ylim=(0, 0.7))\n",
    "    cons_plot = fp.format_figure(cons_plot, width=600, height=400)\n",
    "    resp_list.append(resp_plot)\n",
    "    cons_list.append(cons_plot)\n",
    "\n",
    "resp_overlay = hv.Overlay(resp_list).opts(legend_position='top', show_legend=True)\n",
    "cons_overlay = hv.Overlay(cons_list).opts(legend_position='top', show_legend=True)\n",
    "# print(sums)\n",
    "# combo_plot = (hv.Overlay(resp_list)+hv.Overlay(cons_list)).cols(1)\n",
    "# combo_plot.opts(opts.Overlay(legend_position='top', show_legend=True))\n",
    "# display figure\n",
    "(resp_overlay+cons_overlay).cols(1)\n",
    "\n",
    "# assemble the file name\n",
    "# save_name = os.path.join(save_path, '_'.join(('resp_index', target_feature)) + '.png')\n",
    "# save the figure\n",
    "# _ = fp.save_figure(resp_overlay, save_name, fig_width=6, dpi=600)\n",
    "\n",
    "\n",
    "# assemble the file name\n",
    "# save_name = os.path.join(save_path, '_'.join(('cons_index', target_feature)) + '.png')\n",
    "# save the figure\n",
    "# _ = fp.save_figure(cons_overlay, save_name, fig_width=6, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example cells\n",
    "# random.seed(1)\n",
    "# # define how many cells to plot per animal\n",
    "# number_cells = 10\n",
    "# # define the criterion\n",
    "# # criterion = 'random'\n",
    "# criterion_list = ['top', 'random']\n",
    "# # define the colormap to use\n",
    "# cmap = 'Purples'\n",
    "\n",
    "# for criterion in criterion_list:\n",
    "\n",
    "#     # get a list of all the animals\n",
    "#     animal_list = np.unique(data['animal'])\n",
    "#     print(animal_list)\n",
    "#     # get current bins\n",
    "#     current_bins = processing_parameters.tc_params[target_feature]\n",
    "#     plot_list = []\n",
    "#     # for all the animals\n",
    "#     for animal in animal_list:\n",
    "#         # get the cells for this animal\n",
    "#         current_cells = data.iloc[data.loc[:, 'animal'].to_numpy()==animal, :]\n",
    "#         # get the cells based on a criterion\n",
    "#         if criterion == 'top':\n",
    "#             # get top cells from every animal based on passing both criteria and aggregated score\n",
    "#             both_idx = ((current_cells.loc[:, 'Resp_test'] > 0) & \\\n",
    "#                 (current_cells.loc[:, 'Cons_test'] > 0)).to_numpy()\n",
    "#             agg = current_cells.loc[both_idx, 'Resp_index'] * current_cells.loc[both_idx, 'Cons_index']\n",
    "#             current_cells.insert(current_cells.shape[1], 'agg', agg)\n",
    "#             top_idx = np.flip(np.argsort(current_cells.loc[both_idx, 'agg']))\n",
    "#             current_cells = current_cells.loc[both_idx, :]\n",
    "#             top_cells = current_cells.iloc[top_idx, :]\n",
    "#         elif criterion == 'random':\n",
    "#             # get n random cells per animal\n",
    "#             sel_idx = random.sample(list(np.arange(current_cells.shape[0])), number_cells)\n",
    "#             top_cells = current_cells.iloc[sel_idx, :]\n",
    "\n",
    "#         # make sure there are no more cells indexed than detected\n",
    "#         idx_limit = number_cells if top_cells.shape[0] >= number_cells else top_cells.shape[0]\n",
    "\n",
    "#         # for the top n\n",
    "#         for cell_idx in np.arange(idx_limit):\n",
    "#             # get the current cell\n",
    "#             current_cell = top_cells.iloc[cell_idx, :]\n",
    "\n",
    "#             # get the current values\n",
    "#             current_resp = current_cell['Resp_index']\n",
    "#             current_cons = current_cell['Cons_index']\n",
    "#             # get the date\n",
    "#             current_day = current_cell['day']\n",
    "#             # get the cell id in the original dataframe\n",
    "#             cell_id = top_cells.index[cell_idx]\n",
    "#             # get the variable names\n",
    "#             var_names = target_feature.split('__')[::-1]\n",
    "#             # get the three maps\n",
    "#             # define bins\n",
    "#             bins0 = np.linspace(current_bins[0], current_bins[1], 10)\n",
    "# #             bins1 = np.linspace(current_bins[1][0], current_bins[1][1], 10)\n",
    "\n",
    "#             # full map\n",
    "#             full_labels = [el for el in current_cell.index if ('bin_' in el) & ('half_' not in el)]\n",
    "#             full_map = current_cell.loc[full_labels].to_numpy().reshape((10, 10))\n",
    "\n",
    "#             title = f'{animal}, {current_day}'\n",
    "#             full_map = hv.Image((bins1, bins0, full_map), kdims=var_names)\n",
    "#             full_map.opts(title=title, shared_axes=False, xrotation=45, cmap=cmap)\n",
    "#             plot_list.append(full_map)\n",
    "\n",
    "#             # half maps\n",
    "#             half0_labels = [el for el in current_cell.index if ('half_0_bin_' in el)]\n",
    "#             half0_map = current_cell.loc[half0_labels].to_numpy().reshape((10, 10))\n",
    "\n",
    "#             title = f'Cell number: {cell_id}'\n",
    "#             half0_map = hv.Image((bins1, bins0, half0_map), kdims=var_names)\n",
    "#             half0_map.opts(title=title, shared_axes=False, xrotation=45, cmap=cmap)\n",
    "#             plot_list.append(half0_map)\n",
    "\n",
    "#             half1_labels = [el for el in current_cell.index if ('half_1_bin_' in el)]\n",
    "#             half1_map = current_cell.loc[half1_labels].to_numpy().reshape((10, 10))\n",
    "\n",
    "#             title = f'Cons: {current_cons:.2f}, Resp: {current_resp:.2f}'\n",
    "#             half1_map = hv.Image((bins1, bins0, half1_map), kdims=var_names)\n",
    "#             half1_map.opts(title=title, shared_axes=False, xrotation=45, cmap=cmap)\n",
    "#             plot_list.append(half1_map)\n",
    "\n",
    "#     example_layout = hv.Layout(plot_list).opts(shared_axes=False).cols(3)\n",
    "#     example_layout\n",
    "\n",
    "#     # assemble the path\n",
    "#     save_name = os.path.join(save_path, '_'.join(('examples', target_feature, criterion)) + '.png')\n",
    "#     hv.save(example_layout, save_name, dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot defined cells as examples\n",
    "\n",
    "# # define the number of cells to save\n",
    "# save_cells = 2 \n",
    "# # define the target animal\n",
    "# animal = 'DG_200701_a'\n",
    "# # reset the rng\n",
    "# random.seed(1)\n",
    "\n",
    "# criterion_list = ['top', 'random']\n",
    "# current_bins = processing_parameters.tc_params[target_feature]\n",
    "# labels = processing_parameters.label_dictionary\n",
    "# cmap = 'Purples'\n",
    "# number_cells = 10\n",
    "\n",
    "# cell_list = []\n",
    "# # get the cells for this animal\n",
    "# current_cells = data.iloc[data.loc[:, 'animal'].to_numpy()==animal, :]\n",
    "# number_cells = np.min((number_cells, current_cells.shape[0]))\n",
    "\n",
    "# def format_colorbar_hook(plot, element):\n",
    "#     # get the plot dict\n",
    "#     b = plot.state\n",
    "#     b.right[0].major_label_text_font_size = '40pt'\n",
    "#     b.right[0].major_label_text_font_size = '40pt'\n",
    "#     b.right[0].label_standoff = 25\n",
    "\n",
    "\n",
    "# # for the criteria on the list\n",
    "# for criterion in criterion_list:\n",
    "#     working_cells = current_cells.copy()\n",
    "#     # get the cells based on a criterion\n",
    "#     if criterion == 'top':\n",
    "#         # get top cells from every animal based on passing both criteria and aggregated score\n",
    "#         both_idx = ((working_cells.loc[:, 'Resp_test'] > 0) & \\\n",
    "#             (current_cells.loc[:, 'Cons_test'] > 0)).to_numpy()\n",
    "#         agg = current_cells.loc[both_idx, 'Resp_index'] * working_cells.loc[both_idx, 'Cons_index']\n",
    "#         working_cells.insert(working_cells.shape[1], 'agg', agg)\n",
    "#         top_idx = np.flip(np.argsort(working_cells.loc[both_idx, 'agg']))\n",
    "#         working_cells = working_cells.loc[both_idx, :]\n",
    "#         top_cells = working_cells.iloc[top_idx, :]\n",
    "#     elif criterion == 'random':\n",
    "#         # get n random cells per animal\n",
    "#         sel_idx = random.sample(list(np.arange(working_cells.shape[0])), number_cells)\n",
    "#         top_cells = current_cells.iloc[sel_idx, :]\n",
    "#     # plot and save the top n cells from above\n",
    "#     for cell in np.arange(save_cells):\n",
    "#         # get the current cell\n",
    "#         current_cell = top_cells.iloc[cell, :]\n",
    "\n",
    "#     #         # get the current values\n",
    "#     #         current_resp = current_cell['Resp_index']\n",
    "#     #         current_cons = current_cell['Cons_index']\n",
    "#     #         # get the date\n",
    "#     #         current_day = current_cell['day']\n",
    "#     #         # get the cell id in the original dataframe\n",
    "#     #         cell_id = top_cells.index[cell_idx]\n",
    "#         # get the variable names\n",
    "#         var_names = target_feature.split('__')[::-1]\n",
    "#         # get the three maps\n",
    "#         # define bins\n",
    "#         bins0 = np.linspace(current_bins[0][0], current_bins[0][1], 10)\n",
    "#         bins1 = np.linspace(current_bins[1][0], current_bins[1][1], 10)\n",
    "        \n",
    "# #         # convert to polar coordinates\n",
    "# #         bins0_pol = bins0*np.cos(bins1)\n",
    "# #         bins1_pol = bins0*np.sin(bins1)\n",
    "        \n",
    "# #         bins0 = bins0_pol\n",
    "# #         bins1 = bins1_pol\n",
    "\n",
    "#         # full map\n",
    "#         full_labels = [el for el in current_cell.index if ('bin_' in el) & ('half_' not in el)]\n",
    "#         full_map = current_cell.loc[full_labels].to_numpy().reshape((10, 10))\n",
    "\n",
    "#     #         title = f'{animal}, {current_day}'\n",
    "#         full_map = hv.Image((bins1, bins0, full_map), kdims=[labels[el] for el in var_names])\n",
    "# #         full_map = hv.HexTiles((bins0, bins1, full_map))\n",
    "#         full_map.opts(cmap=cmap, colorbar=True, hooks=[format_colorbar_hook])\n",
    "#     #     full_map.opts(shared_axes=False, xrotation=45, cmap=cmap)\n",
    "#         full_map = fp.format_figure(full_map, frame_width=400, frame_height=400)\n",
    "#         cell_list.append(full_map)\n",
    "\n",
    "#         save_name = os.path.join(save_path, \n",
    "#                                  '_'.join(('Example', str(cell), target_feature, criterion)) + '.png')\n",
    "#         _ = fp.save_figure(full_map, save_name, fig_width=4, dpi=600)        \n",
    "# # hv.Layout(cell_list).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variables\n",
    "\n",
    "# target_features = ['mouse_x', 'cricket_0_mouse_distance', 'cricket_0_delta_heading', 'cricket_0_x', 'mouse_speed', 'cricket_0_speed', 'mouse_heading']\n",
    "\n",
    "# target_features = ['mouse_speed', 'mouse_x', 'mouse_angular_speed', 'cricket_0_mouse_distance',\n",
    "#                    'cricket_0_delta_heading', 'cricket_0_x',\n",
    "#                    'cricket_0_visual_angle', 'hunt_trace', 'cricket_0_direction', 'cricket_0_loom',\n",
    "#                    'cricket_0_delta_visual']\n",
    "# target_features.remove('hunt_trace')\n",
    "\n",
    "# allocate memory for the fractions\n",
    "fraction_list = []\n",
    "resp_list = []\n",
    "cons_list = []\n",
    "# for all the targets\n",
    "for target_feature in variable_list:\n",
    "    # load the data\n",
    "    data = []\n",
    "    for file in data_path:\n",
    "        try:\n",
    "            data.append(pd.read_hdf(file, target_feature))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    print(target_feature)\n",
    "    data = pd.concat(data, axis=0)\n",
    "    # plot average histograms\n",
    "    analysis_df = data[['Resp_test', 'Cons_test', 'Qual_test', 'Qual_index', 'day', 'animal']]\n",
    "    \n",
    "    analysis_df.loc[np.isnan(analysis_df.loc[:, 'Resp_test']), 'Resp_test'] = 0\n",
    "    analysis_df.loc[np.isinf(analysis_df.loc[:, 'Resp_test']), 'Resp_test'] = 0\n",
    "    \n",
    "    analysis_df.loc[np.isnan(analysis_df.loc[:, 'Cons_test']), 'Cons_test'] = 0\n",
    "    analysis_df.loc[np.isinf(analysis_df.loc[:, 'Cons_test']), 'Cons_test'] = 0\n",
    "    # generate a binary vector with cells passing both criteria\n",
    "#     both = ((analysis_df.loc[:, 'Resp_test']>0) & (analysis_df.loc[:, 'Cons_test']>0)).to_numpy()\n",
    "    both = (analysis_df.loc[:, 'Qual_test']>0).to_numpy()\n",
    "    # insert this as a column in the dataframe\n",
    "    analysis_df.insert(analysis_df.shape[1], 'Pass_fraction', both) \n",
    "    analysis_df['Qual_index'] = np.abs(analysis_df['Qual_index'].mask(analysis_df['Qual_test'].to_numpy()==0))\n",
    "#     analysis_df.iloc[analysis_df['Qual_test'].to_numpy()==0, :].loc[:, 'Qual_index'] = np.nan\n",
    "#     print(analysis_df.iloc[analysis_df['Qual_test'].to_numpy()==0, :].loc[:, 'Qual_index'])\n",
    "    \n",
    "#     sums = analysis_df.groupby(['day'], as_index=False)['Pass_fraction'].sum()\n",
    "#     counts = analysis_df.groupby(['day'], as_index=False)['Pass_fraction', 'Qual_index'].mean()\n",
    "    counts = analysis_df.groupby(['day'], as_index=False)['Pass_fraction', 'Qual_index'].agg(np.nanmean)\n",
    "    \n",
    "    counts.loc[:, 'Feature'] = label_dict[target_feature]\n",
    "    \n",
    "    fraction_list.append(counts[['Feature', 'Pass_fraction', 'Qual_index']])\n",
    "    \n",
    "    resp_df = data[['Resp_index', 'day']]\n",
    "    resp_df.loc[:, 'Pass_fraction'] = both\n",
    "    resp_df = resp_df.loc[resp_df['Pass_fraction'] == 1, :]\n",
    "    print(resp_df.shape)\n",
    "    resp_df.loc[:, 'Feature'] = target_feature\n",
    "    resp_list.append(resp_df[['Resp_index', 'Feature']])\n",
    "    \n",
    "    \n",
    "    cons_df = data[['Cons_index', 'day']]\n",
    "    cons_df.loc[:, 'Pass_fraction'] = both\n",
    "    cons_df = cons_df.loc[cons_df['Pass_fraction'] == 1, :]\n",
    "    \n",
    "    cons_df.loc[:, 'Feature'] = target_feature\n",
    "    cons_list.append(cons_df[['Cons_index', 'Feature']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa17b16",
   "metadata": {},
   "source": [
    "# TC Box Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f830f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distributions\n",
    "# print(fraction_list[1].shape)\n",
    "importlib.reload(fp)\n",
    "plot_array = pd.concat(fraction_list)\n",
    "# print(plot_array.columns)\n",
    "# print(plot_array)\n",
    "\n",
    "# print(plot_array)\n",
    "# ticks = [(idx+0.5, label_dict[el]) for idx, el in enumerate(variable_list)]\n",
    "\n",
    "whisker = hv.BoxWhisker(plot_array, ['Feature'], ['Pass_fraction'])\n",
    "whisker.opts(width=800, height=800, xrotation=45, ylabel='Significant fraction', xlabel='', box_line_width=1, whisker_line_width=1, outlier_line_width=1)\n",
    "\n",
    "# assemble the file name\n",
    "save_name = os.path.join(save_path, '_'.join((target_document, 'TC_fraction')) + '.png')\n",
    "# save the figure\n",
    "fig = fp.save_figure(whisker, save_name, fig_width=5, dpi=1200, fontsize='small', target='save')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b58c3",
   "metadata": {},
   "source": [
    "# TC Mean Quality Boxplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7dc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distributions\n",
    "# print(fraction_list[1].shape)\n",
    "importlib.reload(fp)\n",
    "plot_array = pd.concat(fraction_list)\n",
    "\n",
    "# print(plot_array.columns)\n",
    "# print(plot_array)\n",
    "\n",
    "# print(plot_array)\n",
    "# ticks = [(idx+0.5, label_dict[el]) for idx, el in enumerate(variable_list)]\n",
    "\n",
    "whisker = hv.BoxWhisker(plot_array, ['Feature'], ['Qual_index'])\n",
    "whisker.opts(width=800, height=800, xrotation=45, ylabel='Tuning index', xlabel='', box_line_width=1, whisker_line_width=1, outlier_line_width=1)\n",
    "\n",
    "# assemble the file name\n",
    "save_name = os.path.join(save_path, '_'.join((target_document, 'TC_index')) + '.png')\n",
    "# save the figure\n",
    "fig = fp.save_figure(whisker, save_name, fig_width=5, dpi=1200, fontsize='small', target='save')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_array = pd.concat(resp_list)\n",
    "# print(plot_array)\n",
    "\n",
    "# whisker = hv.BoxWhisker(plot_array, ['Feature'], ['Resp_index'])\n",
    "whisker = hv.BoxWhisker(plot_array, ['Feature'], ['Resp_index'])\n",
    "whisker.opts(width=600, height=800, xrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da88b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_array = pd.concat(cons_list)\n",
    "# print(plot_array)\n",
    "\n",
    "# whisker = hv.BoxWhisker(plot_array, ['Feature'], ['Resp_index'])\n",
    "whisker = hv.BoxWhisker(plot_array, ['Feature'], ['Cons_index'])\n",
    "whisker.opts(width=600, height=800, xrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92279003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TCs for each cell and feature to embed with UMAP\n",
    "\n",
    "tc_whole = []\n",
    "# for all the targets\n",
    "for idx, target_feature in enumerate(variable_list):\n",
    "    # load the data\n",
    "    data = []\n",
    "    for file in data_path:\n",
    "        # get the keys\n",
    "        \n",
    "#         with pd.HDFStore(file, mode='r') as h:\n",
    "#             current_keys = [el[1:] for el in h.keys()]\n",
    "#         if target_features.sort() != current_keys.sort():\n",
    "#         if ~all(el in target_features for el in current_keys):\n",
    "#             print('yay')\n",
    "#             continue\n",
    "        try:\n",
    "            data.append(pd.read_hdf(file, target_feature))\n",
    "#             print(file, target_feature, data[-1].shape)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    data = pd.concat(data, axis=0)\n",
    "#     print(target_feature, data.shape)\n",
    "    \n",
    "    # load the relevant columns\n",
    "    if idx == 0:\n",
    "        target_columns = ['day', 'animal', 'Resp_index', 'Cons_index', 'Qual_index'] + [el for el in data.columns if ('bin' in el) & ('half' not in el)]\n",
    "    else:\n",
    "        target_columns = ['Resp_index', 'Cons_index', 'Qual_index'] + [el for el in data.columns if ('bin' in el) & ('half' not in el)]\n",
    "    \n",
    "    data = data.loc[:, target_columns]\n",
    "    \n",
    "    # change the column names\n",
    "    new_names = {el: target_feature+'_'+el if ('bin' in el) | ('index' in el) else el for el in target_columns}\n",
    "    data = data.rename(columns=new_names)\n",
    "    # save in the list\n",
    "    tc_whole.append(data)\n",
    "\n",
    "# concatenate    \n",
    "tc_whole = pd.concat(tc_whole, axis=1)\n",
    "print(tc_whole.shape)\n",
    "# exclude all rows with nans\n",
    "# drop_columns = ['day', 'animal'] + [el for el in tc_whole.columns if 'Cons' in el]\n",
    "cleanup_columns = [el for el in tc_whole.columns if 'Qual' in el]\n",
    "cleanup_data = tc_whole.loc[:, cleanup_columns].to_numpy()\n",
    "cleanup_data[np.isnan(cleanup_data)] = 0\n",
    "cleanup_data[np.isinf(cleanup_data)] = 0\n",
    "tc_whole.loc[:, cleanup_columns] = cleanup_data\n",
    "# nonan_vector = ~np.any(np.isnan(tc_whole.drop(drop_columns, axis=1).to_numpy()), axis=1)\n",
    "# nan_vector = np.any(np.isnan(tc_whole.drop(drop_columns, axis=1).to_numpy()), axis=1)\n",
    "# tc_whole[np.isnan(tc_whole.to_numpy())] = 0\n",
    "# tc_whole = tc_whole.iloc[nonan_vector, :]\n",
    "\n",
    "print(tc_whole.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2853e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count cells per animal\n",
    "\n",
    "animal_counts = tc_whole.groupby(['animal', 'day'])[['day']].count()\n",
    "for el in np.arange(animal_counts.shape[0]):\n",
    "    print(animal_counts.iloc[el, :])\n",
    "# print(animal_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33336c",
   "metadata": {},
   "source": [
    "# Correlation plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd1a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correlation matrix between the responsivity indexes\n",
    "\n",
    "# get only the resp columns\n",
    "resp_columns = [el for el in tc_whole.columns if 'Qual_index' in el]\n",
    "\n",
    "resp_indexes = tc_whole.loc[:, resp_columns]\n",
    "\n",
    "# get rid of the nans and infs\n",
    "nonan_vector = ~np.any(np.isnan(resp_indexes.to_numpy()), axis=1)\n",
    "resp_indexes = resp_indexes.iloc[nonan_vector, :]\n",
    "# print(resp_indexes)\n",
    "\n",
    "# calculate the correlation matrix\n",
    "correlation_matrix, pvalue_matrix = stat.spearmanr(resp_indexes.to_numpy())\n",
    "correlation_matrix[pvalue_matrix>0.05] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9be029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation matrix\n",
    "# ticks = [(idx+0.5, el[:-11]) for idx, el in enumerate(resp_columns)]\n",
    "\n",
    "# raster = hv.Raster(correlation_matrix)\n",
    "# raster.opts(width=800, height=600, yticks=ticks, xticks=ticks, xrotation=45, colorbar=True, cmap='RdBu', clim=(-1, 1), tools=['hover'])\n",
    "# raster\n",
    "importlib.reload(fp)\n",
    "\n",
    "ticks = [(idx+0.5, label_dict[el]) for idx, el in enumerate(variable_list)]\n",
    "# ticks = [(idx+0.5, idx) for idx, el in enumerate(variable_list)]\n",
    "plot_matrix = correlation_matrix.copy()\n",
    "plot_matrix = np.tril(plot_matrix, k=0)\n",
    "plot_matrix[plot_matrix==0] = np.nan\n",
    "# hv.Raster(correlation_matrix)\n",
    "raster = hv.Raster(plot_matrix)\n",
    "# format the plot\n",
    "raster.opts(width=1050, height=800, yticks=ticks, xticks=ticks, colorbar=True, cmap='RdBu_r', clim=(-1, 1), xrotation=45, xlabel='', ylabel='')\n",
    "\n",
    "# assemble the file name\n",
    "save_name = os.path.join(save_path, '_'.join((target_document, 'TC_correlation')) + '.png')\n",
    "# save the figure\n",
    "fig = fp.save_figure(raster, save_name, fig_width=7, dpi=1200, fontsize='small', target='save')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e11bfc",
   "metadata": {},
   "source": [
    "# Tunings plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the tunings across the population\n",
    "\n",
    "plot_matrix = resp_indexes.to_numpy().copy()\n",
    "\n",
    "model = Rastermap(n_components=2, n_X=30, nPC=200, init='pca')\n",
    "model.fit(plot_matrix)\n",
    "plot_matrix = plot_matrix[model.isort, :]\n",
    "\n",
    "# idx_matrix = np.lexsort(plot_matrix)\n",
    "# print(idx_matrix)\n",
    "# plot_matrix = plot_matrix[:, idx_matrix]\n",
    "\n",
    "plot = hv.Raster(plot_matrix)\n",
    "plot.opts(width=1000, height=600, tools=['hover'], cmap='RdBu_r', xticks=ticks, ylabel='Cells', clim=(-0.5, 0.5), xlabel='', xrotation=45, colorbar=True)\n",
    "\n",
    "# assemble the file name\n",
    "save_name = os.path.join(save_path, '_'.join((target_document, 'TC_tunings')) + '.png')\n",
    "# save the figure\n",
    "fig = fp.save_figure(plot, save_name, fig_width=7, dpi=1200, fontsize='small', target='save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run the UMAP embedding\n",
    "\n",
    "# get the data\n",
    "# umap_data = tc_whole.drop(drop_columns, axis=1).to_numpy()\n",
    "umap_data = tc_whole.loc[:, cleanup_columns].to_numpy()\n",
    "\n",
    "# run the decomposition\n",
    "reducer = umap.UMAP(min_dist=0.5, n_neighbors=30)\n",
    "embedded_data = reducer.fit_transform(umap_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277171ef",
   "metadata": {},
   "source": [
    "# UMAP TC plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the UMAP results\n",
    "importlib.reload(fp)\n",
    "# define the interval between points\n",
    "interv = 1\n",
    "# define percentile to discard\n",
    "perc = 95\n",
    "\n",
    "label_list = resp_columns + ['animal', 'day']\n",
    "umap_list = []\n",
    "# target_key = 'cricket_0_mouse_distance'\n",
    "# for all the variables\n",
    "for target_key in label_list:\n",
    "#     print(target_key)\n",
    "    if ('Cons' in target_key) | ('Resp' in target_key):\n",
    "        continue\n",
    "#     if 'index' not in target_key:\n",
    "#         counts, raw_labels = np.unique(tc_whole.loc[:, target_key].to_numpy(), return_inverse=True)\n",
    "#         raw_labels = (raw_labels - raw_labels.min())/(raw_labels.max() - raw_labels.min())\n",
    "#     else:\n",
    "#         raw_labels = tc_whole.loc[:, target_key].to_numpy().copy()\n",
    "# #         print(target_key)\n",
    "# #         print(raw_labels)\n",
    "# #         raw_labels = np.log10(raw_labels)\n",
    "#         raw_labels[raw_labels>10] = np.nan\n",
    "# #         raw_labels[np.isnan(raw_labels)] = 0\n",
    "# #         raw_labels[np.isinf(raw_labels)] = 0\n",
    "    if 'index' not in target_key:\n",
    "        counts, raw_labels = np.unique(tc_whole.loc[:, target_key].to_numpy(), return_inverse=True)\n",
    "        raw_labels = (raw_labels - raw_labels.min())/(raw_labels.max() - raw_labels.min())\n",
    "        title = target_key\n",
    "    else:\n",
    "#     #     counts, raw_labels = np.unique(output_df.loc[:, target_key].to_numpy(), return_inverse=True)\n",
    "        raw_labels = tc_whole.loc[:, target_key].to_numpy().astype(np.float64)\n",
    "        raw_labels[raw_labels>np.percentile(raw_labels, perc)] = np.percentile(raw_labels, perc)\n",
    "#         raw_labels[raw_labels<np.percentile(raw_labels, 100-perc)] = np.percentile(raw_labels, 100-perc)\n",
    "#         raw_labels[raw_labels<0] = 0\n",
    "        title = label_dict[target_key[:-11]]\n",
    "#     print(raw_labels)\n",
    "    compiled_labels = np.expand_dims(raw_labels, axis=1)\n",
    "    \n",
    "#     compiled_labels[compiled_labels==0] = np.nan\n",
    "\n",
    "    umap_data = np.concatenate((embedded_data,compiled_labels),axis=1)\n",
    "\n",
    "    compiled_labels = compiled_labels[::interv]\n",
    "    umap_data = umap_data[::interv, :]\n",
    "\n",
    "    umap_plot = hv.Scatter(umap_data, vdims=['Dim 2', target_key], kdims=['Dim 1'])\n",
    "    umap_plot.opts(color=target_key, colorbar=False, cmap='Spectral_r', size=1, tools=['hover'], clim=(-np.nanmax(compiled_labels), np.nanmax(compiled_labels)))\n",
    "    umap_plot.opts(height=600, width=800, colorbar_opts={'title': 'QI', 'title_standoff': 15}, xaxis=None, yaxis=None, title=title)\n",
    "    \n",
    "    save_name = os.path.join(save_path, '_'.join((target_document, 'TC_UMAP', target_key)) + '.png')\n",
    "    # save the figure\n",
    "    fig = fp.save_figure(umap_plot, save_name, fig_width=7.7, dpi=1200, fontsize=target_document, target='save', display_factor=0.1)\n",
    "\n",
    "    umap_list.append(umap_plot)\n",
    "\n",
    "# hv.Layout(umap_list).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78726549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array. From https://neuroplausible.com/gini\"\"\"\n",
    "    # All values are treated equally, arrays must be 1d:\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        # Values cannot be negative:\n",
    "        array -= np.amin(array)\n",
    "    # Values cannot be 0:\n",
    "    array += 0.0000001\n",
    "    # Values must be sorted:\n",
    "    array = np.sort(array)\n",
    "    # Index per array element:\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    # Number of array elements:\n",
    "    n = array.shape[0]\n",
    "    # Gini coefficient:\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ae8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini2(array, bins=30):\n",
    "    \"\"\"Calculate the Gini coefficient according to de Oliveira and Kim et al.\"\"\"\n",
    "    # bin the data\n",
    "    counts, bin_edges, _ = stat.binned_statistic(np.abs(array), array, bins=bins, statistic='count')\n",
    "    \n",
    "    # get the fractions\n",
    "    fractions = counts/counts.sum()\n",
    "    # multiply by the counts\n",
    "    values = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "    s = np.cumsum(fractions * values)\n",
    "    s0 = np.concatenate(([0], s[:-1]), axis=0)\n",
    "\n",
    "    # calculate the coefficient\n",
    "    gini_coefficient = 1 - np.sum(fractions*(s0 + s))/s[-1]\n",
    "    \n",
    "    return gini_coefficient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot Gini coefficient\n",
    "\n",
    "# allocate memory for the calculation\n",
    "gini_array = []\n",
    "# for all the variables\n",
    "for animal_date, current_day in tc_whole.groupby(['animal', 'day'], as_index=False):\n",
    "    # allocate memory for the day\n",
    "    day_list = []\n",
    "    # for all the features\n",
    "    for feature in variable_list:\n",
    "        # get the feature\n",
    "        current_feat = current_day[feature+'_Qual_index'].to_numpy()\n",
    "        # calculate the gini coefficient and store\n",
    "        current_gini = gini2(current_feat, bins=20)\n",
    "        day_list.append(pd.DataFrame([[label_dict[feature], current_gini]], columns=['Feature', 'Gini']))\n",
    "        \n",
    "    # store\n",
    "    gini_array.append(pd.concat(day_list, axis=0))\n",
    "    \n",
    "gini_array = pd.concat(gini_array, axis=0)\n",
    "print(gini_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# calculate the Gini coefficient based on resampled weights\n",
    "\n",
    "# define the number of shuffles\n",
    "number_shuffles = 100\n",
    "# allocate a list for the output\n",
    "shuffle_gini = []\n",
    "# for all the shuffles\n",
    "for shuff in np.arange(number_shuffles):\n",
    "\n",
    "    # for all the variables\n",
    "    for animal_date, current_day in tc_whole.groupby(['animal', 'day'], as_index=False):\n",
    "        # allocate memory for the day\n",
    "        day_list = []\n",
    "        # for all the features\n",
    "        for feature in variable_list:\n",
    "            # get the feature\n",
    "            current_feat = current_day[feature+'_Qual_index'].to_numpy().astype(np.float64)\n",
    "            # draw randomly from the feature\n",
    "#             current_feat = np.random.choice(current_feat, current_feat.shape[0], replace=True)\n",
    "#             current_feat = np.mean(current_feat)*np.ones_like(current_feat)\n",
    "#             current_feat = np.random.rand(current_feat.shape[0])\n",
    "            a = np.min(current_feat)\n",
    "            b = np.max(current_feat)\n",
    "            current_feat = (b - a) * np.random.random_sample(current_feat.shape[0]) + a\n",
    "#             print(current_feat)\n",
    "\n",
    "            # calculate the gini coefficient and store\n",
    "            current_gini = gini2(current_feat, bins=20)\n",
    "\n",
    "            day_list.append(pd.DataFrame([[label_dict[feature], current_gini]], columns=['Feature', 'Gini']))\n",
    "\n",
    "        # store\n",
    "        shuffle_gini.append(pd.concat(day_list, axis=0))\n",
    "# concatenate the dataframes\n",
    "shuffle_gini = pd.concat(shuffle_gini, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77123f",
   "metadata": {},
   "source": [
    "# TC Gini plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c450b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the gini coefficients\n",
    "\n",
    "importlib.reload(fp)\n",
    "# print(plot_array.columns)\n",
    "# print(plot_array)\n",
    "\n",
    "# print(plot_array)\n",
    "# ticks = [(idx+0.5, label_dict[el]) for idx, el in enumerate(variable_list)]\n",
    "\n",
    "whisker0 = hv.BoxWhisker(gini_array, ['Feature'], ['Gini'])\n",
    "whisker0.opts(width=1500, height=600, xrotation=45, ylabel='Sparsity', xlabel='')\n",
    "\n",
    "whisker1 = hv.BoxWhisker(shuffle_gini, ['Feature'], ['Gini'])\n",
    "\n",
    "whisker = (whisker0*whisker1).opts(opts.BoxWhisker(box_line_width=1, whisker_line_width=1, outlier_line_width=1))\n",
    "# assemble the file name\n",
    "save_name = os.path.join(save_path, '_'.join((target_document, 'TC_gini')) + '.png')\n",
    "# save the figure\n",
    "fig = fp.save_figure(whisker, save_name, fig_width=10, dpi=1200, fontsize='small', target='save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61fded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantify non-linearity of the mixed selectivity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prey_capture] *",
   "language": "python",
   "name": "conda-env-.conda-prey_capture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
