{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdba192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture'))\n",
    "\n",
    "import functions_plotting as fp\n",
    "import functions_loaders as fl\n",
    "import paths\n",
    "import processing_parameters\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PSID\n",
    "from PSID.evaluation import evalPrediction\n",
    "import scipy.signal as signal\n",
    "import sklearn.preprocessing as preproc\n",
    "import sklearn.cross_decomposition as cross\n",
    "import umap\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a19817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the figure config\n",
    "importlib.reload(fp)\n",
    "importlib.reload(processing_parameters)\n",
    "# define the target saving path\n",
    "save_path = os.path.join(paths.figures_path, 'PSID_vis')\n",
    "\n",
    "# define the printing mode\n",
    "save_mode = True\n",
    "# define the target document\n",
    "target_document = 'paper'\n",
    "# set up the figure theme\n",
    "fp.set_theme()\n",
    "# load the label dict\n",
    "label_dict = processing_parameters.label_dictionary\n",
    "variable_list = processing_parameters.variable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1715b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "importlib.reload(processing_parameters)\n",
    "importlib.reload(fl)\n",
    "\n",
    "# get the paths from the database using search_list\n",
    "all_paths, all_queries = fl.query_search_list()\n",
    "# print(all_paths)\n",
    "\n",
    "data_list = []\n",
    "# load the data\n",
    "for path, queries in zip(all_paths, all_queries):\n",
    "    \n",
    "    data, _, _  = fl.load_preprocessing(path, queries)\n",
    "    data_list.append(data)\n",
    "\n",
    "# print(all_paths)\n",
    "print(f'Number of trials: {len(data_list)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad751d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target trials to evaluate\n",
    "test_trials = np.arange(57, 67)\n",
    "\n",
    "print(test_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run PSID on the data\n",
    "\n",
    "# define the test/train percentage\n",
    "test_perc = 0.3\n",
    "\n",
    "# get the unique dates and mice\n",
    "unique_dates_mice = np.unique([(el.loc[0, 'datetime'][:10], el.loc[0, 'mouse']) for el in data_list[0]], axis=0)\n",
    "\n",
    "# allocate a list to store the psid objects\n",
    "psid_list = []\n",
    "\n",
    "# for all the pairs\n",
    "for pair in unique_dates_mice:\n",
    "    # get the relevant trials\n",
    "    # target_trials = [el for el in data_list[0] if (target_day in el.loc[0, 'datetime']) & (target_mouse in el.loc[0, 'mouse'])]\n",
    "    target_trials = [el for el in data_list[0] if (pair[0] in el.loc[0, 'datetime']) & (pair[1] in el.loc[0, 'mouse'])]\n",
    "#     target_trials = data_list[0]\n",
    "\n",
    "    # define the target behaviors\n",
    "    target_behavior = variable_list\n",
    "\n",
    "    # allocate memory for the training and test sets\n",
    "    ca_train = []\n",
    "    ca_test = []\n",
    "    beh_train = []\n",
    "    beh_test = []\n",
    "    # for all the trials\n",
    "    for trial in target_trials:\n",
    "\n",
    "        # get the available columns\n",
    "        labels = list(trial.columns)\n",
    "        cells = [el for el in labels if 'cell' in el]\n",
    "        # get the cell data\n",
    "        calcium_data = np.array(trial[cells].copy())\n",
    "        # get rid of the super small values\n",
    "        calcium_data[np.isnan(calcium_data)] = 0\n",
    "\n",
    "        try:\n",
    "            # get the parameter\n",
    "            beh_data = trial[target_behavior].to_numpy()\n",
    "\n",
    "            # smooth the parameter\n",
    "            beh_data = signal.medfilt(beh_data, (21, 1))\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        # skip if empty\n",
    "        if (calcium_data.shape[0] == 0) | (calcium_data.shape[1] < 3):\n",
    "            continue\n",
    "\n",
    "    #     downsamp = 1\n",
    "    #     # bin the data\n",
    "    #     if downsamp > 1:\n",
    "    #         beh_data = ss.decimate(beh_data, downsamp, axis=0)\n",
    "    #         calcium_data = ss.decimate(calcium_data, downsamp, axis=0)\n",
    "\n",
    "        # get the threshold index\n",
    "        threshold_idx = int(calcium_data.shape[0]*(test_perc))\n",
    "        # split the data\n",
    "        ca_trial_train = calcium_data[threshold_idx:, :] \n",
    "        ca_trial_test = calcium_data[:threshold_idx, :] \n",
    "        beh_trial_train = beh_data[threshold_idx:, :]\n",
    "        beh_trial_test = beh_data[:threshold_idx, :] \n",
    "\n",
    "        # store the data\n",
    "        ca_train.append(ca_trial_train)\n",
    "        ca_test.append(ca_trial_test)\n",
    "        beh_train.append(beh_trial_train)\n",
    "        beh_test.append(beh_trial_test)    \n",
    "\n",
    "    # skip if empty arrays\n",
    "    if len(ca_train) == 0:\n",
    "        continue\n",
    "    # scale the data\n",
    "    # ca_scaler = preprocessing.StandardScaler().fit(np.concatenate(ca_train))\n",
    "    # beh_scaler = preprocessing.StandardScaler().fit(np.concatenate(beh_train))\n",
    "\n",
    "    # ca_train = [ca_scaler.transform(el) for el in ca_train]\n",
    "    # ca_test = [ca_scaler.transform(el) for el in ca_test]\n",
    "    # beh_train = [beh_scaler.transform(el) for el in beh_train]\n",
    "    # beh_test = [beh_scaler.transform(el) for el in beh_test]\n",
    "\n",
    "    # scale each trial separately\n",
    "    ca_scaler_list = [preproc.StandardScaler().fit(el) for el in ca_train]\n",
    "    beh_scaler_list = [preproc.StandardScaler().fit(el) for el in beh_train]\n",
    "\n",
    "    ca_train = [ca_scaler_list[idx].transform(el) for idx, el in enumerate(ca_train)]\n",
    "    ca_test = [ca_scaler_list[idx].transform(el) for idx, el in enumerate(ca_test)]\n",
    "    beh_train = [beh_scaler_list[idx].transform(el) for idx, el in enumerate(beh_train)]\n",
    "    beh_test = [beh_scaler_list[idx].transform(el) for idx, el in enumerate(beh_test)]\n",
    "\n",
    "\n",
    "    # train the PSID model\n",
    "    idSys = PSID.PSID(ca_train, beh_train, nx=20, n1=10, i=20)\n",
    "    # idSys = PSID.PSID(ca_train, beh_train, nx=1, n1=1, i=20) # for cricket distance\n",
    "    # idSys = PSID.PSID(ca_train, beh_train, nx=20, n1=10, i=35)\n",
    "    \n",
    "    # store the element\n",
    "    psid_list.append([pair, idSys, ca_scaler_list])\n",
    "\n",
    "    # allocate memory for the predictions\n",
    "    beh_pred = []\n",
    "    ca_pred = []\n",
    "    latent_pred = []\n",
    "    # predict each trial\n",
    "    for trial in ca_test:\n",
    "        beh_p, ca_p, latent_p = idSys.predict(trial)\n",
    "        beh_pred.append(beh_p)\n",
    "        ca_pred.append(ca_p)\n",
    "        latent_pred.append(latent_p)\n",
    "\n",
    "    combo_beh_test = np.vstack(beh_test)\n",
    "    combo_beh_pred = np.vstack(beh_pred)\n",
    "\n",
    "    combo_ca_test = np.vstack(ca_test)\n",
    "    combo_ca_pred = np.vstack(ca_pred)\n",
    "\n",
    "    R2TrialBased_beh = evalPrediction(combo_beh_test, combo_beh_pred, 'CC')\n",
    "    R2TrialBased_ca = evalPrediction(combo_ca_test, combo_ca_pred, 'CC')\n",
    "\n",
    "    print('Number of cells that have a larger than 0 CC:', np.sum(R2TrialBased_ca != 0))\n",
    "    print('Mean Ca CC:', np.nanmean(R2TrialBased_ca))\n",
    "    print('CC of behavior:', R2TrialBased_beh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d89fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run the model on all experiments\n",
    "\n",
    "# allocate memory for the predictions\n",
    "final_beh = []\n",
    "final_ca = []\n",
    "final_latent = []\n",
    "final_pairs = []\n",
    "final_scaled_beh = []\n",
    "# for all the pairs\n",
    "for pair in unique_dates_mice[test_trials]:\n",
    "    # get the trials\n",
    "    target_trials = [el for el in data_list[0] if (pair[0] in el.loc[0, 'datetime']) & (pair[1] in el.loc[0, 'mouse'])]\n",
    "    tag_vector = [False if (el[0][0] == pair[0]) & (el[0][1] == pair[1]) else True for el in psid_list]\n",
    "    # see if the pair was calculated\n",
    "    if all(tag_vector):\n",
    "        continue\n",
    "        \n",
    "    # get the index of the corresponding psid element\n",
    "    idx = np.argwhere(~np.array(tag_vector))[0][0]\n",
    "    \n",
    "    # get the corresponding psid element\n",
    "    idSys = psid_list[idx][1]\n",
    "    scalers = psid_list[idx][2]\n",
    "    # predict each trial\n",
    "    for trial_idx, trial in enumerate(target_trials):\n",
    "\n",
    "        # get the available columns\n",
    "        labels = list(trial.columns)\n",
    "        cells = [el for el in labels if 'cell' in el]\n",
    "        \n",
    "        # get the cell data\n",
    "        calcium_data = np.array(trial[cells].copy())\n",
    "        # skip if empty\n",
    "        if (calcium_data.shape[0] == 0) | (calcium_data.shape[1] < 3):\n",
    "            continue\n",
    "        \n",
    "        # scale the data\n",
    "        # get rid of the super small values\n",
    "        calcium_data[np.isnan(calcium_data)] = 0\n",
    "        calcium_data = scalers[trial_idx].transform(calcium_data)\n",
    "        \n",
    "        # predict and store\n",
    "        beh_p, ca_p, latent_p = idSys.predict(calcium_data)\n",
    "        final_beh.append(beh_p)\n",
    "        final_ca.append(ca_p)\n",
    "        final_latent.append(latent_p)\n",
    "        final_pairs.append(pair)\n",
    "        # get the behavior\n",
    "        final_scaled_beh.append(trial[variable_list].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the trial to plot\n",
    "layout_list = []\n",
    "\n",
    "target_trial = 15\n",
    "dim0 = 0\n",
    "dim1 = 1\n",
    "x = final_latent[target_trial][:, dim0].reshape((-1, 1))\n",
    "y = final_latent[target_trial][:, dim1].reshape((-1, 1))\n",
    "color = np.arange(x.shape[0]).reshape((-1, 1))\n",
    "plot_array = np.concatenate((x, y, color), axis=1)\n",
    "plot = hv.Scatter(plot_array, kdims=['x'], vdims=['y', 'Param'])\n",
    "plot.opts(width=700, height=600, color='Param', cmap='Spectral', size=5, colorbar=True, xlabel=f'Dim {dim0}', ylabel=f'Dim {dim1}')\n",
    "layout_list.append(plot)\n",
    "\n",
    "param0 = 'cricket_0_delta_heading'\n",
    "param1 = 'cricket_0_mouse_distance'\n",
    "param_idx0 = [idx for idx, el in enumerate(variable_list) if el == param0]\n",
    "param_idx1 = [idx for idx, el in enumerate(variable_list) if el == param1]\n",
    "x = final_scaled_beh[target_trial][:, param_idx0].reshape((-1, 1))\n",
    "y = final_scaled_beh[target_trial][:, param_idx1].reshape((-1, 1))\n",
    "color = np.arange(x.shape[0]).reshape((-1, 1))\n",
    "plot_array = np.concatenate((x, y, color), axis=1)\n",
    "plot = hv.Scatter(plot_array, kdims=['x'], vdims=['y', 'Param'])\n",
    "plot.opts(width=700, height=600, color='Param', cmap='Spectral', size=5, colorbar=True, xlabel=param0, ylabel=param1)\n",
    "layout_list.append(plot)\n",
    "\n",
    "hv.Layout(layout_list).cols(2).opts(shared_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e935d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(psid_list[0][1].__dict__.keys())\n",
    "t_trial = 67\n",
    "print(final_latent[t_trial].shape, final_ca[t_trial].shape, final_beh[t_trial].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92456918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.random.randint(0, np.size(transformed_data), np.size(transformed_data)))\n",
    "print(np.random.shuffle(np.arange(np.size(transformed_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# plot_list = []\n",
    "# # for all the models\n",
    "# for model in psid_list[:10]:\n",
    "#     # get the idsys element\n",
    "#     idsys = model[1]\n",
    "    \n",
    "#     # get the target matrix\n",
    "#     target_matrix = idsys.Cz\n",
    "    \n",
    "#     plot = hv.Raster(target_matrix)\n",
    "    \n",
    "#     plot_list.append(plot)\n",
    "# layout = hv.Layout(plot_list)\n",
    "# layout\n",
    "\n",
    "target_metric = [el[1].C for el in psid_list]\n",
    "# target_metric = [el[1].A.reshape((-1, 1)) for el in psid_list]\n",
    "# target_metric = [el.T for el in final_latent]\n",
    "\n",
    "target_metric = [preproc.StandardScaler().fit_transform(el) for el in target_metric]\n",
    "\n",
    "# target_metric = pd.DataFrame(target_metric)\n",
    "\n",
    "# define the template trial\n",
    "template_idx = 67\n",
    "print(target_metric[template_idx].shape)\n",
    "\n",
    "second_dim = target_metric[template_idx].shape[1]\n",
    "# define the number of dimensions\n",
    "dimension_number = 10\n",
    "# cca trials\n",
    "cca_list = []\n",
    "cca_score = []\n",
    "# for all the trials\n",
    "for idx, trial in enumerate(target_metric):\n",
    "# for [(day, mouse), _, _] in psid_list:\n",
    "\n",
    "#     if idx == template_trial:\n",
    "#         cca_list.append(trial)\n",
    "#         continue\n",
    "#     if trial.shape[1] < dimension_number:\n",
    "#         continue\n",
    "    template_trial = target_metric[template_idx]#[:10, :10]\n",
    "    trial = trial#[:10, :10]\n",
    "    \n",
    "#     np.random.shuffle(trial.ravel())\n",
    "#     trial = trial.reshape((-1, second_dim), order='F')\n",
    "    \n",
    "#     cca_trial = cross.CCA(n_components=dimension_number).fit(template_trial, trial)\n",
    "#     cca_score.append(cca_trial.score(template_trial, trial))\n",
    "# #     print(cca_trial.x_rotations_.shape, cca_trial.y_rotations_.shape, trial.shape)\n",
    "#     transformed_data = np.dot(np.dot(trial, cca_trial.y_rotations_), cca_trial.x_rotations_.T)\n",
    "\n",
    "    transformed_data = trial\n",
    "#     print(cca_trial[0].shape, cca_trial[1].shape)\n",
    "#     print(transformed_data.shape)\n",
    "#     raise ValueError\n",
    "    cca_list.append(transformed_data.reshape([-1, 1]))\n",
    "target_metric = cca_list\n",
    "cca_score = np.array(cca_score)\n",
    "print(transformed_data.shape)\n",
    "# target_metric = [(el - el.min(axis=0))/(el.max(axis=0) - el.min(axis=0)) for el in target_metric]\n",
    "# print([el.shape for el in target_metric])\n",
    "# target_metric[np.isnan(target_metric)] = 0\n",
    "# print(target_metric[0].min(axis=0).shape)\n",
    "# raise ValueError\n",
    "print(f'Number of trials: {len(target_metric)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, bins = np.histogram(cca_score[cca_score>0], bins=20)\n",
    "print(np.sum(cca_score>0))\n",
    "plot = hv.Bars((bins, freq))\n",
    "plot.opts(width=600, xrotation=45, tools=['hover'])\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0865841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the aligned matrices\n",
    "plotting_array = []\n",
    "\n",
    "\n",
    "# ticks = [(idx+0.5, el) for idx, el in enumerate(variable_list)]\n",
    "for trial in target_metric[:20]:\n",
    "    # get the trial shape per side\n",
    "#     square_shape = int(np.sqrt(trial.shape[0]))\n",
    "#     reshaped_matrix = trial.reshape((square_shape, square_shape), order='F')\n",
    "    reshaped_matrix = trial.reshape((-1, second_dim), order='F')\n",
    "    plot = hv.Raster(reshaped_matrix)\n",
    "    plot.opts(width=800, height=400, cmap='Spectral', tools=['hover'], xrotation=90, ylabel='', xlabel='')\n",
    "#     yticks = [(idx+0.5, f'C')]\n",
    "#     plot.opts(yticks=yticks)\n",
    "    plotting_array.append(plot)\n",
    "layout = hv.Layout(plotting_array).cols(2).opts(shared_axes=False)\n",
    "layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini2(array, bins=30):\n",
    "    \"\"\"Calculate the Gini coefficient according to de Oliveira and Kim et al.\"\"\"\n",
    "    # bin the data\n",
    "    counts, bin_edges, _ = stat.binned_statistic(np.abs(array), array, bins=bins, statistic='count')\n",
    "    \n",
    "    # get the fractions\n",
    "    fractions = counts/counts.sum()\n",
    "    # multiply by the counts\n",
    "    values = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "    s = np.cumsum(fractions * values)\n",
    "    s0 = np.concatenate(([0], s[:-1]), axis=0)\n",
    "\n",
    "    # calculate the coefficient\n",
    "    gini_coefficient = 1 - np.sum(fractions*(s0 + s))/s[-1]\n",
    "    \n",
    "    return gini_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_array = []\n",
    "# for all the trials\n",
    "for idx, trial in enumerate(target_metric):\n",
    "    gini_array.append(gini2(trial.flatten()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fde963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform UMAP\n",
    "compiled_target = np.concatenate(target_metric, axis=0)\n",
    "compiled_target[np.isnan(compiled_target)] = 0\n",
    "\n",
    "reducer1 = umap.UMAP(min_dist=0.01, n_neighbors=20)\n",
    "embedded_data1 = reducer1.fit_transform(compiled_target)\n",
    "\n",
    "print(f'Number of samples: {embedded_data1.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c825831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the trials\n",
    "umap_plot = hv.Scatter(embedded_data1, vdims=['Dim 2'], kdims=['Dim 1'])\n",
    "# umap_plot = hv.HexTiles(umap_data, kdims=['Dim 1', 'Dim 2'])\n",
    "umap_plot.opts(colorbar=True, cmap='Spectral', tools=['hover'], alpha=1)\n",
    "umap_plot.opts(width=1200, height=1000, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7bc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the latents\n",
    "\n",
    "\n",
    "compiled_latent = np.concatenate(final_latent, axis=0)\n",
    "reducer = umap.UMAP(min_dist=0.1, n_neighbors=20)\n",
    "embedded_data = reducer.fit_transform(compiled_latent[:, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the UMAP results\n",
    "\n",
    "frames = [np.arange(el.shape[0]).reshape((-1, 1)) for el in final_scaled_beh]\n",
    "trial = [np.ones((el.shape[0], 1))*idx for idx, el in enumerate(final_scaled_beh)]\n",
    "# print(frames[0].shape, trial[0].shape, final_scaled_beh[0].shape)\n",
    "\n",
    "behavior = [np.concatenate([el0, el1, el2], axis=1) for el0, el1, el2 in zip(final_scaled_beh, frames, trial)]\n",
    "\n",
    "behavior = pd.DataFrame(np.concatenate(behavior, axis=0), columns=variable_list+['time', 'trial'])\n",
    "\n",
    "\n",
    "# get the labels\n",
    "# compiled_labels = np.expand_dims(np.hstack(distance_list), axis=1)\n",
    "compiled_labels = np.expand_dims(behavior.loc[:, 'trial'].to_numpy().copy(), axis=1)\n",
    "# need to threshold, for some reason there's some weird distances\n",
    "# compiled_labels[compiled_labels>50] = 50\n",
    "# compiled_labels[compiled_labels<0] = 0\n",
    "compiled_labels = signal.medfilt(compiled_labels, kernel_size=[21, 1])\n",
    "\n",
    "# define the sampling ratio\n",
    "sampling_ratio = 10\n",
    "\n",
    "umap_data = np.concatenate((embedded_data[::sampling_ratio, :],compiled_labels[::sampling_ratio, :]), axis=1)\n",
    "\n",
    "print(umap_data.shape)\n",
    "                            \n",
    "                            \n",
    "umap_plot = hv.Scatter(umap_data, vdims=['Dim 2','parameter'], kdims=['Dim 1'])\n",
    "# umap_plot = hv.HexTiles(umap_data, kdims=['Dim 1', 'Dim 2'])\n",
    "umap_plot.opts(color='parameter', colorbar=True, cmap='Spectral', tools=['hover'], alpha=1)\n",
    "umap_plot.opts(width=1200, height=1000, size=5)\n",
    "# umap_plot.opts(width=1200, height=1000)\n",
    "umap_plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prey_capture] *",
   "language": "python",
   "name": "conda-env-.conda-prey_capture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
