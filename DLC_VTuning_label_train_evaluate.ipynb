{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282ff9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut as dlc\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# From paths.py\n",
    "import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0f2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all videos in the data directory with VTuning in the name\n",
    "all_videos = glob.glob(paths.vrexperiment_path + os.sep + \"*VTuning*.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b5fb6",
   "metadata": {},
   "source": [
    "# If Project already created, run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bdf885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config path\n",
    "config_path = paths.config_path_VTuning\n",
    "\n",
    "# Read config file\n",
    "cfg = dlc.auxiliaryfunctions.read_config(config_path)\n",
    "\n",
    "# Get project directory\n",
    "project_directory = cfg['project_path']\n",
    "\n",
    "# Get list of local videos as found in the config\n",
    "project_video_list = [vid for vid in cfg[\"video_sets\"]]\n",
    "test_video_dir = os.path.join(project_directory, \"test-videos\")\n",
    "test_vids = glob.glob(test_video_dir + os.sep + \"*VWheel*.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c8801",
   "metadata": {},
   "source": [
    "# If you haven't created a new project, run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_new_project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ed438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 15 videos to train on\n",
    "remote_video_list = []\n",
    "for i in range(20):\n",
    "    remote_video_list.append(random.choice(all_videos))\n",
    "\n",
    "dlc.create_new_project(\"VTuning\", \"Matt\", remote_video_list, working_directory=r\"D:\\DLC_projects\\vtuning_wired\", copy_videos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config and path info\n",
    "config_path = paths.config_path_VTuning\n",
    "cfg = dlc.auxiliaryfunctions.read_config(config_path)\n",
    "project_directory = cfg['project_path']\n",
    "project_video_list = [vid for vid in cfg[\"video_sets\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01645bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick videos to test the network that are not part of the training set and copy to the project directory\n",
    "test_video_dir = os.path.join(project_directory, \"test-videos\")\n",
    "if not os.path.isdir(test_video_dir):\n",
    "    os.mkdir(test_video_dir)\n",
    "\n",
    "# Randomly pick five videos outside of the training set to test the network on\n",
    "test_vids = []\n",
    "while(len(test_vids) < 5):\n",
    "    vid = random.choice(all_videos)\n",
    "    if vid not in project_video_list:\n",
    "        dest = shutil.copy2(vid, test_video_dir)\n",
    "        test_vids.append(dest)\n",
    "        \n",
    "test_vids = glob.glob(test_video_dir + os.sep + \"*VWheel*.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5351f95",
   "metadata": {},
   "source": [
    "# Add extra videos (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.add_new_videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca27ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If adding new videos, do that here by randomly selecting some not in the original data set or the test set\n",
    "# For this particular case, we want videos that are older than March 12th 2022\n",
    "from datetime import datetime\n",
    "from os.path import sep\n",
    "\n",
    "valid_extras = [vid for vid in all_videos if datetime.strptime(vid.split(sep)[-1].split('_VTuning')[0], \"%m_%d_%Y_%H_%M_%S\") > datetime(2022, 3, 12)]\n",
    "\n",
    "extra_vids = []\n",
    "while(len(extra_vids) < 5):\n",
    "    vid = random.choice(valid_extras)\n",
    "    if vid not in project_video_list or test_vids:\n",
    "        extra_vids.append(vid)\n",
    "        \n",
    "dlc.add_new_videos(config_path, extra_vids, copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacff94a",
   "metadata": {},
   "source": [
    "# Extract and label frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42484018",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.extract_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1e171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract frames from the videos\n",
    "# will go through all of the videos on the list, so if many videos, it might take a while\n",
    "dlc.extract_frames(config_path, mode='automatic', algo='kmeans', crop=False, userfeedback=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f86e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "# label frames\n",
    "# generates folders in the labeled-data folder with the video name\n",
    "dlc.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5326eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the labels\n",
    "# generates folders in the labeled-data folder with the video name but the actual labels printed on the pics\n",
    "dlc.check_labels(config_path, draw_skeleton=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e829a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_25_2022_15_16_33_VTuning_MM_220121_a_free0 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_22_2022_11_18_44_VTuning_MM_220117_a_free1 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\03_01_2022_16_06_35_VTuning_MM_220120_a_free1 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_22_2022_12_21_28_VTuning_MM_220118_a_free2 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\03_04_2022_13_28_55_VTuning_MM_220118_a_free1 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\03_02_2022_12_21_03_VTuning_MM_220118_a_free0 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_24_2022_15_42_10_VTuning_MM_220119_a_free2 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_23_2022_14_01_48_VTuning_MM_220119_a_free1 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_23_2022_13_50_10_VTuning_MM_220119_a_free0 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\03_02_2022_11_28_53_VTuning_MM_220117_a_free1 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_24_2022_13_31_10_VTuning_MM_220118_a_free2 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\03_03_2022_13_16_31_VTuning_MM_220119_a_free2 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\03_02_2022_13_58_57_VTuning_MM_220120_a_free0 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_24_2022_13_19_30_VTuning_MM_220118_a_free1 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_22_2022_14_45_34_VTuning_MM_220120_a_free1 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\02_24_2022_12_34_38_VTuning_MM_220117_a_free2 ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\04_12_2022_15_24_48_VTuning_miniscope_MM_220119_a_free1_gabor ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\04_12_2022_14_53_03_VTuning_miniscope_MM_220118_a_free2_gabor ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\04_13_2022_11_48_14_VTuning_miniscope_MM_220118_a_free1_gabor ?\n",
      "yes/noy\n",
      "Do you want to convert the csv file in folder: D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\labeled-data\\04_12_2022_16_00_04_VTuning_miniscope_MM_220120_a_free2_gabor ?\n",
      "yes/noy\n"
     ]
    }
   ],
   "source": [
    "# Used if need to |reconstruct labeling h5 files from csvs\n",
    "dlc.convertcsv2h5(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e79b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\training-datasets\\iteration-1\\UnaugmentedDataSet_VTuningApr6  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "# create the training set\n",
    "# also creates the Pose.yaml in the dlc-models/train dataset, which contains the setting for training, i.e. take a look\n",
    "dlc.create_training_dataset(config_path, augmenter_type='default');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7e870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]],\n",
      " 'all_joints_names': ['mouseSnout',\n",
      "                      'mouseBarL',\n",
      "                      'mouseBarR',\n",
      "                      'mouseBody1',\n",
      "                      'mouseBody2',\n",
      "                      'mouseBody3',\n",
      "                      'mouseBase',\n",
      "                      'miniscope',\n",
      "                      'corner_UL',\n",
      "                      'corner_UR',\n",
      "                      'corner_BR',\n",
      "                      'corner_BL'],\n",
      " 'alpha_r': 0.02,\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_VTuningApr6\\\\VTuning_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_VTuningApr6\\\\Documentation_data-VTuning_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 12,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\DLC_projects\\\\vtuning_wired\\\\VTuning-Matt-2022-04-06',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DLC_projects\\\\vtuning_wired\\\\VTuning-Matt-2022-04-06\\\\dlc-models\\\\iteration-1\\\\VTuningApr6-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Display_iters overwritten as 50000\n",
      "Save_iters overwritten as 50000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\DLC_projects\\\\vtuning_wired\\\\VTuning-Matt-2022-04-06\\\\dlc-models\\\\iteration-1\\\\VTuningApr6-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]], 'all_joints_names': ['mouseSnout', 'mouseBarL', 'mouseBarR', 'mouseBody1', 'mouseBody2', 'mouseBody3', 'mouseBase', 'miniscope', 'corner_UL', 'corner_UR', 'corner_BR', 'corner_BL'], 'alpha_r': 0.02, 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_VTuningApr6\\\\VTuning_Matt95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_VTuningApr6\\\\Documentation_data-VTuning_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 12, 'pos_dist_thresh': 17, 'project_path': 'D:\\\\DLC_projects\\\\vtuning_wired\\\\VTuning-Matt-2022-04-06', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 50000 loss: 0.0055 lr: 0.02\n",
      "iteration: 100000 loss: 0.0024 lr: 0.02\n",
      "iteration: 150000 loss: 0.0019 lr: 0.02\n",
      "iteration: 200000 loss: 0.0016 lr: 0.02\n",
      "iteration: 250000 loss: 0.0015 lr: 0.02\n",
      "iteration: 300000 loss: 0.0014 lr: 0.02\n",
      "iteration: 350000 loss: 0.0013 lr: 0.02\n",
      "iteration: 400000 loss: 0.0012 lr: 0.02\n",
      "iteration: 450000 loss: 0.0011 lr: 0.002\n",
      "iteration: 500000 loss: 0.0009 lr: 0.002\n",
      "iteration: 550000 loss: 0.0009 lr: 0.002\n",
      "iteration: 600000 loss: 0.0009 lr: 0.002\n",
      "iteration: 650000 loss: 0.0009 lr: 0.002\n",
      "iteration: 700000 loss: 0.0009 lr: 0.002\n",
      "iteration: 750000 loss: 0.0009 lr: 0.001\n",
      "iteration: 800000 loss: 0.0009 lr: 0.001\n",
      "iteration: 850000 loss: 0.0008 lr: 0.001\n",
      "iteration: 900000 loss: 0.0008 lr: 0.001\n",
      "iteration: 950000 loss: 0.0008 lr: 0.001\n",
      "iteration: 1000000 loss: 0.0008 lr: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "Caused by op 'fifo_queue_enqueue', defined at:\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3166, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-9656768b07b8>\", line 2, in <module>\n",
      "    dlc.train_network(config_path, max_snapshots_to_keep=10, displayiters=50000, saveiters=50000)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\n",
      "    allow_growth=allow_growth,\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 177, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4158, in queue_enqueue_v2\n",
      "    timeout_ms=timeout_ms, name=name)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\mmccann\\Miniconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "dlc.train_network(config_path, max_snapshots_to_keep=10, displayiters=50000, saveiters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f80ad57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]],\n",
      " 'all_joints_names': ['mouseSnout',\n",
      "                      'mouseBarL',\n",
      "                      'mouseBarR',\n",
      "                      'mouseBody1',\n",
      "                      'mouseBody2',\n",
      "                      'mouseBody3',\n",
      "                      'mouseBase',\n",
      "                      'miniscope',\n",
      "                      'corner_UL',\n",
      "                      'corner_UR',\n",
      "                      'corner_BR',\n",
      "                      'corner_BL'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_VTuningApr6\\\\VTuning_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 12,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DLC_projects\\\\vtuning_wired\\\\VTuning-Matt-2022-04-06\\\\dlc-models\\\\iteration-1\\\\VTuningApr6-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06/evaluation-results/  already exists!\n",
      "Running  DLC_resnet_50_VTuningApr6shuffle1_1030000  with # of trainingiterations: 1030000\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "509it [00:57,  8.87it/s]\n",
      "  0%|                                                                                          | 0/509 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-1030000\n",
      "Results for 1030000  training iterations: 95 1 train error: 1.97 pixels. Test error: 5.75  pixels.\n",
      "With pcutoff of 0.6  train error: 1.86 pixels. Test error: 4.6 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 509/509 [02:28<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "dlc.evaluate_network(config_path, Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6dd46b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]],\n",
      " 'all_joints_names': ['mouseSnout',\n",
      "                      'mouseBarL',\n",
      "                      'mouseBarR',\n",
      "                      'mouseBody1',\n",
      "                      'mouseBody2',\n",
      "                      'mouseBody3',\n",
      "                      'mouseBase',\n",
      "                      'miniscope',\n",
      "                      'corner_UL',\n",
      "                      'corner_UR',\n",
      "                      'corner_BR',\n",
      "                      'corner_BL'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_VTuningApr6\\\\VTuning_Matt95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\mmccann\\\\Miniconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 12,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DLC_projects\\\\vtuning_wired\\\\VTuning-Matt-2022-04-06\\\\dlc-models\\\\iteration-1\\\\VTuningApr6-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-1030000 for model D:\\DLC_projects\\vtuning_wired\\VTuning-Matt-2022-04-06\\dlc-models\\iteration-1\\VTuningApr6-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "No video(s) were found. Please check your paths and/or 'video_type'.\n",
      "No video(s) were found. Please check your paths and/or 'video_type'.\n"
     ]
    }
   ],
   "source": [
    "dlc.analyze_videos(config_path, test_video_dir)\n",
    "dlc.create_labeled_video(config_path, test_video_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract outlier frames\n",
    "# dlc.extract_outlier_frames(config_path, project_video_list, outlieralgorithm='uncertain', p_bound=0.6)\n",
    "dlc.extract_outlier_frames(config_path, project_video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef92aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataset, then move to check labels and retrain\n",
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.analyze_videos(config_path, test_vids)\n",
    "dlc.create_labeled_video(config_path, test_vids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLC-GPU] *",
   "language": "python",
   "name": "conda-env-DLC-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
