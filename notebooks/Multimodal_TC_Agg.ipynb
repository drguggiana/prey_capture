{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc22c5e-f78c-4e1d-afc8-c1b2651cbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import panel as pn\n",
    "import seaborn as sns\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import datashader as dshade\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import importlib\n",
    "import datetime\n",
    "import warnings\n",
    "import math\n",
    "import h5py\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.io import export_svgs, export_png\n",
    "from bokeh.plotting import show\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation import histogram\n",
    "from holoviews.operation.datashader import datashade, shade\n",
    "hv.extension('bokeh')\n",
    "# hv.extension('matplotlib')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "%aimport paths\n",
    "import processing_parameters\n",
    "import functions_bondjango as bd\n",
    "import functions_plotting as fp\n",
    "import functions_data_handling as fdh\n",
    "import functions_kinematic as fk\n",
    "import functions_tuning as tuning\n",
    "import functions_misc as misc\n",
    "from wirefree_experiment import WirefreeExperiment, DataContainer\n",
    "\n",
    "importlib.reload(fp)\n",
    "# set up the figure theme\n",
    "fp.set_theme()\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "cm = 1./2.54\n",
    "figure_save_path = r\"C:\\Users\\mmccann\\Dropbox\\bonhoeffer lab\\SFN 2023\\poster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ca251-a24f-40b8-8b11-ea95403aa5cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Go through all the mice and create aggregate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cda5a6-fbaa-466e-b325-a595bdbaa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(processing_parameters)\n",
    "for mouse in ['MM_221110_a', 'MM_221109_a', 'MM_220928_a', 'MM_220915_a',\n",
    "              'MM_230518_b', 'MM_230705_b', 'MM_230706_a', 'MM_230706_b']:\n",
    "    \n",
    "    # get the search string\n",
    "    search_string = f\"mouse:{mouse}, lighting:normal, analysis_type:tc_consolidate, result:repeat\"\n",
    "    parsed_search = fdh.parse_search_string(search_string)\n",
    "    \n",
    "    # get the paths from the database\n",
    "    file_infos = bd.query_database(\"analyzed_data\", search_string)\n",
    "    input_paths = np.array([el['analysis_path'] for el in file_infos if ('_tcconsolidate' in el['slug']) and\n",
    "                            (parsed_search['mouse'].lower() in el['slug'])])\n",
    "    print(np.sort(input_paths))\n",
    "    if len(input_paths) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        date_list = [os.path.basename(path)[:10] for path in input_paths]\n",
    "        mouse = parsed_search['mouse']\n",
    "        \n",
    "        # assemble the output path\n",
    "        output_path = os.path.join(paths.analysis_path, f\"AGG_{'_'.join(parsed_search.values())}.hdf5\")\n",
    "        \n",
    "        data_list = []\n",
    "        for file, date in zip(input_paths, date_list):\n",
    "            data_dict = {}\n",
    "            with pd.HDFStore(file, 'r') as tc:\n",
    "                # print(tc.keys())\n",
    "                if '/no_ROIs'in tc.keys():\n",
    "                    continue\n",
    "                else:\n",
    "                    for key in tc.keys():\n",
    "                        label = \"_\".join(key.split('/')[1:])\n",
    "                        data = tc[key]\n",
    "                        data['date'] = date\n",
    "                        data_dict[label] = data\n",
    "                        \n",
    "                    data_list.append(data_dict)\n",
    "        \n",
    "        # Aggregate it all\n",
    "        agg_dict = {}\n",
    "        \n",
    "        for key in data_list[0].keys():\n",
    "            df = pd.concat([d[key] for d in data_list]).reset_index(names='old_index')\n",
    "            agg_dict[key] = df\n",
    "            df.to_hdf(output_path, key)\n",
    "        \n",
    "        # assemble the entry data\n",
    "        entry_data = {\n",
    "            'analysis_type': 'agg_tc',\n",
    "            'analysis_path': output_path,\n",
    "            'date': '',\n",
    "            'pic_path': '',\n",
    "            'result': parsed_search['result'],\n",
    "            'rig': parsed_search['rig'],\n",
    "            'lighting': parsed_search['lighting'],\n",
    "            'imaging': 'wirefree',\n",
    "            'slug': misc.slugify(os.path.basename(output_path)[:-5]),\n",
    "        }\n",
    "        \n",
    "        # check if the entry already exists, if so, update it, otherwise, create it\n",
    "        update_url = '/'.join((paths.bondjango_url, 'analyzed_data', entry_data['slug'], ''))\n",
    "        output_entry = bd.update_entry(update_url, entry_data)\n",
    "        if output_entry.status_code == 404:\n",
    "            # build the url for creating an entry\n",
    "            create_url = '/'.join((paths.bondjango_url, 'analyzed_data', ''))\n",
    "            output_entry = bd.create_entry(create_url, entry_data)\n",
    "        \n",
    "        print('The output status was %i, reason %s' %\n",
    "              (output_entry.status_code, output_entry.reason))\n",
    "        if output_entry.status_code in [500, 400]:\n",
    "            print(entry_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc95b12-72a0-4cf3-a724-7058f205419e",
   "metadata": {},
   "source": [
    "# Load aggregate files from all mice to make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cedb80-3443-4ded-8988-edab1748be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the search string\n",
    "search_string = f\"analysis_type:agg_tc, result:multi\"\n",
    "parsed_search = fdh.parse_search_string(search_string)\n",
    "\n",
    "# get the paths from the database\n",
    "file_infos = bd.query_database(\"analyzed_data\", search_string)\n",
    "input_paths = np.array([el['analysis_path'] for el in file_infos if ('agg' in el['slug'])])\n",
    "print(np.sort(input_paths))\n",
    "\n",
    "data_list = []\n",
    "for file in input_paths:\n",
    "    data_dict = {}\n",
    "    mouse = '_'.join(os.path.basename(file).split('_')[10:13])\n",
    "    with pd.HDFStore(file, 'r') as tc:\n",
    "        for key in tc.keys():\n",
    "            label = \"_\".join(key.split('/')[1:])\n",
    "            data = tc[key]\n",
    "            data['mouse'] = mouse\n",
    "            data_dict[label] = data\n",
    "                \n",
    "        data_list.append(data_dict)\n",
    "\n",
    "# Aggregate it all\n",
    "agg_dict = {}\n",
    " \n",
    "for key in data_list[0].keys():\n",
    "    df = pd.concat([d[key] for d in data_list]).reset_index(drop=True)\n",
    "    agg_dict[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d182ed-c699-4689-973a-ede169dfaea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_nums = [len(d['cell_matches']) for d in data_list]\n",
    "plt.hist(match_nums, bins=100, edgecolor=\"black\")\n",
    "plt.title('Num. cells matched')\n",
    "plt.xlabel('Cells')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7998b36-83d3-44a3-a58c-f442700daacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-animal fraction kinematic or dir/ori responsive\n",
    "ds_name = 'VTuningWF_summary_stats'\n",
    "ds = agg_dict[ds_name]\n",
    "kinem_cols = list(ds.columns[4:-6])\n",
    "vis_cols = list(ds.columns[-6:-2])\n",
    "kinem_vis_cols = kinem_cols + vis_cols\n",
    "\n",
    "if 'VWheelWF' in ds_name:\n",
    "    rename_dict = dict(zip(kinem_vis_cols, processing_parameters.wf_fixed_kinem_cols + processing_parameters.wf_vis_cols))\n",
    "else:\n",
    "    rename_dict = dict(zip(kinem_vis_cols, processing_parameters.wf_free_kinem_cols + processing_parameters.wf_vis_cols))\n",
    "\n",
    "frac_vis_resp = ds[ds.old_index == 'all_cells'].rename(columns=rename_dict)\n",
    "\n",
    "violinplot_free = frac_vis_resp[list(rename_dict.values())].hvplot.violin(legend=False, cmap=['blue']*len(kinem_cols) +  ['red']*len(vis_cols))\n",
    "violinplot_free.opts(xlabel='', ylabel='Significant Frac.', ylim=(-0.05, 1.05), xrotation=45, width=800, height=600)\n",
    "\n",
    "save_path = os.path.join(figure_save_path, \"Fig2\", \"sig_frac_kinem_vis_free.png\")\n",
    "violinplot_free = fp.save_figure(violinplot_free, save_path=save_path, fig_width=11, dpi=1000, fontsize='poster', target='both', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e934bd-15ac-4b03-a44d-ee7ddd3061dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-animal fraction kinematic or dir/ori responsive\n",
    "ds_name = 'VWheelWF_summary_stats'\n",
    "ds = agg_dict[ds_name]\n",
    "kinem_cols = list(ds.columns[4:-6])\n",
    "vis_cols = list(ds.columns[-6:-2])\n",
    "kinem_vis_cols = kinem_cols + vis_cols\n",
    "\n",
    "if 'VWheelWF' in ds_name:\n",
    "    rename_dict = dict(zip(kinem_vis_cols, processing_parameters.wf_fixed_kinem_cols + processing_parameters.wf_vis_cols))\n",
    "else:\n",
    "    rename_dict = dict(zip(kinem_vis_cols, processing_parameters.wf_free_kinem_cols + processing_parameters.wf_vis_cols))\n",
    "\n",
    "frac_vis_resp = ds[ds.old_index == 'all_cells'].rename(columns=rename_dict)\n",
    "\n",
    "violinplot = frac_vis_resp[list(rename_dict.values())].hvplot.violin(legend=False, cmap=['blue']*len(kinem_cols) +  ['red']*len(vis_cols))\n",
    "violinplot.opts(xlabel='', ylabel='Significant Frac.', ylim=(-0.05, 1.05), xrotation=45, width=600, height=600)\n",
    "\n",
    "save_path = os.path.join(figure_save_path, \"Fig2\", \"sig_frac_kinem_vis_fixed.png\")\n",
    "violinplot = fp.save_figure(violinplot, save_path=save_path, fig_width=8, dpi=1000, fontsize='poster', target='both', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db032f7f-5013-4341-923b-e47ba7a025fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frac_tuned(df):\n",
    "    kinem_cols = list(df.columns[1:-6])\n",
    "    vis_cols = list(df.columns[-6:-2])\n",
    "    \n",
    "    df['sum_kinem'] = df[kinem_cols].sum(axis=1)\n",
    "    df['sum_vis'] = df[vis_cols].sum(axis=1)\n",
    "    df['sum_mix'] = df[['sum_kinem', 'sum_vis']].sum(axis=1)\n",
    "   \n",
    "    frac_vis_tuned = df['sum_vis'].loc[df['sum_vis'] > 0].count() / df.shape[0]\n",
    "    frac_kinem_tuned = df['sum_kinem'].loc[df['sum_kinem'] > 0].count() / df.shape[0]\n",
    "    # frac_mix_tuned = df['sum_mix'].loc[df['sum_mix'] > 0].count() / df.shape[0]\n",
    "\n",
    "    frac_only_kinem = df[(df[vis_cols].sum(axis=1) == 0) & (df[kinem_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "    frac_only_vis = df[(df[kinem_cols].sum(axis=1) == 0) & (df[vis_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "    frac_mix_tuned = df[(df[vis_cols].sum(axis=1) > 0) & (df[kinem_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "\n",
    "    return frac_only_kinem, frac_only_vis, frac_vis_tuned, frac_kinem_tuned, frac_mix_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edf58b-cf4e-410b-b28a-87ad0692987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "for ds, exp_type in zip([agg_dict['VTuningWF_multimodal_tuned'], agg_dict['VWheelWF_multimodal_tuned']], ['Freely Moving', 'Head Fixed']):\n",
    "    only_kinem = []\n",
    "    only_vis = []\n",
    "    vis_tuned = []\n",
    "    kinem_tuned = []\n",
    "    mix_tuned = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in ds.groupby('mouse'):\n",
    "        frac_only_kinem, frac_only_vis, frac_vis_tuned, frac_kinem_tuned, frac_mix_tuned = get_frac_tuned(group)\n",
    "        only_kinem.append(frac_only_kinem)\n",
    "        only_vis.append(frac_only_vis)\n",
    "        vis_tuned.append(frac_vis_tuned)\n",
    "        kinem_tuned.append(frac_kinem_tuned)\n",
    "        mix_tuned.append(frac_mix_tuned)\n",
    "\n",
    "    df['group'] = [exp_type] * len(vis_tuned)\n",
    "    df[' Visual Only'] = only_vis\n",
    "    df[' Postural Only'] = only_kinem\n",
    "    df[' Visual'] = vis_tuned\n",
    "    df[' Postural'] = kinem_tuned\n",
    "    df['Multimodal'] = mix_tuned\n",
    "    df_list.append(df)\n",
    "    plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "both = pd.concat(df_list, axis=0)\n",
    "both = pd.melt(both, id_vars=['group'], value_vars=[' Visual Only', ' Postural Only', ' Visual', ' Postural', 'Multimodal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e093530-12dc-4ebb-8f20-1ae6d769d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "violinplot = hv.Violin(both, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=400,\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"Fig2\", \"frac_multimodal.png\")\n",
    "# violinplot\n",
    "violinplot = fp.save_figure(violinplot, save_path=save_path, fig_width=17, dpi=1000, fontsize='poster', target='both', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b1ed5-be24-463c-ba6b-1976d72b8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(data=both, x=\"variable\", y=\"value\", hue=\"group\")\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.set_ylabel('Significant Frac.')\n",
    "ax.set_xlabel('')\n",
    "ax.legend(title='', loc='lower right')\n",
    "plt.savefig(os.path.join(figure_save_path, 'Fig2', 'frac_multimodal_alt.png'), dpi=1000, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b7ae6-7f3d-402c-ae7d-8c2f64afa5aa",
   "metadata": {},
   "source": [
    "# Bootstrapped tuning shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d035992-f770-4f78-9fa4-d44ff27f9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_matched_vis_tuning(ds_list, cell, tuning_kind='direction', exp_name='', error='std', norm=True, polar=True, axes=None):\n",
    "    if axes is None:\n",
    "        axes = []\n",
    "        fig = plt.figure(layout='constrained', figsize=(18*cm, 2*len(data_list)*cm))\n",
    "        fig.suptitle(f\"Cell {cell}\", fontsize='x-large')\n",
    "        subfigs = fig.subfigures(nrows=len(ds_list), ncols=1, hspace=0.07)\n",
    "    \n",
    "        for i, subfig in enumerate(subfigs):\n",
    "            subfig.suptitle(processing_parameters.wf_label_dictionary[exp_name[i]].title())\n",
    "            \n",
    "            if polar:\n",
    "                ax1 = subfig.add_subplot(121, projection=\"polar\") # direction tuning\n",
    "            else:\n",
    "                ax1 = subfig.add_subplot(121) # tuning\n",
    "                \n",
    "            ax2 = subfig.add_subplot(222) #  resp\n",
    "            ax3 = subfig.add_subplot(224) #  error\n",
    "            ax = np.array([ax1, ax2, ax3])\n",
    "            axes.append(ax)\n",
    "\n",
    "    for sub_ax, ds in zip(axes, ds_list):\n",
    "        sub_ax = fp.plot_tuning_with_stats(ds, cell, tuning_kind=tuning_kind, error=error, norm=norm, polar=polar, axes=sub_ax)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "def plot_compare_all_vis_tuning(ds_list, cell, tuning_kind=['direction', 'orientation'], exp_name='', error='std', norm=True, polar=True, axes=None):\n",
    "    if axes is None:\n",
    "        axes = []\n",
    "        fig = plt.figure(layout='constrained', figsize=(36*cm, 2*len(data_list)*cm))\n",
    "        fig.suptitle(f\"Cell {cell}\", fontsize='x-large')\n",
    "        subfigs = fig.subfigures(nrows=2, ncols=2, hspace=0.07)\n",
    "    \n",
    "        for i, subfig in enumerate(subfigs.flatten()):\n",
    "            subfig.suptitle(processing_parameters.wf_label_dictionary[exp_name[i//2]].title())\n",
    "            \n",
    "            if polar:\n",
    "                ax1 = subfig.add_subplot(121, projection=\"polar\") # tuning\n",
    "            else:\n",
    "                ax1 = subfig.add_subplot(121) # tuning\n",
    "                \n",
    "            ax2 = subfig.add_subplot(222) #  resp\n",
    "            ax3 = subfig.add_subplot(224) #  error\n",
    "            ax = np.array([ax1, ax2, ax3])\n",
    "            axes.append(ax)\n",
    "\n",
    "    tuning_kind = ['direction', 'orientation'] * 2\n",
    "    for i, (ds, sub_ax) in enumerate(zip(ds_list, axes)):\n",
    "        sub_ax = fp.plot_tuning_with_stats(ds, cell, tuning_kind=tuning_kind[i], error=error, norm=norm, polar=polar, axes=sub_ax)\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d6f44-06e3-429d-8a2a-90cbef77290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict['VTuningWF_matched_norm_spikes_viewed_direction_props'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001e280-133a-49b7-ad9c-966b989869ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_matched = ['VTuningWF_matched_norm_spikes_viewed_direction_props',\n",
    "                'VTuningWF_matched_norm_spikes_viewed_orientation_props',\n",
    "                'VTuningWF_matched_norm_spikes_viewed_still_direction_props',\n",
    "                'VTuningWF_matched_norm_spikes_viewed_still_orientation_props',]\n",
    "fixed_matched = ['VWheelWF_matched_norm_spikes_viewed_direction_props',\n",
    "                 'VWheelWF_matched_norm_spikes_viewed_orientation_props',\n",
    "                 'VWheelWF_matched_norm_spikes_viewed_still_direction_props',\n",
    "                 'VWheelWF_matched_norm_spikes_viewed_still_orientation_props',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3964bd-2600-41a4-b4b7-28669678fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_kind = 'still_orientation'\n",
    "datasets = [f'VWheelWF_matched_norm_spikes_viewed_{tuning_kind}_props', f'VTuningWF_matched_norm_spikes_viewed_{tuning_kind}_props']\n",
    "\n",
    "ref_ds = agg_dict[datasets[0]]\n",
    "strict_index = ref_ds.loc[(ref_ds.responsivity < 0.25)].index\n",
    "super_strict_index = ref_ds.loc[(ref_ds.responsivity >= 0.25) & (ref_ds.p_responsivity >= 0.95)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489028f4-5efe-40c5-a633-ec70d1908137",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_shifts = []\n",
    "\n",
    "if 'direction' in tuning_kind:\n",
    "    multiplier = 1.\n",
    "else:\n",
    "    multiplier = 2.\n",
    "\n",
    "for (idxRow, cell_fixed), (_, cell_free) in zip(agg_dict[datasets[0]].iloc[strict_index, :].iterrows(), agg_dict[datasets[1]].iloc[strict_index, :].iterrows()):\n",
    "\n",
    "    resultant_fixed = fk.wrap(cell_fixed.bootstrap_resultant[:, -1], bound=180)\n",
    "    resultant_fixed = resultant_fixed[~np.isnan(resultant_fixed)]\n",
    "    ci_fixed = st.t.interval(alpha=0.95, df=len(resultant_fixed)-1, loc=np.mean(resultant_fixed), scale=st.sem(resultant_fixed)) \n",
    "    del_ci_fixed = ci_fixed[-1] - ci_fixed[0]\n",
    "    \n",
    "    resultant_free = fk.wrap(cell_free.bootstrap_resultant[:, -1], bound=180)\n",
    "    resultant_free = resultant_free[~np.isnan(resultant_free)]\n",
    "    ci_free = st.t.interval(alpha=0.95, df=len(resultant_free)-1, loc=np.mean(resultant_free), scale=st.sem(resultant_free)) \n",
    "    del_ci_free = ci_free[-1] - ci_free[0]\n",
    "    \n",
    "    # Check if orientation tuned or not\n",
    "    if del_ci_fixed > 40:\n",
    "        # The cell is not orientation tuned\n",
    "        del_po = np.nan\n",
    "        sig_shift = 0\n",
    "    else:\n",
    "        # Get delta preferred orientation\n",
    "        po_fixed = fk.wrap(cell_fixed.resultant[-1], bound=180)\n",
    "        po_free = fk.wrap(cell_free.resultant[-1], bound=180)\n",
    "        if (np.isnan(po_fixed)) or (np.isnan(po_free)):\n",
    "            po_fixed = cell_fixed.pref\n",
    "            po_free = cell_free.pref\n",
    "        del_po = po_free - po_fixed\n",
    "        del_po_wrapped = fk.wrap(del_po, bound=180)\n",
    "    \n",
    "        # determine significance of shift\n",
    "        if ~(ci_fixed[0] <= po_free <= ci_fixed[1]) and ~(ci_free[0] <= po_fixed <= ci_free[1]):\n",
    "            # Shift is significant\n",
    "            sig_shift = 1\n",
    "        else:\n",
    "            # Shift is not significant    \n",
    "            sig_shift = 0\n",
    "    \n",
    "    tuning_shifts.append([idxRow, del_po, del_po_wrapped, sig_shift, cell_fixed.mouse, cell_fixed.date])\n",
    "\n",
    "tuning_shifts = pd.DataFrame(data=tuning_shifts, columns=['', 'delta_po', 'delta_po_wrapped', 'is_sig_po', 'mouse', 'date'])\n",
    "tuning_shifts = tuning_shifts.set_index(tuning_shifts.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee8a1a-ab41-47d3-80a3-b4909bd83dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 1.01, 0.05)\n",
    "plt.hist([agg_dict[datasets[0]].responsivity, agg_dict[datasets[1]].responsivity], bins=bins, edgecolor=\"black\")\n",
    "plt.legend(['fixed', 'free'])\n",
    "plt.axvline(0.25, c='r')\n",
    "plt.title(f'{tuning_kind} responsivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cbfba-93f2-4c0f-8d93-aebf8cb50cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_sig_po_shift_frac = tuning_shifts.is_sig_po.sum() / tuning_shifts.is_sig_po.count() \n",
    "print(overall_sig_po_shift_frac)\n",
    "tuning_shifts.groupby('mouse').apply(lambda x: x.is_sig_po.sum() / x.is_sig_po.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc698f-8b0d-41ad-aba1-edc180603cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies, edges = np.histogram(tuning_shifts[tuning_shifts.is_sig_po == 1].delta_po.to_numpy(), 36)\n",
    "hv.Histogram((edges, frequencies)).opts(width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096c76b-966e-4192-8d2d-764da3db9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tuning_shifts[tuning_shifts.is_sig_po == 1].groupby('mouse').apply(lambda x: np.histogram(x.delta_po.to_numpy(), 36)).to_list()\n",
    "layout = hv.Layout([hv.Histogram((edges, frequencies)).opts(width=400) for frequencies, edges in x]).opts(shared_axes=False)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b94bba-8eff-48d1-a7fa-76aa5516c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "datasets = ['VWheelWF_matched_norm_spikes_viewed_still_direction_props', 'VWheelWF_matched_norm_spikes_viewed_still_orientation_props',\n",
    "            'VTuningWF_matched_norm_spikes_viewed_still_direction_props', 'VTuningWF_matched_norm_spikes_viewed_still_orientation_props']\n",
    "\n",
    "matched_vis_fig = interactive(plot_compare_all_vis_tuning,\n",
    "                              ds_list=widgets.fixed([agg_dict[dataset] for dataset in datasets]),\n",
    "                              cell=tuning_shifts[tuning_shifts.is_sig_po == 1].index, \n",
    "                              tuning_kind = widgets.fixed(['direction', 'orientation']),\n",
    "                              exp_name = widgets.fixed(['VWheelWF', 'VTuningWF']),\n",
    "                              error = ['std', 'sem'],\n",
    "                              polar=[True, False],\n",
    "                              norm=widgets.fixed(True),\n",
    "                              axes=widgets.fixed(None))\n",
    "matched_vis_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5922ef-9e52-46ec-b493-ca1680323fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_shifts.loc[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eab01b-6f45-4f52-8786-2085d3c8fc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
