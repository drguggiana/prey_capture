{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:17:30.925070700Z",
     "start_time": "2023-12-05T12:17:30.905380800Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import h5py\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "\n",
    "import paths\n",
    "import functions_matching as fm\n",
    "import functions_preprocessing as fp\n",
    "import functions_wirefree_trigger_fix as wf_trig\n",
    "import snakemake_scripts.sub_preprocess_S1 as s1\n",
    "import snakemake_scripts.sub_preprocess_S2 as s2\n",
    "from functions_misc import interp_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:15:03.385482500Z",
     "start_time": "2023-12-05T12:15:03.338466100Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_selector(ref_path, file_info):\n",
    "    \"\"\"functions that selects the preprocessing function for the first step, either dlc or not\"\"\"\n",
    "    # check if the input has a dlc path or not\n",
    "    if (len(file_info['dlc_path']) > 0 and file_info['dlc_path'] != 'N/A') or \\\n",
    "            os.path.isfile(file_info['avi_path'].replace('.avi', '_dlc.h5')):\n",
    "        # assemble the path here, in case the file wasn't in the database\n",
    "        dlc_path = file_info['avi_path'].replace('.avi', '_dlc.h5')\n",
    "        # select function depending on the rig\n",
    "        if files['rig'] in ['VWheel', 'VWheelWF'] :\n",
    "            # use the eye specific function\n",
    "            traces, corner_out, frame_b = s1.run_preprocess_eye(ref_path, dlc_path, file_info)\n",
    "        else:\n",
    "            # if there's a dlc file, use this preprocessing\n",
    "            traces, corner_out, frame_b = s1.run_dlc_preprocess(ref_path, dlc_path, file_info)\n",
    "    else:\n",
    "        # if not, use the legacy non-dlc preprocessing\n",
    "        output_path, traces = s1.run_preprocess(ref_path, file_info)\n",
    "        # set corners to empty\n",
    "        corner_out = []\n",
    "        # set frame bounds to empty\n",
    "        frame_b = []\n",
    "    return traces, corner_out, frame_b\n",
    "\n",
    "\n",
    "def check_frame_code(frame_code, error_limit=5):\n",
    "    last_change = 0\n",
    "    count = 0\n",
    "    # error_start = 0\n",
    "    start_frame = 0\n",
    "    error_end = 0\n",
    "    end_frame = 0\n",
    "    error_segment = []\n",
    "\n",
    "    for idx, (frame_a, frame_b) in enumerate(zip(frame_code[:-1], frame_code[1:])):\n",
    "        idx += 1\n",
    "        count += 1\n",
    "\n",
    "        # If we are repeating, but within acceptable limits, continue\n",
    "        if (frame_b == frame_a) and (count <= error_limit):\n",
    "            # Do nothing\n",
    "            pass\n",
    "\n",
    "        # If we find a change in frame number within the acceptable repeat length, reset the count and record the last change\n",
    "        elif (frame_b != frame_a) and (count <= error_limit):\n",
    "            last_change = idx\n",
    "            count = 0\n",
    "\n",
    "        # If the frame is repeated for more than n frames, start recording the error region\n",
    "        elif (frame_b == frame_a) and (count > error_limit):\n",
    "            # Do nothing\n",
    "            pass\n",
    "\n",
    "        elif (frame_b != frame_a)  and (count > error_limit):\n",
    "            error_end = idx\n",
    "            start_frame = frame_a\n",
    "            end_frame = frame_b\n",
    "            \n",
    "            error_segment.append([last_change, start_frame, error_end, end_frame])\n",
    "            \n",
    "            count = 0\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    return np.array(error_segment)\n",
    "   \n",
    "\n",
    "def generate_trigger_sequence(start_num, max_val=3):\n",
    "    seq_list = []\n",
    "    for i in np.arange(max_val + 1):\n",
    "        if i == 0:\n",
    "            seq_list.append(start_num)\n",
    "        else:\n",
    "            if seq_list[i-1] < max_val:\n",
    "                seq_list.append(seq_list[i-1] + 1)\n",
    "            else:\n",
    "                seq_list.append(0)\n",
    "    return seq_list\n",
    "\n",
    "\n",
    "def fix_lost_sync_triggers(error_segments, trigger_code):\n",
    "    for err_seg in error_segments:\n",
    "        start_idx  = err_seg[0]\n",
    "        start_frame = err_seg[1]\n",
    "        end_idx = err_seg[2]\n",
    "        end_frame = err_seg[3]\n",
    "        length = end_idx - start_idx\n",
    "\n",
    "        r = 4    # Repeat factor (empirically determined)\n",
    "        seq = generate_trigger_sequence(start_frame)\n",
    "        repeat_seq = np.repeat(seq, r)\n",
    "\n",
    "        # Generate a vector of \"triggers\" that matches the theoretical sequence\n",
    "        replacement_seq = np.tile(repeat_seq, np.ceil(length/len(seq)/r).astype(int))[:length]\n",
    "\n",
    "        replacement_seq_end = replacement_seq[-1]\n",
    "        if replacement_seq_end in [0, 1, 2]:\n",
    "            # Consider this good\n",
    "            if (replacement_seq_end == end_frame) or (replacement_seq_end == end_frame - 1):\n",
    "                trigger_code[start_idx:end_idx] = replacement_seq\n",
    "            else:\n",
    "                # Hacky hacky\n",
    "                replacement_seq[-1:] = end_frame - 1\n",
    "                trigger_code[start_idx:end_idx] = replacement_seq\n",
    "        if replacement_seq_end == 3:\n",
    "            if (replacement_seq_end == end_frame) or (end_frame == 0):\n",
    "                trigger_code[start_idx:end_idx] = replacement_seq\n",
    "            else:\n",
    "                replacement_seq[-1:] = 0\n",
    "                trigger_code[start_idx:end_idx] = replacement_seq\n",
    "\n",
    "    return trigger_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:20:30.876059Z",
     "start_time": "2023-12-05T12:20:30.861061Z"
    }
   },
   "outputs": [],
   "source": [
    "basedir = paths.vrexperiment_path\n",
    "basename = r'01_11_2023_12_13_01_VWheelWF_MM_221109_a_fixed1_gabor'\n",
    "\n",
    "sync_path = os.path.join(basedir, basename.replace('VWheelWF', 'syncVWheelWF') + '.csv')\n",
    "track_path = os.path.join(basedir, basename + '.txt')\n",
    "tif_path = os.path.join(basedir, basename + '.tif')\n",
    "avi_path = os.path.join(basedir, basename + '.avi')\n",
    "screen_path = os.path.join(basedir, basename + '.h5')\n",
    "dlc_path = os.path.join(basedir, basename + '_dlc.h5')\n",
    "calcium_path = os.path.join(basedir, basename + '_calcium.hdf5')\n",
    "\n",
    "files = {'sync_path':sync_path,\n",
    "        'track_path': track_path,\n",
    "        'screen_path':screen_path,\n",
    "        'dlc_path':dlc_path,\n",
    "        'avi_path': avi_path,\n",
    "        'result': 'free0',\n",
    "        'rig': 'VTuningWF',\n",
    "        'imaging': 'wirefree',\n",
    "        'notes': 'gabor_crickets_0_vrcrickets_0',\n",
    "        'date': '2023-08-31T12:35:13Z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:20:44.485487600Z",
     "start_time": "2023-12-05T12:20:32.882337400Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data for the trial structure and parameters\n",
    "trials = pd.read_hdf(files['screen_path'], key='trial_set')\n",
    "params = pd.read_hdf(files['screen_path'], key='params')\n",
    "\n",
    "# get the video tracking data\n",
    "filtered_traces, px_corners, frame_bounds = preprocess_selector(files['avi_path'], files)\n",
    "\n",
    "# define the dimensions of the arena\n",
    "manual_coordinates = paths.arena_coordinates['VTuningWF']\n",
    "\n",
    "# get the motive tracking data\n",
    "motive_traces, reference_coordinates, obstacle_coordinates = \\\n",
    "    s1.extract_motive(files['track_path'], files['rig'])\n",
    "\n",
    "# scale the traces accordingly\n",
    "filtered_traces, corners = \\\n",
    "    fp.rescale_pixels(filtered_traces, files, manual_coordinates, px_corners.to_numpy().T)\n",
    "\n",
    "# align them temporally based on the sync file\n",
    "filtered_traces = fm.match_motive_2(motive_traces, files['sync_path'], filtered_traces)\n",
    "\n",
    "# run the preprocessing kinematic calculations\n",
    "# also saves the data\n",
    "kinematics_data, real_crickets, vr_crickets = s2.kinematic_calculations(filtered_traces)\n",
    "\n",
    "# get a dataframe with the calcium data matched to the bonsai data\n",
    "matched_calcium, roi_info = fm.match_calcium_wf(calcium_path, files['sync_path'], kinematics_data, trials=trials)\n",
    "_ = wf_trig.get_trial_duration_stats(matched_calcium, 'trial_num', 'time_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:03.922560200Z",
     "start_time": "2023-12-05T12:21:03.795562Z"
    }
   },
   "outputs": [],
   "source": [
    "duration_stats_motive = wf_trig.get_trial_duration_stats(motive_traces, 'trial_num', 'time_m')\n",
    "duration_stats_kinem = wf_trig.get_trial_duration_stats(kinematics_data, 'trial_num', 'time_vector')\n",
    "duration_stats_matched_ca = wf_trig.get_trial_duration_stats(matched_calcium, 'trial_num', 'time_vector')\n",
    "\n",
    "print(np.allclose(duration_stats_motive, duration_stats_kinem,  rtol=1e-1, atol=1e-2))\n",
    "print(np.allclose(duration_stats_kinem, duration_stats_matched_ca,  rtol=1e-1, atol=1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explode match_motive_2 to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematics_data = filtered_traces\n",
    "\n",
    "# find the first motive frame\n",
    "first_motive = np.argwhere(motive_traces.loc[:, 'trial_num'].to_numpy() == 0)[0][0]\n",
    "# exclude the last frame if it managed to include a single frame of 0\n",
    "last_motive = -1 if motive_traces.loc[motive_traces.shape[0] - 1, 'trial_num'] == 0 else motive_traces.shape[0]\n",
    "# trim the motive frames to the start and end of the experiment\n",
    "trimmed_traces = motive_traces.iloc[first_motive:last_motive, :].reset_index(drop=True)\n",
    "# TODO: remove this for regular trials, only here for 21.2.2022 ones\n",
    "if np.max(trimmed_traces.loc[:, 'color_factor']) > 81:\n",
    "    trimmed_traces.loc[:, 'color_factor'] = trimmed_traces.loc[:, 'color_factor'] / 255\n",
    "# normalize the number to 0 1 2 3 range\n",
    "trimmed_traces.loc[:, 'color_factor'] = np.array([int('0b' + format(int(el) - 1, '#09b')[2] +\n",
    "                                                        format(int(el) - 1, '#09b')[4], 2)\n",
    "                                                    if el > 0 else 0 for el in trimmed_traces.loc[:, 'color_factor']])\n",
    "\n",
    "# load the sync data\n",
    "sync_data = pd.read_csv(sync_path, names=['Time', 'projector_frames', 'camera_frames',\n",
    "                                            'sync_trigger', 'mini_frames', 'wheel_frames', 'projector_frames_2'],\n",
    "                        index_col=False)\n",
    "# get the camera frames (as the indexes from sync_frames are referenced for the uncut sync_data, see match_dlc)\n",
    "frame_times_cam_sync = sync_data.loc[kinematics_data['sync_frames'].to_numpy(), 'Time'].to_numpy()\n",
    "\n",
    "# get the start and end triggers\n",
    "sync_start = np.argwhere(sync_data.loc[:, 'sync_trigger'].to_numpy() == 1)[0][0] - 1\n",
    "sync_end = np.argwhere(sync_data.loc[:, 'sync_trigger'].to_numpy() == 2)[0][0]\n",
    "\n",
    "# trim the sync data to the experiment\n",
    "sync_data = sync_data.iloc[sync_start:sync_end, :].reset_index(drop=True)\n",
    "\n",
    "# get the motive frame times\n",
    "# TODO: probs remove this later, since all trials should be on the new rig with the 2bit frame encoding\n",
    "if np.any(np.isnan(sync_data['projector_frames_2'])):\n",
    "    # get the frame indexes\n",
    "    idx_code = np.argwhere(np.abs(np.diff(np.round(sync_data.loc[:, 'projector_frames'] / 4))) > 0).squeeze() + 1\n",
    "    # get the frame times\n",
    "    frame_times_motive_sync = sync_data.loc[idx_code, 'Time'].to_numpy()\n",
    "    # if the number of frames doesn't match, trim from the end\n",
    "    if trimmed_traces.shape[0] > frame_times_motive_sync.shape[0]:\n",
    "        trimmed_traces = trimmed_traces.iloc[-frame_times_motive_sync.shape[0]:, :]\n",
    "    elif trimmed_traces.shape[0] < frame_times_motive_sync.shape[0]:\n",
    "        frame_times_motive_sync = frame_times_motive_sync[-trimmed_traces.shape[0]:]\n",
    "\n",
    "else:\n",
    "    # This is all from sync file\n",
    "    # binarize both frame streams\n",
    "    frames_0 = np.round(sync_data.loc[:, 'projector_frames'] / 4).astype(int) * 2\n",
    "    frames_1 = np.round(sync_data.loc[:, 'projector_frames_2'] / 4).astype(int)\n",
    "    # assemble the actual sequence\n",
    "    frame_code = (frames_0 | frames_1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematics_data = filtered_traces\n",
    "\n",
    "# find the first motive frame\n",
    "first_motive = np.argwhere(motive_traces.loc[:, 'trial_num'].to_numpy() == 0)[0][0]\n",
    "# exclude the last frame if it managed to include a single frame of 0\n",
    "last_motive = -1 if motive_traces.loc[motive_traces.shape[0] - 1, 'trial_num'] == 0 else motive_traces.shape[0]\n",
    "# trim the motive frames to the start and end of the experiment\n",
    "trimmed_traces = motive_traces.iloc[first_motive:last_motive, :].reset_index(drop=True)\n",
    "# TODO: remove this for regular trials, only here for 21.2.2022 ones\n",
    "if np.max(trimmed_traces.loc[:, 'color_factor']) > 81:\n",
    "    trimmed_traces.loc[:, 'color_factor'] = trimmed_traces.loc[:, 'color_factor'] / 255\n",
    "# normalize the number to 0 1 2 3 range\n",
    "trimmed_traces.loc[:, 'color_factor'] = np.array([int('0b' + format(int(el) - 1, '#09b')[2] +\n",
    "                                                        format(int(el) - 1, '#09b')[4], 2)\n",
    "                                                    if el > 0 else 0 for el in trimmed_traces.loc[:, 'color_factor']])\n",
    "\n",
    "# load the sync data\n",
    "sync_data = pd.read_csv(sync_path, names=['Time', 'projector_frames', 'camera_frames',\n",
    "                                            'sync_trigger', 'mini_frames', 'wheel_frames', 'projector_frames_2'],\n",
    "                        index_col=False)\n",
    "# get the camera frames (as the indexes from sync_frames are referenced for the uncut sync_data, see match_dlc)\n",
    "frame_times_cam_sync = sync_data.loc[kinematics_data['sync_frames'].to_numpy(), 'Time'].to_numpy()\n",
    "\n",
    "# get the start and end triggers\n",
    "sync_start = np.argwhere(sync_data.loc[:, 'sync_trigger'].to_numpy() == 1)[0][0] - 1\n",
    "sync_end = np.argwhere(sync_data.loc[:, 'sync_trigger'].to_numpy() == 2)[0][0]\n",
    "\n",
    "# trim the sync data to the experiment\n",
    "sync_data = sync_data.iloc[sync_start:sync_end, :].reset_index(drop=True)\n",
    "\n",
    "# get the motive frame times\n",
    "# TODO: probs remove this later, since all trials should be on the new rig with the 2bit frame encoding\n",
    "if np.any(np.isnan(sync_data['projector_frames_2'])):\n",
    "    # get the frame indexes\n",
    "    idx_code = np.argwhere(np.abs(np.diff(np.round(sync_data.loc[:, 'projector_frames'] / 4))) > 0).squeeze() + 1\n",
    "    # get the frame times\n",
    "    frame_times_motive_sync = sync_data.loc[idx_code, 'Time'].to_numpy()\n",
    "    # if the number of frames doesn't match, trim from the end\n",
    "    if trimmed_traces.shape[0] > frame_times_motive_sync.shape[0]:\n",
    "        trimmed_traces = trimmed_traces.iloc[-frame_times_motive_sync.shape[0]:, :]\n",
    "    elif trimmed_traces.shape[0] < frame_times_motive_sync.shape[0]:\n",
    "        frame_times_motive_sync = frame_times_motive_sync[-trimmed_traces.shape[0]:]\n",
    "\n",
    "else:\n",
    "    # This is all from sync file\n",
    "    # binarize both frame streams\n",
    "    frames_0 = np.round(sync_data.loc[:, 'projector_frames'] / 4).astype(int) * 2\n",
    "    frames_1 = np.round(sync_data.loc[:, 'projector_frames_2'] / 4).astype(int)\n",
    "    # assemble the actual sequence\n",
    "    frame_code = (frames_0 | frames_1).to_numpy()\n",
    "\n",
    "    # NEED TO FIND WHERE CONSECUTIVE CODES EXCEED THRESHOLD AND FIX\n",
    "    # Found that in general, the sync frame code dwells for 3 or 4 frames per code. \n",
    "    # We can generate a sequnce bewteen the start and end codes that should somewhat match the real triggers\n",
    "    error_segments_sync = check_frame_code(frame_code, error_limit=7)\n",
    "    frame_code = fix_lost_sync_triggers(error_segments_sync, frame_code)\n",
    "    error_segments_sync_2 = check_frame_code(frame_code, error_limit=7)\n",
    "\n",
    "    # TODO: turn this into a function\n",
    "    fixed_code = frame_code.copy()\n",
    "\n",
    "    # for all the frames\n",
    "    for idx, frame in enumerate(frame_code[1:-1]):\n",
    "        idx += 1\n",
    "        # if it's the same number as before, skip\n",
    "        if frame == fixed_code[idx - 1]:\n",
    "            continue\n",
    "        # if the numbers before and after are equal\n",
    "        if fixed_code[idx - 1] == frame_code[idx + 1]:\n",
    "            # replace this position by the repeated number cause it's likely a mistake\n",
    "            fixed_code[idx] = frame_code[idx - 1]\n",
    "            continue\n",
    "        # if not, start filtering\n",
    "        # first check for 0-2, cause 3 is a special case\n",
    "        if fixed_code[idx - 1] in [0, 1, 2]:\n",
    "            if frame != fixed_code[idx - 1] + 1:\n",
    "                fixed_code[idx] = fixed_code[idx - 1] + 1\n",
    "                continue\n",
    "        else:\n",
    "            if frame != 0:\n",
    "                fixed_code[idx] = 0\n",
    "                continue\n",
    "\n",
    "    # get the motive-based frame code in sync\n",
    "    idx_code = np.argwhere(np.abs(np.diff(fixed_code)) > 0).squeeze() + 1\n",
    "    motive_code = fixed_code[idx_code]\n",
    "    # if the frame numbers don't match, find the first motive color number and match that\n",
    "    last_number = trimmed_traces.loc[trimmed_traces.shape[0] - 1, 'color_factor']\n",
    "    # trim the idx based on the last appearance of the last_number in motive_code\n",
    "    trim_idx = np.argwhere(motive_code == last_number)[-1][0] + 1\n",
    "    idx_code = idx_code[-(trimmed_traces.shape[0] + 1):trim_idx]\n",
    "    # if idx_code.shape[0] < trimmed_traces.shape[0]:\n",
    "    #\n",
    "    #     # get the difference in frames\n",
    "    #     delta_frames = trimmed_traces.shape[0] - idx_code.shape[0]\n",
    "    #     # get trimmed traces trimmed\n",
    "    #     idx_code = idx_code[delta_frames:]\n",
    "    # display_code = fixed_code[idx_code]\n",
    "    \n",
    "    # get the frame times\n",
    "    frame_times_motive_sync = sync_data.loc[idx_code, 'Time'].to_numpy()\n",
    "    \n",
    "    # trim the motive frames to be contained within the camera frames\n",
    "    if frame_times_motive_sync[0] < frame_times_cam_sync[0]:\n",
    "        start_idx = np.argwhere(frame_times_motive_sync > frame_times_cam_sync[0])[0][0]\n",
    "        frame_times_motive_sync = frame_times_motive_sync[start_idx:]\n",
    "        idx_code = idx_code[start_idx:]\n",
    "        trimmed_traces = trimmed_traces.iloc[start_idx:, :].reset_index(drop=True)\n",
    "    \n",
    "    if frame_times_motive_sync[-1] > frame_times_cam_sync[-1]:\n",
    "        end_idx = np.argwhere(frame_times_motive_sync < frame_times_cam_sync[-1])[-1][0] + 1\n",
    "        frame_times_motive_sync = frame_times_motive_sync[:end_idx]\n",
    "        idx_code = idx_code[:end_idx]\n",
    "        trimmed_traces = trimmed_traces.iloc[:end_idx, :].reset_index(drop=True)\n",
    "\n",
    "    if trimmed_traces.shape[0] > frame_times_motive_sync.shape[0]:\n",
    "        delta_frames = trimmed_traces.shape[0] - frame_times_motive_sync.shape[0]\n",
    "        trimmed_traces = trimmed_traces.iloc[delta_frames:, :].reset_index(drop=True)\n",
    "\n",
    "# interpolate the camera traces to match the unity frames\n",
    "matched_camera = kinematics_data.drop(['time_vector', 'mouse', 'datetime', 'sync_frames'],\n",
    "                                        axis=1).apply(interp_trace, raw=False, args=(frame_times_cam_sync,\n",
    "                                                                                    frame_times_motive_sync))\n",
    "\n",
    "# add the correct time vector from the interpolated traces\n",
    "matched_camera['time_vector'] = frame_times_motive_sync\n",
    "matched_camera['mouse'] = kinematics_data.loc[kinematics_data.index[0], 'mouse']\n",
    "matched_camera['datetime'] = kinematics_data.loc[kinematics_data.index[0], 'datetime']\n",
    "# correct the frame indexes to work with the untrimmed sync file\n",
    "idx_code += sync_start\n",
    "matched_camera['sync_frames'] = idx_code\n",
    "\n",
    "# concatenate both data frames\n",
    "full_dataframe = pd.concat([matched_camera, trimmed_traces.drop(['time_m', 'color_factor'], axis=1)], axis=1)\n",
    "\n",
    "# reset the time vector\n",
    "old_time = full_dataframe['time_vector']\n",
    "full_dataframe['time_vector'] = np.array([el - old_time[0] for el in old_time])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "# ax.scatter(sync_data.loc[:, 'Time'], sync_data.loc[:, 'projector_frames'])\n",
    "ax.scatter(sync_data.loc[:, 'Time'], sync_data.loc[:, 'camera_frames'])\n",
    "ax.scatter(sync_data.loc[:, 'Time'], np.round(sync_data.loc[:, 'projector_frames']/4)*4)\n",
    "ax.scatter(frame_times_motive_sync, np.ones_like(frame_times_motive_sync))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax = fig2.add_subplot(211)\n",
    "# ax.plot(np.diff(motive_traces.loc[:, 'time_m']))\n",
    "ax.plot(frame_times_motive_sync[1:], np.diff(frame_times_motive_sync))\n",
    "\n",
    "fig3 = plt.figure()\n",
    "ax = fig3.add_subplot(211)\n",
    "ax.plot(sync_data.loc[1:, 'Time'], np.diff(frame_code))\n",
    "ax.plot(sync_data.loc[1:, 'Time'], np.diff(fixed_code))\n",
    "\n",
    "fig4 = plt.figure()\n",
    "ax = fig4.add_subplot(211)\n",
    "# ax.plot(sync_data.loc[:, 'Time'], sync_data.loc[:, 'projector_frames'])\n",
    "ax.plot(sync_data.loc[:, 'Time'], sync_data.loc[:, 'sync_trigger'])\n",
    "ax.scatter(frame_times_motive_sync, np.ones_like(frame_times_motive_sync))\n",
    "\n",
    "\n",
    "fig5 = plt.figure()\n",
    "ax = fig5.add_subplot(211)\n",
    "ax.plot(trimmed_traces.loc[:, 'time_m'], trimmed_traces.loc[:, 'trial_num'])\n",
    "# ax.plot(trimmed_traces.loc[:, 'time_m'], trimmed_traces.loc[:, 'sync_trigger'])\n",
    "\n",
    "fig6 = plt.figure()\n",
    "ax = fig6.add_subplot(111)\n",
    "ax.plot(np.diff(motive_code), marker='o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematics_data = full_dataframe.copy()\n",
    "duration_stats_motive = get_trial_duration_stats(motive_traces, 'trial_num', 'time_m')\n",
    "duration_stats_kinem = get_trial_duration_stats(kinematics_data, 'trial_num', 'time_vector')\n",
    "np.allclose(duration_stats_motive, duration_stats_kinem, rtol=1e-1, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's not the kinematics matching that's throwing the error, it's `match_calcium_wf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ERROR ALSO HERE\n",
    "# THIS ONE COMES FROM THE MINISCOPE TRIGGERS FAILING (???)\n",
    "matched_calcium, roi_info = fm.match_calcium_wf(calcium_path, files['sync_path'], kinematics_data, trials=trials)\n",
    "duration_stats_matched_ca = get_trial_duration_stats(matched_calcium, 'trial_num', 'time_vector')\n",
    "\n",
    "print(duration_stats_motive)\n",
    "print(duration_stats_kinem)\n",
    "print(duration_stats_matched_ca)\n",
    "np.allclose(duration_stats_kinem, duration_stats_matched_ca,  rtol=1e-1, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explode 'match_calcium_wf' to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:25:55.864515300Z",
     "start_time": "2023-12-05T12:25:53.767826900Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the calcium data (cells x time), transpose to get time x cells\n",
    "with h5py.File(calcium_path, mode='r') as f:\n",
    "    calcium_data = np.array(f['calcium_data']).T\n",
    "    fluor_data = np.array(f['fluor_data']).T\n",
    "\n",
    "# load the sync data\n",
    "sync_data = pd.read_csv(sync_path, header=None)\n",
    "if sync_data.shape[1] == 3:\n",
    "    sync_data.columns = ['Time', 'mini_frames', 'camera_frames']\n",
    "elif sync_data.shape[1] == 6:\n",
    "    # TODO: only for files from 21.02.2022\n",
    "    sync_data.columns = ['Time', 'projector_frames', 'camera_frames',\n",
    "                            'sync_trigger', 'mini_frames', 'wheel_frames']\n",
    "else:\n",
    "    sync_data.columns = ['Time', 'projector_frames', 'camera_frames',\n",
    "                            'sync_trigger', 'mini_frames', 'wheel_frames', 'projector_frames_2']\n",
    "\n",
    "# get the camera frame times\n",
    "frame_idx_camera_sync = kinematics_data['sync_frames'].to_numpy().astype(int)\n",
    "frame_times_camera_sync = sync_data.loc[frame_idx_camera_sync, 'Time'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:25:58.834968Z",
     "start_time": "2023-12-05T12:25:57.986904800Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# Sometimes there are weird segments where the mini frame triggers aren't recorded in the middle of a session. \n",
    "# These are large gaps that are obvious\n",
    "# get the miniscope frame indexes from the sync file\n",
    "fig = plt.figure()\n",
    "mini_frame_triggers = np.round(sync_data.loc[:, 'mini_frames']).astype(int)\n",
    "plt.plot(mini_frame_triggers)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:26:04.936770400Z",
     "start_time": "2023-12-05T12:26:04.884065600Z"
    }
   },
   "outputs": [],
   "source": [
    "frame_idx_mini_sync = np.argwhere(np.diff(np.round(sync_data.loc[:, 'mini_frames'])) > 0).squeeze() + 1\n",
    "print(calcium_data.shape[0])\n",
    "print(np.sum(mini_frame_triggers > 0))\n",
    "print(frame_idx_mini_sync.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:28:29.149979900Z",
     "start_time": "2023-12-05T12:28:29.120879200Z"
    }
   },
   "outputs": [],
   "source": [
    " # get the miniscope frame indexes from the sync file\n",
    "frame_idx_mini_sync = np.argwhere(np.diff(np.round(sync_data.loc[:, 'mini_frames'])) > 0).squeeze() + 1\n",
    "frame_times_mini_sync = sync_data.loc[frame_idx_mini_sync, 'Time'].to_numpy()\n",
    "# interpolate missing triggers (based on experience)\n",
    "# frame_idx_mini_sync = np.round(interpolate_frame_triggers(frame_idx_mini_sync)).astype(int)\n",
    "# print(frame_idx_mini_sync.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:28:30.765561200Z",
     "start_time": "2023-12-05T12:28:30.734254200Z"
    }
   },
   "outputs": [],
   "source": [
    "print(frame_idx_mini_sync[0], frame_idx_mini_sync[-1])\n",
    "print(frame_idx_camera_sync[0], frame_idx_camera_sync[-1])\n",
    "print(calcium_data.shape[0])\n",
    "\n",
    "# correct for the calcium starting before and/or ending after the behavior\n",
    "if frame_idx_mini_sync[0] < frame_idx_camera_sync[0]:\n",
    "    start_idx = np.argwhere(frame_idx_mini_sync > frame_idx_camera_sync[0])[0][0]\n",
    "    print(start_idx)\n",
    "    frame_idx_mini_sync = frame_idx_mini_sync[start_idx:]\n",
    "    calcium_data = calcium_data[start_idx:, :]\n",
    "    fluor_data = fluor_data[start_idx:, :]\n",
    "\n",
    "if frame_idx_mini_sync[-1] > frame_idx_camera_sync[-1]:\n",
    "    end_idx = np.argwhere(frame_idx_mini_sync < frame_idx_camera_sync[-1])[-1][0] + 1\n",
    "    print(end_idx)\n",
    "    frame_idx_mini_sync = frame_idx_mini_sync[:end_idx]\n",
    "    calcium_data = calcium_data[:end_idx, :]\n",
    "    fluor_data = fluor_data[:end_idx, :]\n",
    "\n",
    "print(frame_idx_mini_sync[0], frame_idx_mini_sync[-1])\n",
    "print(frame_idx_camera_sync[0], frame_idx_camera_sync[-1])\n",
    "\n",
    "print(calcium_data.shape[0])\n",
    "print(frame_idx_mini_sync.shape[0])\n",
    "\n",
    "# get the delta frames with the calcium\n",
    "delta_frames = frame_idx_mini_sync.shape[0] - calcium_data.shape[0]\n",
    "\n",
    "# remove extra detections coming from terminating the calcium mid frame (I think)\n",
    "if delta_frames > 0:\n",
    "    print(f'There were {delta_frames} triggers more than frames on file {os.path.basename(calcium_path)}')\n",
    "    frame_idx_mini_sync = frame_idx_mini_sync[:-delta_frames]\n",
    "elif delta_frames < 0:\n",
    "    print(f'There were {-delta_frames} more frames than triggers on file {os.path.basename(calcium_path)}')\n",
    "    calcium_data = calcium_data[:delta_frames, :]\n",
    "    fluor_data = fluor_data[:delta_frames, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:28:32.375913400Z",
     "start_time": "2023-12-05T12:28:32.269726600Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(frame_times_mini_sync)\n",
    "plt.plot(frame_times_camera_sync)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:33:25.081257500Z",
     "start_time": "2023-12-05T12:33:24.766257600Z"
    }
   },
   "outputs": [],
   "source": [
    "# trim calcium according to the frames left within the behavior\n",
    "calcium_data = calcium_data[frame_idx_mini_sync > frame_idx_camera_sync[0], :]\n",
    "fluor_data = fluor_data[frame_idx_mini_sync > frame_idx_camera_sync[0], :]\n",
    "\n",
    "# and then remove frames before the behavior starts\n",
    "frame_idx_mini_sync = frame_idx_mini_sync[frame_idx_mini_sync > frame_idx_camera_sync[0]]\n",
    "\n",
    "# get the actual mini times\n",
    "frame_times_mini_sync = sync_data.loc[frame_idx_mini_sync, 'Time'].to_numpy()\n",
    "\n",
    "# interpolate the bonsai traces to match the mini frames\n",
    "matched_bonsai = kinematics_data.drop(['time_vector', 'sync_frames', 'mouse', 'datetime'], axis=1).apply(interp_trace, raw=False, args=(frame_times_camera_sync, frame_times_mini_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:47:50.272913800Z",
     "start_time": "2023-12-05T12:47:50.214966500Z"
    }
   },
   "outputs": [],
   "source": [
    "if trials is not None:\n",
    "\n",
    "    # repair the trial_num column\n",
    "    trial_nums = matched_bonsai.trial_num\n",
    "    real_trials = np.concatenate([[0], trials.index + 1])\n",
    "    incorrect_trial_assignments = ~np.isin(matched_bonsai.loc[:, 'trial_num'], real_trials)\n",
    "    incorrect_trial_idxs = matched_bonsai.index[incorrect_trial_assignments]\n",
    "    \n",
    "    # Check preceding or following frames for the correct trial number\n",
    "    for idx in incorrect_trial_idxs:\n",
    "        trial_val = matched_bonsai.loc[idx, 'trial_num']\n",
    "        rounded_trial = np.round(trial_val)\n",
    "        prec_trial = matched_bonsai.loc[idx - 1, 'trial_num']\n",
    "        next_trial = matched_bonsai.loc[idx + 1, 'trial_num']\n",
    "        \n",
    "        if (rounded_trial == prec_trial) and (next_trial == 0):\n",
    "            matched_bonsai.loc[idx, 'trial_num'] = prec_trial\n",
    "        elif (rounded_trial == next_trial) and (prec_trial == 0):\n",
    "            matched_bonsai.loc[idx, 'trial_num'] = next_trial\n",
    "        elif (rounded_trial == prec_trial) and (rounded_trial == next_trial):\n",
    "            matched_bonsai.loc[idx, 'trial_num'] = prec_trial\n",
    "        else:\n",
    "            matched_bonsai.loc[idx, 'trial_num'] = 0\n",
    "    \n",
    "    matched_bonsai.loc[:, 'trial_num'] = np.round(matched_bonsai.loc[:, 'trial_num'])\n",
    "\n",
    "    # find indexes for each trial number > 0. If there are some that aren't consecutive, fix them\n",
    "    # Seems to be the case the sometimes the transition is split across two frames\n",
    "    for trial in matched_bonsai.trial_num.unique():\n",
    "        indexes = matched_bonsai.index[matched_bonsai.trial_num == trial]\n",
    "        if np.any(np.diff(indexes) != 1):\n",
    "            where_bad = np.argwhere(np.diff(indexes) > 1).squeeze() + 1\n",
    "            matched_bonsai.loc[indexes[where_bad], 'trial_num'] = 0\n",
    "\n",
    "    # # now that the trials are reassigned, add the trial data\n",
    "    matched_bonsai = fm.assign_trial_parameters(matched_bonsai, trials)\n",
    "\n",
    "else:\n",
    "    # round the quadrant vector as it should be discrete\n",
    "    quadrant_columns = [el for el in matched_bonsai.columns if ('_quadrant' in el)]\n",
    "\n",
    "    for el in quadrant_columns:\n",
    "        matched_bonsai[el] = np.round(matched_bonsai[el])\n",
    "\n",
    "    # same for the hunt trace\n",
    "    if 'hunt_trace' in matched_bonsai.columns:\n",
    "        matched_bonsai.loc[:, 'hunt_trace'] = np.round(matched_bonsai.loc[:, 'hunt_trace'])\n",
    "\n",
    "# add the correct time vector from the interpolated traces, plus mouse and datetime\n",
    "matched_bonsai['time_vector'] = frame_times_mini_sync\n",
    "matched_bonsai['mouse'] = kinematics_data.loc[0, 'mouse']\n",
    "matched_bonsai['datetime'] = kinematics_data.loc[0, 'datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = matched_bonsai.trial_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:45:35.518027800Z",
     "start_time": "2023-12-05T12:45:35.419029800Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(matched_bonsai.time_vector, matched_bonsai.trial_num)\n",
    "plt.plot(matched_bonsai.time_vector, matched_bonsai.trial_num == 5)\n",
    "plt.plot(matched_bonsai.time_vector, matched_bonsai.trial_num == 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a single dataframe with the calcium matched positions and timestamps\n",
    "cell_column_names = ['_'.join(('cell', f'{el:04d}', 'spikes')) for el in range(calcium_data.shape[1])]\n",
    "calcium_dataframe = pd.DataFrame(calcium_data, columns=cell_column_names)\n",
    "cell_column_names = [col.replace('spikes', 'fluor') for col in cell_column_names]\n",
    "fluorescence_dataframe = pd.DataFrame(fluor_data, columns=cell_column_names)\n",
    "# concatenate both data frames\n",
    "full_dataframe = pd.concat([matched_bonsai, calcium_dataframe, fluorescence_dataframe], axis=1)\n",
    "\n",
    "# reset the time vector\n",
    "old_time = full_dataframe['time_vector']\n",
    "full_dataframe.loc[:, 'time_vector'] = np.array([el - old_time[0] for el in old_time])\n",
    "\n",
    "# turn the roi info into a dataframe\n",
    "roi_info = pd.DataFrame(roi_info, columns=['centroid_x', 'centroid_y',\n",
    "                                            'bbox_left', 'bbox_top', 'bbox_width', 'bbox_height', 'area'])\n",
    "\n",
    "full_dataframe = full_dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(full_dataframe.trial_num == 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_stats_full = wf_trig.get_trial_duration_stats(full_dataframe, 'trial_num', 'time_vector')\n",
    "\n",
    "print(duration_stats_motive)\n",
    "print(duration_stats_kinem)\n",
    "print(duration_stats_full)\n",
    "np.allclose(duration_stats_kinem, duration_stats_full,  rtol=1e-1, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_trials = full_dataframe.loc[full_dataframe['trial_num'] != 0]\n",
    "grouped_trials = grouped_trials.groupby('trial_num')\n",
    "trial_durations = grouped_trials.apply(lambda x: x['time_vector'].to_list()[-1] - x['time_vector'].to_list()[0])\n",
    "# print(trial_durations.min(), trial_durations.max(), trial_durations.mean())\n",
    "trial_range = grouped_trials.apply(lambda x: (x['time_vector'].to_list()[0], x['time_vector'].to_list()[-1]))\n",
    "trial_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tiff and extract triggers to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:24:12.771253100Z",
     "start_time": "2023-12-05T12:24:12.737255800Z"
    }
   },
   "outputs": [],
   "source": [
    "from functions_wirefree_trigger_fix import extract_timestamp, correct_timestamp_jumps, update_sync_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:24:41.420346400Z",
     "start_time": "2023-12-05T12:24:14.513783500Z"
    }
   },
   "outputs": [],
   "source": [
    "stack = io.imread(tif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.array([extract_timestamp(el)/1000 for el in stack])\n",
    "corrected_timestamps , idxs, _= correct_timestamp_jumps(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:25:20.166095700Z",
     "start_time": "2023-12-05T12:25:20.015440Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(timestamps)\n",
    "plt.plot(corrected_timestamps)\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('Timestamp (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_data_original = pd.read_csv(sync_path.replace('.csv', '_original.csv'), header=None)\n",
    "sync_data_original.columns = ['Time', 'projector_frames', 'camera_frames',\n",
    "                             'sync_trigger', 'mini_frames', 'wheel_frames', 'projector_frames_2']\n",
    "\n",
    "sync_data = pd.read_csv(sync_path, header=None)\n",
    "sync_data.columns = ['Time', 'projector_frames', 'camera_frames',\n",
    "                             'sync_trigger', 'mini_frames', 'wheel_frames', 'projector_frames_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(np.round(sync_data_original.mini_frames))\n",
    "plt.plot(np.round(sync_data.mini_frames))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:25:25.386242900Z",
     "start_time": "2023-12-05T12:25:25.355623300Z"
    }
   },
   "outputs": [],
   "source": [
    "# There are still these little mistakes throughout that cause timing errors down the line. \n",
    "# Let's try to fix them by interpolating the timestamps\n",
    "slope, intercept = np.polyfit(np.arange(len(corrected_timestamps)-1), corrected_timestamps[:-1], deg=1)\n",
    "regressed_timestamps = np.arange(len(corrected_timestamps)) * slope + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:25:26.833523500Z",
     "start_time": "2023-12-05T12:25:26.747354300Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(timestamps, marker='.')\n",
    "plt.plot(corrected_timestamps, marker='.')\n",
    "plt.plot(regressed_timestamps, marker='.')\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('Timestamp (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(corrected_timestamps - regressed_timestamps)\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('Timestamp (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:25:36.025748600Z",
     "start_time": "2023-12-05T12:25:35.995207900Z"
    }
   },
   "outputs": [],
   "source": [
    "interp_idxs = np.argwhere(np.abs(corrected_timestamps - regressed_timestamps) > 0.05).squeeze()\n",
    "corrected_timestamps[interp_idxs] = regressed_timestamps[interp_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T12:25:36.350254200Z",
     "start_time": "2023-12-05T12:25:36.282290200Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(timestamps)\n",
    "plt.plot(corrected_timestamps)\n",
    "plt.plot(regressed_timestamps)\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('Timestamp (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_sync_file(corrected_timestamps, sync_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use snakemake to get a sense of how many experiments are affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_data_handling as fdh\n",
    "import functions_bondjango as bd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = [# 'MM_221110_a', 'MM_221109_a', 'MM_220928_a', 'MM_220915_a', 'MM_230518_b', 'MM_230705_b', \n",
    "       'MM_230706_a', 'MM_230706_b']\n",
    "\n",
    "rigs = ['VTuningWF', 'VWheelWF']\n",
    "\n",
    "num_files = 0\n",
    "affected_files = 0\n",
    "\n",
    "for mouse in mice:\n",
    "    for rig in rigs:\n",
    "        # get the search string\n",
    "        search_string = f\"mouse:{mouse}, rig:{rig}\"\n",
    "        parsed_search = fdh.parse_search_string(search_string)\n",
    "        \n",
    "        # get the paths from the database\n",
    "        file_infos = bd.query_database(\"vr_experiment\", search_string)\n",
    "        \n",
    "        for file_info in tqdm(file_infos):\n",
    "            num_files += 1\n",
    "            tif_path = file_info['tif_path']\n",
    "            sync_path = file_info['sync_path']\n",
    "            \n",
    "            # Load tif and check for timestamp weirdness\n",
    "            stack = io.imread(tif_path)\n",
    "            timestamps = np.array([extract_timestamp(el)/1000 for el in stack])\n",
    "            corrected_timestamps , idxs, _= correct_shifted_timestamps(timestamps)\n",
    "\n",
    "            if len(idxs) > 0:\n",
    "                affected_files += 1\n",
    "                \n",
    "print(f'Fraction of files affected: {affected_files / num_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prey_capture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
