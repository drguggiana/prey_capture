{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new VAME project\n",
    "import vame\n",
    "import functions_bondjango as bd\n",
    "import functions_vame as fv\n",
    "import paths\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import h5py\n",
    "import numpy as np\n",
    "import importlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define the config path if project has already been created\n",
    "# config = r\"D:\\VAME_projects\\VAME_prey_6-Apr28-2021\\config.yaml\"\n",
    "# config = r\"D:\\VAME_projects\\VAME_prey_7-Apr29-2021\\config.yaml\"\n",
    "# config = r\"D:\\VAME_projects\\VAME_prey_15dim-May2-2021\\config.yaml\"\n",
    "# config = r\"D:\\VAME_projects\\VAME_prey_mouse15dim-May14-2021\\config.yaml\"\n",
    "config = r\"D:\\VAME_projects\\VAME_prey_15dim-May17-2021\\config.yaml\"\n",
    "# config = r\"D:\\VAME_projects\\VAME_prey_mouse15dim-Oct12-2021\\config.yaml\"\n",
    "# config = r\"D:\\VAME_projects\\VAME_prey_mouse15dim-Oct25-2021\\config.yaml\"\n",
    "# config = r\"D:\\VAME_projects\\VAME_prey_speeds15dim-Jun27-2022\\config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vame.motif_videos(config)\n",
    "vame.motif_videos(config, videoType='.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(bd)\n",
    "\n",
    "# # target_string = 'mouse:DG_210323_b'\n",
    "# target_string = 'slug:dg_210323_b'\n",
    "# # target_string = 'slug:05_31_2021_10_44_32_miniscope_dg_210323_b_succ_head'\n",
    "\n",
    "# # target_model = 'video_experiment'\n",
    "# target_model = 'analyzed_data'\n",
    "\n",
    "# # results = bd.query_database(target_model, target_string)\n",
    "# results = bd.delete_multiple(target_model, target_string)\n",
    "\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get the file paths\n",
    "\n",
    "# define the number of files to use\n",
    "number_files = 750\n",
    "# define the search string\n",
    "search_string = ['rig:miniscope, result:succ', 'rig:miniscope, result:fail']\n",
    "# search_string = ['rig:miniscope']\n",
    "# search_string = ['slug:06_02_2021_09_33_34_miniscope_dg_210323_b_succ_head']\n",
    "\n",
    "# define the target model\n",
    "target_model = 'video_experiment'\n",
    "\n",
    "# define the columns to check for nans\n",
    "nan_columns = [0, 2, 4, 6, 8, 10, 12, 14]\n",
    "\n",
    "# allocate memory for the files\n",
    "files = []\n",
    "\n",
    "# for all the queries\n",
    "for query in search_string:\n",
    "    # get the queryset\n",
    "    files.append(bd.query_database(target_model, query))\n",
    "\n",
    "# concatenate the list\n",
    "files_list = [item for sublist in files for item in sublist]\n",
    "print(len(files_list))\n",
    "\n",
    "# allocate memory for the cleaned up files and analysis paths\n",
    "files = []\n",
    "analysis_paths = []\n",
    "# set the columns flag\n",
    "column_flag = True\n",
    "# get rid of the files that are too short for pose segmentation\n",
    "# for all the files\n",
    "for el in files_list:\n",
    "    # get the path to the analyzed data file\n",
    "    dlc_path = el['avi_path']\n",
    "    dlc_path = dlc_path.replace('.avi', '_rawcoord.hdf5')\n",
    "    dlc_path = dlc_path.replace('VideoExperiment', 'AnalyzedData')\n",
    "    dlc_path = dlc_path.replace('VRExperiment', 'AnalyzedData')\n",
    "    # open the file using h5py, as can't install pytables in this env\n",
    "    with h5py.File(dlc_path, 'r') as f:\n",
    "        # check if it's a bad file\n",
    "        first_string = np.array(f['full_traces/block0_items']).astype(str)[0]\n",
    "        if first_string == 'badFile':\n",
    "            continue\n",
    "        # parse the bounds from the file\n",
    "        bounds = np.array(f['frame_bounds/block0_values'])[0]\n",
    "        # get also the rest of the data to check for nans\n",
    "        try:\n",
    "            data = np.array(f['matched_calcium/block0_values'])\n",
    "        except KeyError:\n",
    "            data = np.array(f['full_traces/block0_values'])\n",
    "#         print(data.columns)\n",
    "#         raise ValueError\n",
    "        try:\n",
    "            column_sum = any(np.sum(np.isnan(data[:, nan_columns]), axis=0)==data.shape[0])\n",
    "        except IndexError:\n",
    "            print(data)\n",
    "            print(dlc_path)\n",
    "            print(f['full_traces/block0_values'])\n",
    "            print(f['full_traces/block0_items'])\n",
    "            print(np.array(f['full_traces/block0_items']).astype(str))\n",
    "            raise ValueError\n",
    "        if column_sum == 1:\n",
    "            print(f'The file {dlc_path} has only nans in the behavior')\n",
    "        # if it's the first iteration and a success, get the column names\n",
    "        if (column_flag) & ('succ' in dlc_path):\n",
    "            # get the column names\n",
    "            columns_all = np.array(f['full_traces/block0_items']).astype(str)\n",
    "            # select the columns with mouse and x or y on them\n",
    "            column_list = [el for el in columns_all if (('x' in el) or ('y' in el))]\n",
    "#             column_list = [el for el in column_list if 'mouse' in el]\n",
    "            # set the flag to off\n",
    "            column_flag = False\n",
    "#         values = np.array(f['frame_bounds/block0_values'])[0]\n",
    "#         labels = np.array(f['frame_bounds/block0_items']).astype(str)\n",
    "#         bounds = pd.DataFrame(values.reshape([1, 3]), columns=labels)\n",
    "        # add the file to the final list only if it's long enough\n",
    "#         if (bounds.loc[0, 'end'] - bounds.loc[0, 'start']) > 50:\n",
    "        if ((bounds[1] - bounds[0]) > 50) & (column_sum == 0):\n",
    "            files.append(el)\n",
    "            analysis_paths.append(dlc_path)\n",
    "\n",
    "if number_files > 0:\n",
    "    # pick a random subset of number_files\n",
    "    random_indexes = random.sample(range(len(files)), number_files)\n",
    "    files = [files[el] for el in random_indexes]\n",
    "    analysis_paths = [analysis_paths[el] for el in random_indexes]\n",
    "\n",
    "# get the video paths in a list\n",
    "video_paths = [el['avi_path'] for el in files]\n",
    "\n",
    "# define the working directory\n",
    "working_directory = paths.vame_path\n",
    "print(len(video_paths))\n",
    "print(len(analysis_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# initialize the project\n",
    "config = vame.init_new_project(project='VAME_prey_speeds15dim', \n",
    "                               videos=video_paths, working_directory=working_directory, videotype='.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test alignment function\n",
    "# # define the target example file\n",
    "# example_file = r\"J:\\Drago Guggiana Nilo\\Prey_capture\\AnalyzedData\\03_29_2021_09_17_07_miniscope_DG_210202_a_succ_preproc.hdf5\"\n",
    "\n",
    "# with h5py.File(example_file, 'r') as f:\n",
    "#     # parse the bounds from the file\n",
    "#     try:\n",
    "#         data = np.array(f['matched_calcium/block0_values'])\n",
    "#         labels = np.array(f['matched_calcium/block0_items']).astype(str)\n",
    "#     except KeyError:\n",
    "#         data = np.array(f['full_traces/block0_values'])\n",
    "#         labels = np.array(f['full_traces/block0_items']).astype(str)\n",
    "\n",
    "#     dataframe = pd.DataFrame(data, columns=labels)\n",
    "# #     filename = el['slug']\n",
    "#     filename = os.path.splitext(os.path.basename(example_file))[0]\n",
    "#         # define the cropping\n",
    "# #     crop_size = (1, 1)\n",
    "# #     # egocentrically align the data and save\n",
    "# #     fv.run_alignment(dlc_path, project_folder, '.avi', crop_size)\n",
    "# # get the egocentrically aligned coordinates\n",
    "# aligned_traj, frames = vame.egocentric_alignment(config, pose_ref_index=[0, 7], crop_size=(200, 200), \n",
    "#                                                  use_video=False, video_format='.avi', \n",
    "#                                                  check_video=False, save_flag=False, \n",
    "#                                                  filename=[filename], column_list=column_list,\n",
    "#                                                  dataframe=[dataframe], \n",
    "#                                                  extra_columns=['mouse_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# importlib.reload(vame)\n",
    "# Align video trajectories\n",
    "# get the project folder\n",
    "project_folder, _ = os.path.split(config)\n",
    "# get the columns to use (only mouse in this case)\n",
    "\n",
    "\n",
    "# for all the videos\n",
    "for idx, el in enumerate(files):\n",
    "    print(f'Current file: {el[\"slug\"]}')\n",
    "    \n",
    "#     # if there is no preprocessing file, skip and warn\n",
    "#     if len(el['preproc_files']) == 0:\n",
    "#         print('no preprocessing file found')\n",
    "#         continue\n",
    "#     # load the avi file path\n",
    "#     dlc_path = el['avi_path']\n",
    "#     # edit it for the preprocessing path\n",
    "#     dlc_path = dlc_path.replace('.avi', '_preproc.hdf5')\n",
    "#     dlc_path = dlc_path.replace('VideoExperiment', 'AnalyzedData')\n",
    "#     dlc_path = dlc_path.replace('VRExperiment', 'AnalyzedData')\n",
    "    # get the path from the list calculated above\n",
    "    # dlc_path = analysis_paths[idx]\n",
    "    with h5py.File(analysis_paths[idx], 'r') as f:\n",
    "        # parse the bounds from the file\n",
    "        try:\n",
    "            data = np.array(f['matched_calcium/block0_values'])\n",
    "            labels = np.array(f['matched_calcium/block0_items']).astype(str)\n",
    "        except KeyError:\n",
    "            data = np.array(f['full_traces/block0_values'])\n",
    "            labels = np.array(f['full_traces/block0_items']).astype(str)\n",
    "        \n",
    "        dataframe = pd.DataFrame(data, columns=labels)\n",
    "        filename = el['slug']\n",
    "        # define the cropping\n",
    "#     crop_size = (1, 1)\n",
    "#     # egocentrically align the data and save\n",
    "#     fv.run_alignment(dlc_path, project_folder, '.avi', crop_size)\n",
    "    # get the egocentrically aligned coordinates\n",
    "    aligned_traj, frames = vame.egocentric_alignment(config, pose_ref_index=[0, 7], crop_size=(200, 200), \n",
    "                                                     use_video=False, video_format='.avi', \n",
    "                                                     check_video=False, save_flag=True, \n",
    "                                                     filename=[filename], column_list=column_list,\n",
    "                                                     dataframe=[dataframe], \n",
    "                                                     extra_columns=['mouse_speed', 'cricket_0_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create the training set\n",
    "\n",
    "vame.create_trainset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(vame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "\n",
    "# remember to set the parameters in the config.yaml\n",
    "\n",
    "vame.train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the network\n",
    "\n",
    "vame.evaluate_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Segment behavior\n",
    "\n",
    "# vame.behavior_segmentation(config, model_name='VAME_prey_model', cluster_method='kmeans', n_cluster=[30])\n",
    "vame.pose_segmentation(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embedding\n",
    "# vame.visualization(config, label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create motif videos\n",
    "# vame.motif_videos(config, videoType='.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community analysis\n",
    "\n",
    "# vame.community(config, show_umap=False, cut_tree=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify behavior\n",
    "\n",
    "# vame.behavior_quantification(config, model_name='VAME_prey_model', cluster_method='kmeans', n_cluster=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-VAME]",
   "language": "python",
   "name": "conda-env-.conda-VAME-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
