{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20f4a83",
   "metadata": {},
   "source": [
    "# Visualize motif sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e30f34",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"param.Dimension\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.ParameterizedMetaclass\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.SpreadPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.CurvePlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.AdjointLayout\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.HoloMap\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.OverlayPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.BarPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.ErrorPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.RasterPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.Layout\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.PointPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.DynamicMap\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.Callable\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.Image\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.Overlay\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.Scatter\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.LayoutPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.Curve\").setLevel(logging.CRITICAL)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture'))\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')\n",
    "from bokeh.resources import INLINE\n",
    "\n",
    "import paths\n",
    "import functions_bondjango as bd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functions_plotting as fplot\n",
    "import functions_preprocessing as fp\n",
    "import functions_data_handling as fd\n",
    "from scipy.stats import sem\n",
    "import sklearn.decomposition as decomp\n",
    "import umap\n",
    "import sklearn.mixture as mix\n",
    "from scipy.stats import sem\n",
    "import importlib\n",
    "import processing_parameters\n",
    "import cv2\n",
    "import pickle as pk\n",
    "import functions_vame as fv\n",
    "import functions_io as fi\n",
    "\n",
    "from pprint import pprint as pp"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c54b83",
   "metadata": {},
   "source": [
    "# Get the path to the involved files\n",
    "importlib.reload(processing_parameters)\n",
    "\n",
    "# define the type of VAME\n",
    "vame_type = 'prey_speeds_15'\n",
    "# define the number of frames to remove at beginning and end (due to VAME interval)\n",
    "vame_interval = 15\n",
    "# define the folder\n",
    "target_folder = os.path.join(r'J:\\Drago Guggiana Nilo\\Prey_capture\\temp_VAME', vame_type)\n",
    "\n",
    "# # load the sorting\n",
    "# motif_sort = np.array(processing_parameters.motif_sort)\n",
    "# motif_revsort = np.array(processing_parameters.motif_revsort)\n",
    "\n",
    "# get a list of the result folders\n",
    "result_list = os.listdir(os.path.join(target_folder,'results'))\n",
    "# load the search string\n",
    "vame_vis_string = processing_parameters.vame_vis_string\n",
    "\n",
    "# Load the matching prey capture data\n",
    "\n",
    "# using the slug, perform serial calls to the database\n",
    "# (super inefficient, but this is temporary as the VAME data should be includedin the hdf5 file)\n",
    "\n",
    "# for all the files\n",
    "\n",
    "# define the search string\n",
    "# query the database for data to plot\n",
    "data_all = bd.query_database('analyzed_data', vame_vis_string)\n",
    "data_path = data_all[0]['analysis_path']\n",
    "data_vame_name = data_all[0]['slug'].replace('_preprocessing', '')\n",
    "\n",
    "# load the data\n",
    "beh_data = pd.read_hdf(data_path, 'full_traces')\n",
    "beh_data = beh_data.iloc[vame_interval:-vame_interval, :].reset_index(drop=True)\n",
    "# load the frame bounds\n",
    "frame_bounds = pd.read_hdf(data_path, 'frame_bounds')\n",
    "# get the reference corners\n",
    "ref_corners = paths.arena_coordinates['miniscope']\n",
    "\n",
    "# load the latent and labels\n",
    "label_list = motif_revsort[np.load(os.path.join(target_folder,'results',data_vame_name,'VAME',\n",
    "                                  'kmeans-15','15_km_label_'+data_vame_name+'.npy'))]\n",
    "              \n",
    "latent_list = np.load(os.path.join(target_folder,'results',data_vame_name,'VAME',\n",
    "                                   'kmeans-15','latent_vector_'+data_vame_name+'.npy')) \n",
    "               \n",
    "\n",
    "# load the aligned data\n",
    "data_list = np.load(os.path.join(target_folder,'data',data_vame_name,\n",
    "                                 data_vame_name+'-PE-seq.npy'))\n",
    "data_list = data_list[:, vame_interval:-vame_interval]\n",
    "print(beh_data.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5df39b",
   "metadata": {},
   "source": [
    "# get the dlc coordinates\n",
    "likelihood_threshold = 0.8\n",
    "file_path_dlc = os.path.join(paths.videoexperiment_path,\n",
    "                                    data_all[0]['slug'].replace('_preprocessing', '_dlc.h5'))\n",
    "# load the bonsai info\n",
    "raw_h5 = pd.read_hdf(file_path_dlc)\n",
    "# get the column names\n",
    "column_names = raw_h5.columns\n",
    "\n",
    "# DLC in small arena\n",
    "filtered_traces = pd.DataFrame(raw_h5[[\n",
    "    [el for el in column_names if ('mouseSnout' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('mouseSnout' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('mouseBarL' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('mouseBarL' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('mouseBarR' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('mouseBarR' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('mouseHead' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('mouseHead' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody1' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody1' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody2' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody2' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody3' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody3' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('mouseBase' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('mouseBase' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('cricketHead' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('cricketHead' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('cricketBody' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('cricketBody' in el) and ('y' in el)][0],\n",
    "]].to_numpy(), columns=['mouse_snout_x', 'mouse_snout_y', 'mouse_barl_x', 'mouse_barl_y',\n",
    "                        'mouse_barr_x', 'mouse_barr_y', 'mouse_head_x', 'mouse_head_y',\n",
    "                        'mouse_x', 'mouse_y', 'mouse_body2_x', 'mouse_body2_y',\n",
    "                        'mouse_body3_x', 'mouse_body3_y', 'mouse_base_x', 'mouse_base_y',\n",
    "                        'cricket_0_head_x', 'cricket_0_head_y', 'cricket_0_x', 'cricket_0_y'])\n",
    "\n",
    "# get the likelihoods\n",
    "likelihood_frame = pd.DataFrame(raw_h5[[\n",
    "    [el for el in column_names if ('mouseSnout' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('mouseBarL' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('mouseBarR' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('mouseHead' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody1' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody2' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('mouseBody3' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('mouseBase' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('cricketHead' in el) and ('likelihood' in el)][0],\n",
    "    [el for el in column_names if ('cricketBody' in el) and ('likelihood' in el)][0],\n",
    "]].to_numpy(), columns=['mouse_snout', 'mouse_barl', 'mouse_barr', 'mouse_head', 'mouse', 'mouse_body2',\n",
    "                        'mouse_body3', 'mouse_base',\n",
    "                        'cricket_0_head', 'cricket_0'])\n",
    "\n",
    "# nan the trace where the likelihood is too low\n",
    "# for all the columns\n",
    "for col in likelihood_frame.columns:\n",
    "    # get the vector for nans\n",
    "    nan_vector = likelihood_frame[col] < likelihood_threshold\n",
    "    # nan the points\n",
    "    filtered_traces.loc[nan_vector, col+'_x'] = np.nan\n",
    "    filtered_traces.loc[nan_vector, col+'_y'] = np.nan\n",
    "        \n",
    "corner_info = pd.DataFrame(raw_h5[[\n",
    "    [el for el in column_names if ('corner_UL' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('corner_UL' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('corner_BL' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('corner_BL' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('corner_BR' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('corner_BR' in el) and ('y' in el)][0],\n",
    "    [el for el in column_names if ('corner_UR' in el) and ('x' in el)][0],\n",
    "    [el for el in column_names if ('corner_UR' in el) and ('y' in el)][0],\n",
    "]].to_numpy(), columns=['corner_UL_x', 'corner_UL_y', 'corner_BL_x', 'corner_BL_y',\n",
    "                        'corner_BR_x', 'corner_BR_y', 'corner_UR_x', 'corner_UR_y'])\n",
    "# get the corners\n",
    "corner_points = fp.process_corners(corner_info)\n",
    "\n",
    "# trim to the current bounds\n",
    "filtered_traces = \\\n",
    "    filtered_traces.iloc[frame_bounds.loc[0, 'start']:frame_bounds.loc[0, 'end']-1, :].reset_index(drop=True)\n",
    "\n",
    "filtered_traces = filtered_traces.iloc[vame_interval:-vame_interval, :].reset_index(drop=True)\n",
    "print(filtered_traces.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e34a49",
   "metadata": {},
   "source": [
    "%%time\n",
    "# get the video\n",
    "# assemble the path\n",
    "video_path = os.path.join(paths.videoexperiment_path,\n",
    "                          data_all[0]['slug'].replace('_preprocessing', '.avi'))\n",
    "# create the video object\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# allocate memory for the corners\n",
    "frame_list = []\n",
    "# # define sigma for the edge detection parameters\n",
    "# sigma = 0.2\n",
    "# get the frames to mode\n",
    "for frames in np.arange(frame_bounds.loc[0, 'end']-1):\n",
    "\n",
    "    # read the image\n",
    "    frame_list.append(cap.read()[1])\n",
    "\n",
    "# release the capture\n",
    "cap.release()\n",
    "\n",
    "frame_list = frame_list[frame_bounds.loc[0, 'start']:]\n",
    "# keep this for the motif videos\n",
    "frames_formotif = frame_list.copy()\n",
    "# trim to interval\n",
    "frame_list = frame_list[vame_interval:-vame_interval]\n",
    "print(len(frame_list))\n",
    "print(frame_list[0].shape)\n",
    "print(latent_list.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ef3eb",
   "metadata": {},
   "source": [
    "%%time\n",
    "# get the UMAP embedding\n",
    "embedded_data = np.load(os.path.join(target_folder, 'UMAP_result.npy'))\n",
    "\n",
    "# generate the model name\n",
    "model_name = os.path.join(target_folder, 'UMAP_model.pk')\n",
    "with open(model_name, 'rb') as file:\n",
    "    reducer = pk.load(file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7f2df",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Embed the current data\n",
    "current_data = reducer.transform(latent_list)\n",
    "print(current_data.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f962e7",
   "metadata": {},
   "source": [
    "# generate an animation showing the frame in the video next to the umap position of the pose\n",
    "\n",
    "# define the indexes\n",
    "cols_x = [el for el in beh_data.columns if (('mouse' in el) and ('_x' in el))]\n",
    "cols_y = [el for el in beh_data.columns if (('mouse' in el) and ('_y' in el))]\n",
    "cols_cricket_x = [el for el in beh_data.columns if (('cricket' in el) and ('_x' in el))]\n",
    "cols_cricket_y = [el for el in beh_data.columns if (('cricket' in el) and ('_y' in el))]\n",
    "\n",
    "index_x = [0, 2, 4, 6, 8, 10, 12, 14]\n",
    "index_y = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "cricket_idx_x = [16, 18]\n",
    "cricket_idx_y = [17, 19]\n",
    "\n",
    "def frame_plot(time):\n",
    "    \n",
    "    current_frame = frame_list[time]\n",
    "    return hv.Image(current_frame).opts(\n",
    "        invert_yaxis=True, invert_xaxis=True, cmap='Gray')#, width=600, height=600)\n",
    "\n",
    "def umap_trajectory(time):\n",
    "    current_points = current_data[:time, :]\n",
    "    return hv.Scatter((current_points[:, 0], current_points[:, 1]))\n",
    "def umap_current(time):\n",
    "    current_point = current_data[time, :]\n",
    "    return hv.Scatter((current_point[0], current_point[1])).opts(color='red')\n",
    "\n",
    "def skeleton(time):\n",
    "    current_skeleton_x = beh_data.loc[time, cols_x].to_numpy()/40 - 0.5\n",
    "    current_skeleton_y = beh_data.loc[time, cols_y].to_numpy()/40 - 0.5\n",
    "    \n",
    "#     current_skeleton_x = (filtered_traces.loc[time, index_x].to_numpy()/1200) - 0.5\n",
    "#     current_skeleton_y = 1-(filtered_traces.loc[time, index_y].to_numpy()/1200) - 0.5\n",
    "    \n",
    "    return hv.Curve((current_skeleton_x, current_skeleton_y))\n",
    "\n",
    "def cricket_skeleton(time):\n",
    "    current_cricket_x = beh_data.loc[time, cols_cricket_x].to_numpy()/40 - 0.5\n",
    "    current_cricket_y = beh_data.loc[time, cols_cricket_y].to_numpy()/40 - 0.5\n",
    "    return hv.Curve((current_cricket_x, current_cricket_y))\n",
    "\n",
    "def motif(time):\n",
    "    current_motif = label_list[:time]\n",
    "    return hv.Curve(current_motif)\n",
    "\n",
    "def static_pose(time):\n",
    "    current_pose_x = data_list[index_x, time].T\n",
    "    current_pose_y = data_list[index_y, time].T\n",
    "    return hv.Curve((current_pose_x, current_pose_y))\n",
    "\n",
    "def static_cricket(time):\n",
    "    cricket_pose_x = data_list[cricket_idx_x, time].T\n",
    "    cricket_pose_y = data_list[cricket_idx_y, time].T\n",
    "    return hv.Curve((cricket_pose_x, cricket_pose_y))\n",
    "\n",
    "frame_map = hv.DynamicMap(frame_plot, kdims=['time'])\n",
    "umap_map = hv.DynamicMap(umap_trajectory, kdims=['time']).opts(xlim=(-10, 30), ylim=(-10, 30))\n",
    "current_map = hv.DynamicMap(umap_current, kdims=['time']).opts(xlim=(-10, 30), ylim=(-10, 30))\n",
    "skeleton_map = hv.DynamicMap(skeleton, kdims=['time'])\n",
    "c_skeleton_map = hv.DynamicMap(cricket_skeleton, kdims=['time'])\n",
    "motif_map = hv.DynamicMap(motif, kdims=['time']).opts(ylim=(-1, 31), xlim=(0, 200))\n",
    "pose_map = hv.DynamicMap(static_pose, kdims=['time']).opts(xlim=(-40, 40), ylim=(-40, 40))\n",
    "c_pose_map = hv.DynamicMap(static_cricket, kdims=['time'])\n",
    "\n",
    "# umap_base = hv.Scatter(embedded_data)\n",
    "\n",
    "# both_map = (frame_map).opts(width=600, height=400)\n",
    "# sub_map = (umap_map*current_map+motif_map).opts(shared_axes=False)\n",
    "# both_map = (frame_map*skeleton_map+sub_map).opts(\n",
    "#     width=1000, height=800, shared_axes=False).cols(1)\n",
    "both_map = (frame_map*skeleton_map*c_skeleton_map+umap_map*current_map+motif_map+pose_map*c_pose_map)\n",
    "both_map.opts(width=1000, height=800, shared_axes=False).cols(2)\n",
    "        \n",
    "both_panel = pn.panel(both_map.redim.range(time=(0, len(frame_list)-1)), \n",
    "                      center=True, widget_location='top')\n",
    "both_panel\n",
    "#     current_coord = current_data[time, :]\n",
    "    \n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e2bde",
   "metadata": {},
   "source": [
    "# Get the motif locations\n",
    "\n",
    "# get the motif number\n",
    "motif_number = latent_list.shape[1]\n",
    "# turn the movie into an array\n",
    "movie_array = np.array(frame_list)\n",
    "# allocate memory for all the locations\n",
    "location_perfile = []\n",
    "duration_perfile = []\n",
    "# for all the motifs\n",
    "for motif in np.arange(motif_number):\n",
    "\n",
    "    # find all the starts and ends for this motif\n",
    "    m_idx = (label_list==motif).astype(int)\n",
    "    starts = np.argwhere(np.diff(np.pad(m_idx, (1, 1), mode='constant', constant_values=(0, 0)))==1)\n",
    "    ends = np.argwhere(np.diff(np.pad(m_idx, (1, 1), mode='constant', constant_values=(0, 0)))==-1)\n",
    "\n",
    "    # skip if any of the arrays is empty\n",
    "    if (starts.shape[0] == 0) or (ends.shape[0] == 0):\n",
    "        duration_perfile.append(np.empty((0, 1)))\n",
    "        location_perfile.append(np.empty((0, 1)))\n",
    "        continue\n",
    "    # trim the starts and ends based on ordering\n",
    "    if starts[0] > ends[0]:\n",
    "        if ends.shape[0] > 1:\n",
    "            ends = ends[1:]\n",
    "        else:\n",
    "            duration_perfile.append(np.empty((0, 1)))\n",
    "            location_perfile.append(np.empty((0, 1)))\n",
    "            continue\n",
    "    if starts[-1] > ends [-1]:\n",
    "        if starts.shape[0] > 1:\n",
    "            starts = starts[:-1]\n",
    "        else:\n",
    "            duration_perfile.append(np.empty((0, 1))) \n",
    "            location_perfile.append(np.empty((0, 1)))\n",
    "            continue\n",
    "    # trim the starts or ends depending on size\n",
    "    if starts.shape[0] > ends.shape[0]:\n",
    "        starts = starts[:-1]\n",
    "    if ends.shape[0] > starts.shape[0]:\n",
    "        ends = ends[1:]\n",
    "    # make sure the ends are always bigger than the starts\n",
    "    try: \n",
    "        assert np.all((ends-starts)>0) \n",
    "    except AssertionError:\n",
    "        print(str(idx)+'_'+str(motif))\n",
    "        print(starts)\n",
    "        print(ends)\n",
    "\n",
    "    # save the locations for this motif\n",
    "    location_perfile.append([el[0] for el in starts])\n",
    "    duration_perfile.append([el[0] for el in ends-starts])\n",
    "        \n",
    "print(location_perfile[0])\n",
    "# print(duration_perfile[0])\n",
    "print(label_list)\n",
    "# print(location_perfile)\n",
    "# print(duration_perfile)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2989b",
   "metadata": {},
   "source": [
    "# Get the snippets for a single motif\n",
    "\n",
    "# define the target motif\n",
    "target_motif = 7\n",
    "\n",
    "# allocate a list for the frames\n",
    "video_frames = []\n",
    "indexes = []\n",
    "\n",
    "# for all instances of the motif\n",
    "for idx, instances in enumerate(location_perfile[target_motif]):\n",
    "\n",
    "    # get the indexes\n",
    "    instance_idx = np.array(np.arange(instances, instances+duration_perfile[target_motif][idx]))\n",
    "    \n",
    "    # get the video frames\n",
    "    video_frames.append(movie_array[instance_idx])\n",
    "    indexes.append(instance_idx)\n",
    "\n",
    "# plot\n",
    "video_frames = np.concatenate(video_frames, axis=0)\n",
    "indexes = np.concatenate(indexes, axis=0)\n",
    "\n",
    "# create the function for the dynamic map\n",
    "def show_frame(time):\n",
    "    current_frame = video_frames[time]\n",
    "    return hv.Image(current_frame).opts(invert_yaxis=True, invert_xaxis=True, cmap='Gray')\n",
    "def skeleton(time):\n",
    "    current_skeleton_x = beh_data.loc[indexes[time], cols_x].to_numpy()/40 - 0.5\n",
    "    current_skeleton_y = beh_data.loc[indexes[time], cols_y].to_numpy()/40 - 0.5\n",
    "    return hv.Curve((current_skeleton_x, current_skeleton_y))\n",
    "\n",
    "def cricket_skeleton(time):\n",
    "    current_cricket_x = beh_data.loc[indexes[time], cols_cricket_x].to_numpy()/40 - 0.5\n",
    "    current_cricket_y = beh_data.loc[indexes[time], cols_cricket_y].to_numpy()/40 - 0.5\n",
    "    return hv.Curve((current_cricket_x, current_cricket_y))\n",
    "\n",
    "# create the dynamic map\n",
    "frame_map = hv.DynamicMap(show_frame, kdims=['time'])\n",
    "skeleton_map = hv.DynamicMap(skeleton, kdims=['time'])\n",
    "c_skeleton_map = hv.DynamicMap(cricket_skeleton, kdims=['time'])\n",
    "\n",
    "both_map = (frame_map*skeleton_map*c_skeleton_map).opts(width=800, height=600, shared_axes=False)\n",
    "        \n",
    "both_panel = pn.panel(both_map.redim.range(time=(0, len(video_frames)-1)), \n",
    "                      center=True, widget_location='top')\n",
    "both_panel\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b781521",
   "metadata": {},
   "source": [
    "# create a distortion corrected video\n",
    "\n",
    "# define the path for saving the movies\n",
    "temp_path = paths.temp_path\n",
    "# clean the folder\n",
    "fi.delete_contents(temp_path)\n",
    "\n",
    "# create a bounded movie to align later\n",
    "# assemble the bounded movie path\n",
    "bounded_path = os.path.join(temp_path, 'bounded.avi')\n",
    "# new_mat = cv2.UMat(rot_matrix)\n",
    "\n",
    "# save the bounded movie\n",
    "# get the width and height\n",
    "width = frame_list[0].shape[1]\n",
    "height = frame_list[0].shape[0]\n",
    "\n",
    "# test = cv2.warpPerspective(frames_formotif[0].astype('float32'), rot_matrix.to_numpy(), (width, height))\n",
    "# current_matrix = rot_matrix.to_numpy()\n",
    "\n",
    "perspective_matrix = cv2.getPerspectiveTransform(corner_points.astype('float32'),\n",
    "                                                 (np.array(ref_corners).astype('float32')+5)*20)\n",
    "\n",
    "# create the writer\n",
    "out = cv2.VideoWriter(bounded_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (1280, 1024))\n",
    "# save the movie\n",
    "for frames in frame_list:\n",
    "    # apply the perspective matrix\n",
    "    out_frame = cv2.warpPerspective(frames.astype('float32'), perspective_matrix, (1280, 1024))\n",
    "    out.write(out_frame.astype('uint8'))\n",
    "\n",
    "out.release()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826f96f",
   "metadata": {},
   "source": [
    "# Align the video egocentrically\n",
    "importlib.reload(fv)\n",
    "\n",
    "# create the egocentric movie\n",
    "path_dlc = data_path\n",
    "path_vame = target_folder\n",
    "file_format = '.avi'\n",
    "crop_size = (200, 200)\n",
    "use_video = True\n",
    "check_video = False\n",
    "save_align = False\n",
    "\n",
    "scaled_data = (beh_data+5)*20\n",
    "print(scaled_data.shape)\n",
    "\n",
    "_, egocentric_frames = fv.align_demo(scaled_data, path_vame, data_vame_name, file_format, crop_size,\n",
    "                                   use_video=use_video, check_video=check_video, \n",
    "                                   vid_path=bounded_path)\n",
    "\n",
    "# turn the list into an array\n",
    "egocentric_frames = np.array(egocentric_frames)\n",
    "print(egocentric_frames.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3cf841",
   "metadata": {},
   "source": [
    "# create the egocentric movie\n",
    "\n",
    "# assemble the bounded movie path\n",
    "egocentric_path = os.path.join(temp_path, 'egocentric.avi')\n",
    "\n",
    "# save the bounded movie\n",
    "# get the width and height\n",
    "width = egocentric_frames[0].shape[1]\n",
    "height = egocentric_frames[0].shape[0]\n",
    "print(egocentric_frames[0].shape)\n",
    "# hv.Image(video_frames[10]).opts(tools=['hover'])\n",
    "\n",
    "# def egocentric_function(time):\n",
    "#     return hv.Image(video_frames[time]).opts(invert_yaxis=True, invert_xaxis=True, cmap='Gray')\n",
    "\n",
    "# egocentric_map = hv.DynamicMap(egocentric_function, kdims=['time'])\n",
    "\n",
    "# map_out = pn.panel(egocentric_map.redim.range(time=(0, len(video_frames)-1)), \n",
    "#                       center=True, widget_location='top')\n",
    "# map_out\n",
    "# print(video_frames[2].shape)\n",
    "\n",
    "# create the writer\n",
    "out2 = cv2.VideoWriter(egocentric_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (height, width))\n",
    "# save the movie\n",
    "for frames in egocentric_frames:\n",
    "    out_frame = np.repeat(np.expand_dims(frames, 2), 3, axis=2)\n",
    "    out2.write(out_frame.astype('uint8'))\n",
    "\n",
    "out2.release()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cad0d",
   "metadata": {},
   "source": [
    "# Create egocentric movies for all motifs\n",
    "\n",
    "# get the motifs present\n",
    "present_motifs = np.unique(label_list)\n",
    "# for all the motifs present\n",
    "for current_motif in present_motifs:\n",
    "    # get the maximum duration\n",
    "    max_duration = np.max(duration_perfile[current_motif])\n",
    "    # get the start of the maximum duration\n",
    "    max_location = location_perfile[current_motif][np.argmax(duration_perfile[current_motif])]\n",
    "\n",
    "    # get the video frames\n",
    "    frame_idx = np.array(np.arange(max_location, max_location+max_duration))\n",
    "    motif_frames = egocentric_frames[frame_idx]\n",
    "    # save the movie\n",
    "    \n",
    "    # assemble the bounded movie path\n",
    "    motif_path = os.path.join(temp_path, str(current_motif)+'_motif.avi')\n",
    "    # create the writer\n",
    "    out2 = cv2.VideoWriter(motif_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (200,200))\n",
    "    # save the movie\n",
    "    for frames in motif_frames:\n",
    "        out_frame = np.repeat(np.expand_dims(frames, 2), 3, axis=2)\n",
    "        out2.write(out_frame.astype('uint8'))\n",
    "\n",
    "    out2.release()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prey_capture] *",
   "language": "python",
   "name": "conda-env-.conda-prey_capture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
