{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import paths\n",
    "import processing_parameters\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functions_bondjango as bd\n",
    "import functions_loaders as fl\n",
    "import functions_io as fi\n",
    "import functions_vame as fv\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the preproc files\n",
    "\n",
    "importlib.reload(processing_parameters)\n",
    "importlib.reload(fl)\n",
    "\n",
    "# get the paths from the database using search_list\n",
    "data_all = bd.query_database('analyzed_data', processing_parameters.vame_video)\n",
    "data_all = [el for el in data_all if '_preproc' in el['slug']][0]\n",
    "data_path = data_all['analysis_path']\n",
    "data_vame_name = data_all['slug'].replace('_preprocessing', '')\n",
    "\n",
    "\n",
    "data, _, meta_list  = fl.load_preprocessing([data_path], [data_all], behavior_flag=True)\n",
    "data = data[0]\n",
    "meta_list = meta_list[0]\n",
    "\n",
    "real_corners = pd.read_hdf(data_path, 'arena_corners')\n",
    "dlc_corners = pd.read_hdf(data_path, 'corners')\n",
    "frame_bounds = pd.read_hdf(data_path, 'frame_bounds')\n",
    "\n",
    "print(frame_bounds, meta_list, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load the corresponding video\n",
    "\n",
    "# assemble the path\n",
    "video_path = os.path.join(paths.videoexperiment_path,\n",
    "                          data_all['slug'].replace('_preprocessing', '.avi'))\n",
    "print(video_path)\n",
    "# create the video object\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# allocate memory for the corners\n",
    "frame_list = []\n",
    "# # define sigma for the edge detection parameters\n",
    "# sigma = 0.2\n",
    "# get the frames to mode\n",
    "for frames in np.arange(frame_bounds.loc[0, 'end']):\n",
    "\n",
    "    # read the image\n",
    "    frame_list.append(cap.read()[1])\n",
    "\n",
    "# release the capture\n",
    "cap.release()\n",
    "frame_list = frame_list[frame_bounds.loc[0, 'start']:]\n",
    "\n",
    "print(f'Frames after trimming bounds: {len(frame_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a distortion corrected video\n",
    "\n",
    "# define the path for saving the movies\n",
    "temp_path = paths.temp_path\n",
    "# clean the folder\n",
    "fi.delete_contents(temp_path)\n",
    "\n",
    "# get the reference corners \n",
    "ref_corners = paths.arena_coordinates['miniscope']\n",
    "\n",
    "# create a bounded movie to align later\n",
    "# assemble the bounded movie path\n",
    "bounded_path = os.path.join(temp_path, 'bounded.avi')\n",
    "# new_mat = cv2.UMat(rot_matrix)\n",
    "\n",
    "# save the bounded movie\n",
    "# get the width and height\n",
    "width = frame_list[0].shape[1]\n",
    "height = frame_list[0].shape[0]\n",
    "\n",
    "# test = cv2.warpPerspective(frames_formotif[0].astype('float32'), rot_matrix.to_numpy(), (width, height))\n",
    "# current_matrix = rot_matrix.to_numpy()\n",
    "\n",
    "perspective_matrix = cv2.getPerspectiveTransform(dlc_corners.to_numpy().T.astype('float32'),\n",
    "                                                 (np.array(ref_corners).astype('float32')+5)*20)\n",
    "\n",
    "# create the writer\n",
    "out = cv2.VideoWriter(bounded_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (1280, 1024))\n",
    "# save the movie\n",
    "for frames in frame_list:\n",
    "    # apply the perspective matrix\n",
    "    out_frame = cv2.warpPerspective(frames.astype('float32'), perspective_matrix, (1280, 1024))\n",
    "    out.write(out_frame.astype('uint8'))\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716dc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coordinate_columns, data.columns)\n",
    "print(ego_traces)\n",
    "hv.Raster(ego_traces).opts(tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the video egocentrically\n",
    "importlib.reload(fv)\n",
    "\n",
    "# create the egocentric movie\n",
    "# path_dlc = data_path\n",
    "# path_vame = target_folder\n",
    "file_format = '.avi'\n",
    "crop_size = (200, 200)\n",
    "use_video = True\n",
    "check_video = False\n",
    "save_align = False\n",
    "\n",
    "# select the coordinate columns\n",
    "coordinate_columns = [el for el in data.columns if ('mouse_' in el) | ('cricket_' in el)]\n",
    "\n",
    "scaled_data = (data[coordinate_columns].fillna(0)+5)*20/1000\n",
    "print(scaled_data.shape)\n",
    "\n",
    "ego_traces, egocentric_frames, columns_out = fv.align_demo(scaled_data, [], data_vame_name, file_format, crop_size,\n",
    "                                   use_video=use_video, check_video=check_video, \n",
    "                                   vid_path=bounded_path)\n",
    "\n",
    "# turn the list into an array\n",
    "egocentric_frames = np.array(egocentric_frames)\n",
    "print(egocentric_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c79783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the egocentric movie\n",
    "\n",
    "# assemble the bounded movie path\n",
    "egocentric_path = os.path.join(temp_path, 'egocentric.avi')\n",
    "\n",
    "# save the bounded movie\n",
    "# get the width and height\n",
    "width = egocentric_frames[0].shape[1]\n",
    "height = egocentric_frames[0].shape[0]\n",
    "print(egocentric_frames[0].shape)\n",
    "\n",
    "# create the writer\n",
    "out2 = cv2.VideoWriter(egocentric_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (height, width))\n",
    "# save the movie\n",
    "for frames in egocentric_frames:\n",
    "    out_frame = np.repeat(np.expand_dims(frames, 2), 3, axis=2)\n",
    "    out2.write(out_frame.astype('uint8'))\n",
    "\n",
    "out2.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b46d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv.Raster(out_frame[:, :, 10])\n",
    "hv.Raster(egocentric_frames[10, :, :]).opts(tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ca328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(egocentric_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43966645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the motif locations\n",
    "\n",
    "# get the present motifs\n",
    "motif_vector = data['motifs'].to_numpy()\n",
    "present_motifs = np.unique(motif_vector)\n",
    "present_motifs = present_motifs[~np.isnan(present_motifs)]\n",
    "\n",
    "# allocate memory for all the locations\n",
    "location_perfile = []\n",
    "duration_perfile = []\n",
    "# for all the motifs\n",
    "for motif in present_motifs:\n",
    "    \n",
    "    # find all the starts and ends for this motif\n",
    "    m_idx = (current_motifs==motif).astype(int)\n",
    "    starts = np.argwhere(np.diff(np.pad(m_idx, (1, 1), mode='constant', constant_values=(0, 0)))==1)\n",
    "    ends = np.argwhere(np.diff(np.pad(m_idx, (1, 1), mode='constant', constant_values=(0, 0)))==-1)\n",
    "\n",
    "    # skip if any of the arrays is empty\n",
    "    if (starts.shape[0] == 0) or (ends.shape[0] == 0):\n",
    "        duration_perfile.append(np.empty((0, 1)))\n",
    "        location_perfile.append(np.empty((0, 1)))\n",
    "        continue\n",
    "    # trim the starts and ends based on ordering\n",
    "    if starts[0] > ends[0]:\n",
    "        if ends.shape[0] > 1:\n",
    "            ends = ends[1:]\n",
    "        else:\n",
    "            duration_perfile.append(np.empty((0, 1)))\n",
    "            location_perfile.append(np.empty((0, 1)))\n",
    "            continue\n",
    "    if starts[-1] > ends [-1]:\n",
    "        if starts.shape[0] > 1:\n",
    "            starts = starts[:-1]\n",
    "        else:\n",
    "            duration_perfile.append(np.empty((0, 1))) \n",
    "            location_perfile.append(np.empty((0, 1)))\n",
    "            continue\n",
    "    # trim the starts or ends depending on size\n",
    "    if starts.shape[0] > ends.shape[0]:\n",
    "        starts = starts[:-1]\n",
    "    if ends.shape[0] > starts.shape[0]:\n",
    "        ends = ends[1:]\n",
    "    # make sure the ends are always bigger than the starts\n",
    "    try: \n",
    "        assert np.all((ends-starts)>0) \n",
    "    except AssertionError:\n",
    "        print(str(idx)+'_'+str(motif))\n",
    "        print(starts)\n",
    "        print(ends)\n",
    "\n",
    "    # save the locations for this motif\n",
    "    location_perfile.append([el[0] for el in starts])\n",
    "    duration_perfile.append([el[0] for el in ends-starts])\n",
    "        \n",
    "print(location_perfile)\n",
    "print(duration_perfile)\n",
    "print(motif_vector)\n",
    "# print(location_perfile)\n",
    "# print(duration_perfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create egocentric movies for all motifs\n",
    "\n",
    "# for all the motifs present\n",
    "for idx, motif in enumerate(present_motifs):\n",
    "    # get the maximum duration\n",
    "    max_duration = np.max(duration_perfile[idx])\n",
    "    # get the start of the maximum duration\n",
    "    max_location = location_perfile[idx][np.argmax(duration_perfile[idx])]\n",
    "\n",
    "    # get the video frames\n",
    "    frame_idx = np.array(np.arange(max_location, max_location+max_duration))\n",
    "    motif_frames = egocentric_frames[frame_idx]\n",
    "    # save the movie\n",
    "    \n",
    "    # assemble the bounded movie path\n",
    "    motif_path = os.path.join(temp_path, str(motif)+'_motif.avi')\n",
    "    # create the writer\n",
    "    out2 = cv2.VideoWriter(motif_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (200,200))\n",
    "    # save the movie\n",
    "    for frames in motif_frames:\n",
    "        out_frame = np.repeat(np.expand_dims(frames, 2), 3, axis=2)\n",
    "        out2.write(out_frame.astype('uint8'))\n",
    "\n",
    "    out2.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prey_capture] *",
   "language": "python",
   "name": "conda-env-.conda-prey_capture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
