{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ba9fb",
   "metadata": {},
   "source": [
    "# imports\n",
    "# import pixiedust\n",
    "import logging\n",
    "logging.getLogger(\"param.Dimension\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.ParameterizedMetaclass\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.SpreadPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.CurvePlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.AdjointLayout\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.HoloMap\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.OverlayPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.BarPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.ErrorPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.RasterPlot\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.Layout\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.PointPlot\").setLevel(logging.CRITICAL)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture'))\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')\n",
    "from bokeh.resources import INLINE\n",
    "\n",
    "import paths\n",
    "import functions_bondjango as bd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functions_plotting as fp\n",
    "import functions_data_handling as fd\n",
    "import functions_kinematic as fk\n",
    "from scipy.stats import sem\n",
    "import sklearn.decomposition as decomp\n",
    "import umap\n",
    "import sklearn.mixture as mix\n",
    "from scipy.stats import sem\n",
    "import pickle as pk\n",
    "import itertools as it\n",
    "import processing_parameters\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "import importlib\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# # define the name to be used for the saved figures\n",
    "# save_name = 'acrossTrials'\n",
    "# line_width = 5\n",
    "target_folder = r'J:\\Drago Guggiana Nilo\\Prey_capture\\temp_VAME\\mouse_15'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2f5a0",
   "metadata": {},
   "source": [
    "%%time\n",
    "# load the data\n",
    "\n",
    "# Load the desired files\n",
    "importlib.reload(processing_parameters)\n",
    "\n",
    "# define the threshold for matched cells\n",
    "match_threshold = 10\n",
    "# get the data paths\n",
    "try: \n",
    "    data_path = snakemake.input[0]\n",
    "except NameError:\n",
    "    # get the search list\n",
    "    search_list = processing_parameters.search_list\n",
    "    # allocate memory for the data\n",
    "    beh_data = []\n",
    "    ca_data = []\n",
    "    \n",
    "    \n",
    "    beh_motif = []\n",
    "    ca_motif = []\n",
    "    \n",
    "    beh_latents = []\n",
    "    ca_latents = []\n",
    "    # allocate a list for all paths (need to preload to get the dates)\n",
    "    all_paths = []\n",
    "    # for all the search strings\n",
    "    for search_string in search_list:\n",
    "\n",
    "        # query the database for data to plot\n",
    "        data_all = bd.query_database('analyzed_data', search_string)\n",
    "        data_all = [el for el in data_all if 'preproc' in el['slug']]\n",
    "        data_path = [el['analysis_path'] for el in data_all if '_preproc' in el['slug']]\n",
    "        all_paths.append(data_path)\n",
    "    # now load the files\n",
    "    for data_path in all_paths:\n",
    "        # load the calcium data\n",
    "        \n",
    "        # for all the files\n",
    "        for files in data_path:\n",
    "            # load the data\n",
    "            with pd.HDFStore(files) as h:\n",
    "                try:\n",
    "    #                 beh_data.append(h['full_traces'])\n",
    "                    if '/matched_calcium' in h.keys():\n",
    "                        # get the cell matches\n",
    "                        ca_motif.append(h['motifs'])\n",
    "                        ca_latents.append(h['latents'])\n",
    "                        ca_data.append(h['matched_calcium'])\n",
    "                    else:\n",
    "                        beh_motif.append(h['motifs'])\n",
    "                        beh_latents.append(h['latents'])\n",
    "                        beh_data.append(h['full_traces'])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "                    \n",
    "    print(f'Number of calcium files: {len(ca_data)}')\n",
    "    print(f'Number of behavior only files: {len(beh_data)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f507e8c",
   "metadata": {},
   "source": [
    "%%time\n",
    "# create a UMAP embedding of the latents\n",
    "\n",
    "# compile the data\n",
    "try:\n",
    "    compiled_latent = np.vstack([np.vstack(ca_latents), np.vstack(beh_latents)])\n",
    "except ValueError:\n",
    "    compiled_latent = np.vstack(ca_latents)\n",
    "compiled_latent = compiled_latent[:, 1:]\n",
    "\n",
    "# embed using UMAP\n",
    "# original parameters 0.5 and 10\n",
    "# 0.1 and 30 also works\n",
    "# 0.05 and 30 works too\n",
    "reducer = umap.UMAP(min_dist=0.9, n_neighbors=10)\n",
    "embedded_data = reducer.fit_transform(compiled_latent)\n",
    "\n",
    "# # save the embedding\n",
    "# np.save(os.path.join(target_folder, 'UMAP_result'), embedded_data)\n",
    "\n",
    "# # generate the model name\n",
    "# model_name = os.path.join(target_folder, 'UMAP_model.pk')\n",
    "# # save the estimator\n",
    "# with open(model_name, 'wb') as file:\n",
    "#     pk.dump(reducer, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7af371",
   "metadata": {},
   "source": [
    "# Load a pre-existing embedding\n",
    "embedded_data = np.load(os.path.join(target_folder, 'UMAP_result.npy'))\n",
    "\n",
    "# generate the model name\n",
    "model_name = os.path.join(target_folder, 'UMAP_model.pk')\n",
    "with open(model_name, 'rb') as file:\n",
    "    reducer = pk.load(file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e344ea",
   "metadata": {},
   "source": [
    "# plot the embedding\n",
    "\n",
    "# plot the UMAP clusters\n",
    "print(ca_motif[0].shape)\n",
    "\n",
    "label_list = np.hstack([ca_motif, beh_motif])\n",
    "print(label_list.shape)\n",
    "# get the labels\n",
    "# compiled_labels = np.expand_dims(np.hstack(label_list).T, axis=1)\n",
    "compiled_labels = np.vstack(label_list)\n",
    "\n",
    "# print(motif_sort)\n",
    "# compiled_labels = motif_revsort[compiled_labels]\n",
    "\n",
    "# define the sampling ratio\n",
    "sampling_ratio = 1\n",
    "\n",
    "umap_data = np.concatenate((embedded_data[::sampling_ratio, :],\n",
    "                            compiled_labels[::sampling_ratio, :]), axis=1)\n",
    "\n",
    "plot_data = umap_data[(umap_data[:, 2]!= 5) & (umap_data[:, 2]!= 8), :]\n",
    "          \n",
    "print(umap_data.shape)\n",
    "                            \n",
    "                            \n",
    "umap_plot = hv.Scatter(plot_data, vdims=['Dim 2','cluster'], kdims=['Dim 1'])\n",
    "print(umap_plot)\n",
    "umap_plot.opts(color='cluster', colorbar=True, cmap='Spectral', tools=['hover'])\n",
    "umap_plot.opts(opts.Scatter(width=800, height=600))\n",
    "umap_plot"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e8810",
   "metadata": {},
   "source": [
    "# get the features to plot\n",
    "\n",
    "# define the target property\n",
    "target_field = 'mouse_speed'\n",
    "\n",
    "# define the time window\n",
    "time_window = int(30/2)\n",
    "\n",
    "# allocate memory for the feature list\n",
    "feature_list = []\n",
    "\n",
    "# for all the calcium\n",
    "for dataframe in ca_data + beh_data:\n",
    "    try:\n",
    "        data = dataframe.loc[:, target_field].to_numpy()\n",
    "#         print(data.shape)\n",
    "#         raise ValueError\n",
    "        data = medfilt(data, 41)\n",
    "        feature_list.append(data[time_window:-time_window])\n",
    "    except KeyError:\n",
    "        empty_array = np.zeros((dataframe.iloc[time_window:-time_window, 0].to_numpy().shape[0]))\n",
    "        feature_list.append(empty_array)\n",
    "        \n",
    "# # now go through the pure behavior\n",
    "# for dataframe in beh_data:\n",
    "#     try:\n",
    "#         data = dataframe[target_field].to_numpy()\n",
    "#         feature_list.append(data[time_window:-time_window])\n",
    "#     except KeyError:\n",
    "#         continue\n",
    "\n",
    "print(len(feature_list))\n",
    "# turn into a single array\n",
    "features = np.expand_dims(np.hstack(feature_list), 1)\n",
    "\n",
    "print(features.shape)\n",
    "print(compiled_labels.shape)\n",
    "    \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b55ae3",
   "metadata": {},
   "source": [
    "# plot the UMAP embedding with a chosen feature\n",
    "\n",
    "selection_vector = (features<50) & (compiled_labels!=5) & (compiled_labels!=8)\n",
    "# selection_vector = np.ones((embedded_data.shape[0], 1)) == 1\n",
    "# selection_vector = (features > 0)\n",
    "print(selection_vector.shape)\n",
    "print(embedded_data.shape)\n",
    "cropped_data = embedded_data[selection_vector[:, 0], :]\n",
    " \n",
    "feature_labels = features[selection_vector[:, 0], :]\n",
    "# define the sampling ratio\n",
    "sampling_ratio = 1\n",
    "\n",
    "umap_feature = np.concatenate((cropped_data[::sampling_ratio, :],\n",
    "                            feature_labels[::sampling_ratio, :]), axis=1)\n",
    "\n",
    "# umap_feature = umap_feature[umap_data[:, 2]!= 5, :]\n",
    "# umap_feature = umap_feature[umap_data[:, 2]!= 8, :]\n",
    "          \n",
    "print(umap_feature.shape)\n",
    "                            \n",
    "                            \n",
    "umap_plot = hv.Scatter(umap_feature, vdims=['Dim 2','cluster'], kdims=['Dim 1'])\n",
    "print(umap_plot)\n",
    "umap_plot.opts(color='cluster', colorbar=True, cmap='Spectral', tools=['hover'])\n",
    "umap_plot.opts(opts.Scatter(width=800, height=600))\n",
    "umap_plot\n",
    "\n",
    "# freq, bins = np.histogram(features, bins=10)\n",
    "# hv.Bars((bins, freq)).opts(width=600)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907c1a8",
   "metadata": {},
   "source": [
    "# Calculate and plot the average usage\n",
    "# compiled_usage = np.vstack(usage_list)\n",
    "# motif_number = beh_latents[0].shape[1]\n",
    "motif_number = 15#np.unique(compiled_labels).shape[0]\n",
    "print(motif_number)\n",
    "results_list = np.hstack(all_paths)\n",
    "print(len(results_list))\n",
    "print(len(label_list))\n",
    "# allocate memory for the output usages\n",
    "usage_all = np.zeros((len(label_list), motif_number))\n",
    "\n",
    "# for all the files\n",
    "for idx, labels in enumerate(label_list):\n",
    "    # get the unique numbers and their counts\n",
    "#     unique_nums, unique_counts = np.unique(motif_revsort[labels], return_counts=True)\n",
    "    unique_nums, unique_counts = np.unique(labels, return_counts=True)\n",
    "    # fill in the corresponding indexes in the matrix\n",
    "    usage_all[idx, unique_nums] = unique_counts\n",
    "\n",
    "# average\n",
    "average_usage = np.mean(usage_all, axis=0)\n",
    "sem_usage = sem(usage_all, axis=0)\n",
    "\n",
    "# plot\n",
    "def motif_usage_plot(data_in, std_in, axis_limits):\n",
    "    bars = hv.Bars(data_in, kdims=['Motif'], vdims=['Fraction'])\n",
    "    bars.opts(width=600, height=400, ylim=(0, 150))\n",
    "    errorbars = hv.ErrorBars((np.arange(axis_limits), data_in, std_in))\n",
    "\n",
    "    return bars*errorbars\n",
    "\n",
    "# calculate the succ and fail averages\n",
    "succ_usages = np.array([el for idx, el in enumerate(usage_all) if 'succ' in results_list[idx]])\n",
    "succ_average = np.mean(succ_usages, axis=0)\n",
    "succ_std = sem(succ_usages, axis=0)/np.max(succ_average)\n",
    "succ_average /= np.max(succ_average)\n",
    "\n",
    "succ_plot = motif_usage_plot(succ_average, succ_std, motif_number).opts(ylim=(0, 1.2))\n",
    "\n",
    "fail_usages = np.array([el for idx, el in enumerate(usage_all) if 'fail' in results_list[idx]])\n",
    "fail_average = np.mean(fail_usages, axis=0)\n",
    "fail_std = sem(fail_usages, axis=0)/np.max(fail_average)\n",
    "fail_average /= np.max(fail_average)\n",
    "\n",
    "fail_plot = motif_usage_plot(fail_average, fail_std, motif_number).opts(ylim=(0, 1.2))\n",
    "\n",
    "img = succ_plot+fail_plot\n",
    "img.opts(shared_axes=False).cols(1)\n",
    "img\n"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prey_capture] *",
   "language": "python",
   "name": "conda-env-.conda-prey_capture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
