{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc22c5e-f78c-4e1d-afc8-c1b2651cbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import panel as pn\n",
    "import seaborn as sns\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import datashader as dshade\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import importlib\n",
    "import datetime\n",
    "import warnings\n",
    "import math\n",
    "import h5py\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.io import export_svgs, export_png\n",
    "from bokeh.plotting import show\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation import histogram\n",
    "from holoviews.operation.datashader import datashade, shade\n",
    "hv.extension('bokeh')\n",
    "# hv.extension('matplotlib')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "%aimport paths\n",
    "import processing_parameters\n",
    "import functions_bondjango as bd\n",
    "import functions_plotting as fp\n",
    "import functions_data_handling as fdh\n",
    "import functions_kinematic as fk\n",
    "import functions_tuning as tuning\n",
    "import functions_misc as misc\n",
    "from wirefree_experiment import WirefreeExperiment, DataContainer\n",
    "import paths\n",
    "\n",
    "importlib.reload(fp)\n",
    "# set up the figure theme\n",
    "fp.set_theme()\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "cm = 1./2.54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ca251-a24f-40b8-8b11-ea95403aa5cd",
   "metadata": {},
   "source": [
    "# Go through all the mice and create aggregate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cda5a6-fbaa-466e-b325-a595bdbaa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(processing_parameters)\n",
    "mice = ['MM_221109_a', 'MM_221110_a', 'MM_220915_a','MM_220928_a', \n",
    "        'MM_230518_b', 'MM_230705_b', 'MM_230706_a', 'MM_230706_b']\n",
    "results = ['repeat']    # ['multi', 'fullfield', 'control']\n",
    "lightings = ['normal', 'dark']\n",
    "rigs = ['VWheelWF', 'VTuningWF']    # 'ALL' used for everything but repeat aggs\n",
    "\n",
    "for mouse, result, light, rig in itertools.product(mice, results, lightings, rigs):\n",
    "\n",
    "    # get the search stringtc_conso\n",
    "    search_string = f\"mouse:{mouse}, result:{result}, lighting:{light}, rig:{rig}\"\n",
    "    print(search_string)\n",
    "\n",
    "    parsed_search = fdh.parse_search_string(search_string)\n",
    "    \n",
    "    # get the paths from the database\n",
    "    file_infos = bd.query_database(\"analyzed_data\", search_string)\n",
    "    input_paths = np.array([el['analysis_path'] for el in file_infos if ('_tcconsolidate' in el['slug']) and\n",
    "                            (parsed_search['mouse'].lower() in el['slug'])])\n",
    "    input_paths = np.array([in_path for in_path in input_paths if os.path.isfile(in_path)])\n",
    "    print(np.sort(input_paths))\n",
    "    \n",
    "    if len(input_paths) == 0:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        date_list = [os.path.basename(path)[:10] for path in input_paths]\n",
    "        mouse = parsed_search['mouse']\n",
    "        \n",
    "        # assemble the output path\n",
    "        output_path = os.path.join(paths.analysis_path, f\"AGG_{'_'.join(parsed_search.values())}.hdf5\")\n",
    "        \n",
    "        data_list = []\n",
    "        for file, date in zip(input_paths, date_list):\n",
    "            data_dict = {}\n",
    "            with pd.HDFStore(file, 'r') as tc:\n",
    "                # print(tc.keys())\n",
    "                if '/no_ROIs'in tc.keys():\n",
    "                    continue\n",
    "                else:\n",
    "                    for key in tc.keys():\n",
    "                        label = \"_\".join(key.split('/')[1:])\n",
    "\n",
    "                        data = tc[key]\n",
    "                        data['date'] = date\n",
    "                        data_dict[label] = data\n",
    "                        \n",
    "                    data_list.append(data_dict)\n",
    "\n",
    "        if len(data_list) > 0:\n",
    "            # Aggregate it all\n",
    "            for key in data_list[0].keys():\n",
    "                df = pd.concat([d[key] for d in data_list]).reset_index(names='old_index')\n",
    "                df.to_hdf(output_path, key)\n",
    "                    \n",
    "            # assemble the entry data\n",
    "            entry_data = {\n",
    "                'analysis_type': 'agg_tc',\n",
    "                'analysis_path': output_path,\n",
    "                'date': '',\n",
    "                'pic_path': '',\n",
    "                'result': parsed_search['result'],\n",
    "                'rig': parsed_search['rig'],\n",
    "                'lighting': parsed_search['lighting'],\n",
    "                'imaging': 'wirefree',\n",
    "                'slug': misc.slugify(os.path.basename(output_path)[:-5]),\n",
    "            }\n",
    "            \n",
    "            # check if the entry already exists, if so, update it, otherwise, create it\n",
    "            update_url = '/'.join((paths.bondjango_url, 'analyzed_data', entry_data['slug'], ''))\n",
    "            output_entry = bd.update_entry(update_url, entry_data)\n",
    "            if output_entry.status_code == 404:\n",
    "                # build the url for creating an entry\n",
    "                create_url = '/'.join((paths.bondjango_url, 'analyzed_data', ''))\n",
    "                output_entry = bd.create_entry(create_url, entry_data)\n",
    "            \n",
    "            print('The output status was %i, reason %s' %\n",
    "                    (output_entry.status_code, output_entry.reason))\n",
    "            if output_entry.status_code in [500, 400]:\n",
    "                print(entry_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc95b12-72a0-4cf3-a724-7058f205419e",
   "metadata": {},
   "source": [
    "# Load aggregate files from all mice to make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cedb80-3443-4ded-8988-edab1748be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the search string\n",
    "search_string = f\"analysis_type:agg_tc, result:control, lighting:dark\"\n",
    "parsed_search = fdh.parse_search_string(search_string)\n",
    "save_suffix = \"_\".join((parsed_search['result'], parsed_search['rig'], parsed_search['lighting']))\n",
    "\n",
    "if not os.path.isdir(os.path.join(paths.wf_figures_path, save_suffix)):\n",
    "    os.mkdir(os.path.join(paths.wf_figures_path, save_suffix))\n",
    "\n",
    "figure_save_path = os.path.join(paths.wf_figures_path, save_suffix)\n",
    "\n",
    "if parsed_search['result'] == 'repeat':\n",
    "    if parsed_search['rig'] == 'VWheelWF':\n",
    "        session_types = ['fixed0', 'fixed1']\n",
    "    else:\n",
    "        session_types = ['free0', 'free1']\n",
    "    session_shorthand = session_types\n",
    "else:\n",
    "    session_types = ['VWheelWF', 'VTuningWF']\n",
    "    session_shorthand = ['fixed', 'free']\n",
    "\n",
    "# get the paths from the database\n",
    "file_infos = bd.query_database(\"analyzed_data\", search_string)\n",
    "input_paths = np.array([el['analysis_path'] for el in file_infos if ('agg' in el['slug'])])\n",
    "print(np.sort(input_paths))\n",
    "\n",
    "data_list = []\n",
    "for file in input_paths:\n",
    "    data_dict = {}\n",
    "    mouse = '_'.join(os.path.basename(file).split('_')[10:13])\n",
    "    with pd.HDFStore(file, 'r') as tc:\n",
    "        for key in tc.keys():\n",
    "            label = \"_\".join(key.split('/')[1:])\n",
    "            data = tc[key]\n",
    "            data['mouse'] = mouse\n",
    "            data_dict[label] = data\n",
    "                \n",
    "        data_list.append(data_dict)\n",
    "\n",
    "# Aggregate it all\n",
    "agg_dict = {}\n",
    " \n",
    "for key in data_list[0].keys():\n",
    "    df = pd.concat([d[key] for d in data_list]).reset_index(drop=True)\n",
    "    agg_dict[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2cb504-1c48-4330-916b-9c3e8dff4dda",
   "metadata": {},
   "source": [
    "# Cell matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d182ed-c699-4689-973a-ede169dfaea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_nums = [d['cell_matches'].groupby(['date']).apply(lambda x: len(x)).values for d in data_list]\n",
    "\n",
    "match_nums = np.concatenate([el if (len(el) !=0) else -5*np.ones(1) for el in match_nums])\n",
    "frequencies, edges = np.histogram(match_nums, 40)\n",
    "\n",
    "print('Values: %s, Edges: %s' % (frequencies.shape[0], edges.shape[0]))\n",
    "cell_match_hist = hv.Histogram((edges, frequencies)).opts(xlabel='# Matched Cells', ylabel='Freq.')\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"num_cells_matched_{save_suffix}.png\")\n",
    "cell_match_hist = fp.save_figure(cell_match_hist, save_path=save_path, fig_width=8, dpi=800, fontsize='screen', target='both', display_factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_frac0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afcdfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_nums = [d['cell_matches'].groupby(['date']).apply(lambda x: len(x)).values for d in data_list]\n",
    "num_cells = np.zeros((len(data_list), 2))\n",
    "\n",
    "\n",
    "num_cells0 = []\n",
    "num_cells1 = []\n",
    "match_frac0 = []\n",
    "match_frac1 = []\n",
    "\n",
    "for i, d in enumerate(data_list):\n",
    "    num0 = d[f'{session_types[0]}_all_cells_norm_spikes_viewed_props'].groupby(['date']).apply(lambda x: len(x)).values\n",
    "    num1 = d[f'{session_types[1]}_all_cells_norm_spikes_viewed_props'].groupby(['date']).apply(lambda x: len(x)).values\n",
    "\n",
    "    num_cells0.append(num0)\n",
    "    num_cells1.append(num1)\n",
    "\n",
    "    match_frac0.append(match_nums[i]/num0)\n",
    "    match_frac1.append(match_nums[i]/num1)\n",
    "\n",
    "match_nums = [match for match in match_nums if match.shape[0] > 0]\n",
    "match_frac0 = [match for match in match_frac0 if match.shape[0] > 0]\n",
    "match_frac1 = [match for match in match_frac1 if match.shape[0] > 0]\n",
    "\n",
    "match_nums = np.concatenate(match_nums).ravel()\n",
    "match_frac0 = np.concatenate(match_frac0).ravel()\n",
    "match_frac1 = np.concatenate(match_frac1).ravel()\n",
    "\n",
    "scatter = hv.Points((match_frac0, match_frac1))\n",
    "scatter.opts(xlim=(0, 1), xlabel=f'{session_shorthand[0].title()} Frac. Match',\n",
    "             ylim=(0, 1), ylabel=f'{session_shorthand[1].title()} Frac. Match',\n",
    "             size=10, width=400, height=400, tools=['hover'])\n",
    "line = hv.Curve(np.arange(0, 1.1)).opts(color='black', alpha=0.5)\n",
    "frac_cell_match_scatter = line * scatter\n",
    "frac_cell_match_scatter\n",
    "\n",
    "# frequencies0, edges0 = np.histogram(match_frac0, 40)\n",
    "# frequencies1, edges1 = np.histogram(match_frac1, 40)\n",
    "\n",
    "# # print('Values: %s, Edges: %s' % (frequencies.shape[0], edges.shape[0]))\n",
    "# frac_cell_match_hist0 = hv.Histogram((edges0, frequencies0), label=session_types[0]).opts(xlabel='Frac. Matched Cells', ylabel='Freq.')\n",
    "# frac_cell_match_hist1 = hv.Histogram((edges1, frequencies1), label=session_types[1]).opts(xlabel='Frac. Matched Cells', ylabel='Freq.')\n",
    "# frac_cell_match_hist = frac_cell_match_hist0 * frac_cell_match_hist1\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"frac_cells_matched_{save_suffix}.png\")\n",
    "frac_cell_match_scatter = fp.save_figure(frac_cell_match_scatter, save_path=save_path, fig_width=10, dpi=800, fontsize='screen', target='both', display_factor=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0b951-d489-4e3a-946a-daeb63a68911",
   "metadata": {},
   "source": [
    "# Fraction postural or visual responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7998b36-83d3-44a3-a58c-f442700daacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-animal fraction kinematic or dir/ori responsive\n",
    "ds_name = f'{session_types[0]}_summary_stats'\n",
    "ds = agg_dict[ds_name]\n",
    "kinem_cols = list(ds.columns[4:-8])\n",
    "vis_cols = list(ds.columns[-8:-2])\n",
    "kinem_vis_cols = kinem_cols + vis_cols[1:3] + vis_cols[4:]\n",
    "\n",
    "if ('fixed' in ds_name) or ('VWheelWF' in ds_name):\n",
    "    rename_dict = dict(zip(kinem_vis_cols, processing_parameters.wf_fixed_kinem_cols + processing_parameters.wf_vis_cols))\n",
    "else:\n",
    "    rename_dict = dict(zip(kinem_vis_cols, processing_parameters.wf_free_kinem_cols + processing_parameters.wf_vis_cols))\n",
    "\n",
    "frac_vis_resp = ds[ds.old_index == 'all_cells'].rename(columns=rename_dict)\n",
    "\n",
    "violinplot_free = frac_vis_resp[list(rename_dict.values())].hvplot.violin(legend=False)\n",
    "violinplot_free.opts(xlabel='', ylabel='Significant Frac.', ylim=(-0.05, 1.05), xrotation=45, width=1500, height=1000)\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"sig_frac_kinem_vis_{save_suffix}_{session_types[0]}.png\")\n",
    "violinplot_free = fp.save_figure(violinplot_free, save_path=save_path, fig_width=15, dpi=800, fontsize='screen', target='both', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e934bd-15ac-4b03-a44d-ee7ddd3061dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-animal fraction kinematic or dir/ori responsive\n",
    "ds_name = f'{session_types[1]}_summary_stats'\n",
    "ds = agg_dict[ds_name]\n",
    "kinem_cols = list(ds.columns[4:-8])\n",
    "vis_cols = list(ds.columns[-8:-2])\n",
    "kinem_vis_cols = kinem_cols + vis_cols[1:3] + vis_cols[4:]\n",
    "\n",
    "if ('fixed' in ds_name) or ('VWheelWF' in ds_name):\n",
    "    rename_dict = dict(zip(kinem_vis_cols, processing_parameters.wf_fixed_kinem_cols + processing_parameters.wf_vis_cols))\n",
    "else:\n",
    "    rename_dict = dict(zip(kinem_vis_cols, processing_parameters.wf_free_kinem_cols + processing_parameters.wf_vis_cols))\n",
    "\n",
    "frac_vis_resp = ds[ds.old_index == 'all_cells'].rename(columns=rename_dict)\n",
    "\n",
    "violinplot_fixed = frac_vis_resp[list(rename_dict.values())].hvplot.violin(legend=False, violin_fill_color='red')\n",
    "violinplot_fixed.opts(xlabel='', ylabel='Significant Frac.', ylim=(-0.05, 1.05), xrotation=45, width=1500, height=1000)\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"sig_frac_kinem_vis_{save_suffix}_{session_types[1]}.png\")\n",
    "violinplot_fixed = fp.save_figure(violinplot_fixed, save_path=save_path, fig_width=15, dpi=800, fontsize='screen', target='both', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db032f7f-5013-4341-923b-e47ba7a025fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frac_tuned(df):\n",
    "    kinem_cols = list(df.columns[1:-6])\n",
    "    vis_cols = list(df.columns[-6:-2])\n",
    "    \n",
    "    df['sum_kinem'] = df[kinem_cols].sum(axis=1)\n",
    "    df['sum_vis'] = df[vis_cols].sum(axis=1)\n",
    "    df['sum_mix'] = df[['sum_kinem', 'sum_vis']].sum(axis=1)\n",
    "   \n",
    "    frac_vis_tuned = df['sum_vis'].loc[df['sum_vis'] > 0].count() / df.shape[0]\n",
    "    frac_kinem_tuned = df['sum_kinem'].loc[df['sum_kinem'] > 0].count() / df.shape[0]\n",
    "\n",
    "    frac_only_kinem = df[(df[vis_cols].sum(axis=1) == 0) & (df[kinem_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "    frac_only_vis = df[(df[kinem_cols].sum(axis=1) == 0) & (df[vis_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "    frac_mix_tuned = df[(df[vis_cols].sum(axis=1) > 0) & (df[kinem_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "\n",
    "    return frac_only_kinem, frac_only_vis, frac_vis_tuned, frac_kinem_tuned, frac_mix_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edf58b-cf4e-410b-b28a-87ad0692987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "for ds, exp_type in zip([agg_dict[f'{session_types[0]}_multimodal_tuned'], agg_dict[f'{session_types[1]}_multimodal_tuned']], session_types):\n",
    "    only_kinem = []\n",
    "    only_vis = []\n",
    "    vis_tuned = []\n",
    "    kinem_tuned = []\n",
    "    mix_tuned = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in ds.groupby('mouse'):\n",
    "        frac_only_kinem, frac_only_vis, frac_vis_tuned, frac_kinem_tuned, frac_mix_tuned = get_frac_tuned(group)\n",
    "        only_kinem.append(frac_only_kinem)\n",
    "        only_vis.append(frac_only_vis)\n",
    "        vis_tuned.append(frac_vis_tuned)\n",
    "        kinem_tuned.append(frac_kinem_tuned)\n",
    "        mix_tuned.append(frac_mix_tuned)\n",
    "\n",
    "    df['group'] = [exp_type] * len(vis_tuned)\n",
    "    df[' Visual Only'] = only_vis\n",
    "    df[' Postural Only'] = only_kinem\n",
    "    df[' Visual'] = vis_tuned\n",
    "    df[' Postural'] = kinem_tuned\n",
    "    df['Multimodal'] = mix_tuned\n",
    "    df_list.append(df)\n",
    "    plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "comp_tuning = pd.concat(df_list, axis=0)\n",
    "comp_tuning = pd.melt(comp_tuning, id_vars=['group'], value_vars=[' Visual Only', ' Postural Only', ' Visual', ' Postural', 'Multimodal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ff456-4a20-4af4-b332-33263ad9a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "comp_tuning_rank_sum = comp_tuning.groupby(['variable', 'group'], group_keys=True).value.agg(list).unstack(level=1)\n",
    "comp_tuning_stats = comp_tuning_rank_sum.apply(lambda x: st.mannwhitneyu(x[session_types[0]], x[session_types[1]], alternative='two-sided'), axis=1)\n",
    "p_vals = [comp_tuning_stats.to_numpy()[i][1] for i in np.arange(comp_tuning_stats.shape[0])]\n",
    "multipletests(p_vals, alpha=0.05, method='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2add32c-1824-44bf-a92c-14497c56d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tuning_rank_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e093530-12dc-4ebb-8f20-1ae6d769d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "violinplot = hv.Violin(comp_tuning, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=500,\n",
    "                                                                  # ylim=(-0.05, 1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  cmap=[fp.hv_blue_hex, 'red'],\n",
    "                                                                  show_legend=False, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, f\"frac_multimodal_{save_suffix}.png\")\n",
    "# violinplot\n",
    "violinplot = fp.save_figure(violinplot, save_path=save_path, fig_width=10, dpi=800, fontsize='screen', target='both', display_factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b1ed5-be24-463c-ba6b-1976d72b8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(data=comp_tuning, x=\"variable\", y=\"value\", hue=\"group\")\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.set_ylabel('Significant Frac.')\n",
    "ax.set_xlabel('')\n",
    "ax.legend(title='', loc='lower right')\n",
    "plt.savefig(os.path.join(figure_save_path, f'frac_multimodal_alt_{save_suffix}.png'), dpi=800, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b7ae6-7f3d-402c-ae7d-8c2f64afa5aa",
   "metadata": {},
   "source": [
    "# Bootstrapped tuning shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d035992-f770-4f78-9fa4-d44ff27f9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_matched_vis_tuning(ds_list, cell, tuning_kind='direction', exp_name='', error='std', norm=True, polar=True, axes=None):\n",
    "    if axes is None:\n",
    "        axes = []\n",
    "        fig = plt.figure(layout='constrained', figsize=(18*cm, 2*len(data_list)*cm))\n",
    "        fig.suptitle(f\"Cell {cell}\", fontsize='x-large')\n",
    "        subfigs = fig.subfigures(nrows=len(ds_list), ncols=1, hspace=0.07)\n",
    "    \n",
    "        for i, subfig in enumerate(subfigs):\n",
    "            subfig.suptitle(processing_parameters.wf_label_dictionary[exp_name[i]].title())\n",
    "            \n",
    "            if polar:\n",
    "                ax1 = subfig.add_subplot(121, projection=\"polar\") # direction tuning\n",
    "            else:\n",
    "                ax1 = subfig.add_subplot(121) # tuning\n",
    "                \n",
    "            ax2 = subfig.add_subplot(222) #  resp\n",
    "            ax3 = subfig.add_subplot(224) #  error\n",
    "            ax = np.array([ax1, ax2, ax3])\n",
    "            axes.append(ax)\n",
    "\n",
    "    for sub_ax, ds in zip(axes, ds_list):\n",
    "        sub_ax = fp.plot_tuning_with_stats(ds, cell, tuning_kind=tuning_kind, error=error, norm=norm, polar=polar, axes=sub_ax)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "def plot_compare_all_vis_tuning(ds_list, cell, tuning_kind=['direction', 'orientation'], exp_name='', error='std', norm=True, polar=True, axes=None):\n",
    "    if axes is None:\n",
    "        axes = []\n",
    "        fig = plt.figure(layout='constrained', figsize=(36*cm, 2*len(data_list)*cm))\n",
    "        fig.suptitle(f\"Cell {cell}\", fontsize='x-large')\n",
    "        subfigs = fig.subfigures(nrows=2, ncols=2, hspace=0.07)\n",
    "    \n",
    "        for i, subfig in enumerate(subfigs.flatten()):\n",
    "            subfig.suptitle(processing_parameters.wf_label_dictionary[exp_name[i//2]].title())\n",
    "            \n",
    "            if polar:\n",
    "                ax1 = subfig.add_subplot(121, projection=\"polar\") # tuning\n",
    "            else:\n",
    "                ax1 = subfig.add_subplot(121) # tuning\n",
    "                \n",
    "            ax2 = subfig.add_subplot(222) #  resp\n",
    "            ax3 = subfig.add_subplot(224) #  error\n",
    "            ax = np.array([ax1, ax2, ax3])\n",
    "            axes.append(ax)\n",
    "\n",
    "    tuning_kind = ['direction', 'orientation'] * 2\n",
    "    for i, (ds, sub_ax) in enumerate(zip(ds_list, axes)):\n",
    "        sub_ax = fp.plot_tuning_with_stats(ds, cell, tuning_kind=tuning_kind[i], error=error, norm=norm, polar=polar, axes=sub_ax)\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d6f44-06e3-429d-8a2a-90cbef77290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict[f'{session_types[0]}_matched_norm_spikes_viewed_props'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001e280-133a-49b7-ad9c-966b989869ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_matched = [f'{session_types[0]}_matched_norm_spikes_viewed_props',\n",
    "                 f'{session_types[0]}_matched_norm_spikes_viewed_still_props']\n",
    "free_matched = [f'{session_types[1]}_matched_norm_spikes_viewed_props',\n",
    "                f'{session_types[1]}_matched_norm_spikes_viewed_still_props']\n",
    "datasets = [f'{session_types[0]}_matched_norm_spikes_viewed_props', f'{session_types[1]}_matched_norm_spikes_viewed_props']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3964bd-2600-41a4-b4b7-28669678fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ds = agg_dict[datasets[0]]\n",
    "strict_index = ref_ds.loc[(ref_ds.osi > 0.75)].index\n",
    "super_strict_index = ref_ds.loc[(ref_ds.osi >= 0.75) & (ref_ds.bootstrap_p_osi >= 0.95)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489028f4-5efe-40c5-a633-ec70d1908137",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_shifts = []\n",
    "\n",
    "for (idxRow, cell_fixed), (_, cell_free) in zip(agg_dict[datasets[0]].iloc[strict_index, :].iterrows(), agg_dict[datasets[1]].iloc[strict_index, :].iterrows()):\n",
    "\n",
    "    resultant_fixed = fk.wrap(cell_fixed.bootstrap_resultant_ori[:, -1], bound=180)\n",
    "    resultant_fixed = resultant_fixed[~np.isnan(resultant_fixed)]\n",
    "    # ci_fixed = st.t.interval(alpha=0.95, df=len(resultant_fixed)-1, loc=np.mean(resultant_fixed), scale=st.sem(resultant_fixed)) \n",
    "    ci_fixed = st.norm.interval(confidence=0.95, loc=np.mean(resultant_fixed), scale=st.sem(resultant_fixed)) \n",
    "\n",
    "    del_ci_fixed = ci_fixed[-1] - ci_fixed[0]\n",
    "    \n",
    "    resultant_free = fk.wrap(cell_free.bootstrap_resultant_ori[:, -1], bound=180)\n",
    "    resultant_free = resultant_free[~np.isnan(resultant_free)]\n",
    "    # ci_free = st.t.interval(alpha=0.95, df=len(resultant_free)-1, loc=np.mean(resultant_free), scale=st.sem(resultant_free)) \n",
    "    ci_free = st.norm.interval(confidence=0.95, loc=np.mean(resultant_free), scale=st.sem(resultant_free)) \n",
    "    del_ci_free = ci_free[-1] - ci_free[0]\n",
    "    \n",
    "    # Check if orientation tuned or not\n",
    "    if del_ci_fixed > 20:\n",
    "        # The cell is not orientation tuned\n",
    "        del_po = np.nan\n",
    "        sig_shift = 0\n",
    "    else:\n",
    "        # Get delta preferred orientation\n",
    "        po_fixed = fk.wrap(cell_fixed.resultant_ori[-1], bound=180)\n",
    "        po_free = fk.wrap(cell_free.resultant_ori[-1], bound=180)\n",
    "        if (np.isnan(po_fixed)) or (np.isnan(po_free)):\n",
    "            po_fixed = cell_fixed.pref_ori\n",
    "            po_free = cell_free.pref_ori\n",
    "        del_po = po_free - po_fixed\n",
    "        del_po_wrapped = fk.wrap(del_po, bound=180)\n",
    "    \n",
    "        # determine significance of shift\n",
    "        if ~(ci_fixed[0] <= po_free <= ci_fixed[1]) and ~(ci_free[0] <= po_fixed <= ci_free[1]):\n",
    "            # Shift is significant\n",
    "            sig_shift = 1\n",
    "        else:\n",
    "            # Shift is not significant    \n",
    "            sig_shift = 0\n",
    "    \n",
    "    tuning_shifts.append([idxRow, po_fixed, po_free, del_po, del_po_wrapped, sig_shift, cell_fixed.mouse, cell_fixed.date])\n",
    "\n",
    "tuning_shifts = pd.DataFrame(data=tuning_shifts, columns=['', f'po_{session_shorthand[0]}', f'po_{session_shorthand[1]}', 'delta_po', 'delta_po_wrapped', 'is_sig_po', 'mouse', 'date'])\n",
    "tuning_shifts = tuning_shifts.set_index(tuning_shifts.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c177cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = hv.Points(tuning_shifts[[f'po_{session_shorthand[0]}', f'po_{session_shorthand[1]}']].to_numpy())\n",
    "scatter.opts(xlim=(-1, 181), xlabel=f'{session_shorthand[0].title()} Pref. Ori.', xticks=[0, 45, 90, 135, 180],\n",
    "             ylim=(-1, 181), ylabel=f'{session_shorthand[1].title()} Pref. Ori.', yticks=[0, 45, 90, 135, 180],\n",
    "             size=10, width=400, height=400)\n",
    "line = hv.Curve(np.arange(0, 180)).opts(color='black', alpha=0.5)\n",
    "shift_po_plot = line * scatter\n",
    "# line*scatter.hist(dimension=['x','y'], num_bins=18)\n",
    "save_path = os.path.join(figure_save_path, f\"shift_po_{save_suffix}.png\")\n",
    "shift_po_plot = fp.save_figure(shift_po_plot, save_path=save_path, fig_width=10, dpi=800, fontsize='screen', target='both', display_factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee8a1a-ab41-47d3-80a3-b4909bd83dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 1.01, 0.05)\n",
    "plt.hist([agg_dict[datasets[0]].responsivity_ori, agg_dict[datasets[1]].responsivity_ori], bins=bins, edgecolor=\"black\")\n",
    "plt.legend(session_shorthand)\n",
    "plt.axvline(0.25, c='r')\n",
    "plt.title('responsivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc27c3-8ec4-4ceb-9efd-aad2cd3839ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_shifts.groupby('mouse').apply(lambda x: x.is_sig_po.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cbfba-93f2-4c0f-8d93-aebf8cb50cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_sig_po_shift_frac = tuning_shifts.is_sig_po.sum() / tuning_shifts.is_sig_po.count() \n",
    "print(overall_sig_po_shift_frac)\n",
    "tuning_shifts.groupby('mouse').apply(lambda x: x.is_sig_po.sum() / x.is_sig_po.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc698f-8b0d-41ad-aba1-edc180603cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies, edges = np.histogram(tuning_shifts[tuning_shifts.is_sig_po == 1].delta_po.to_numpy(), 36)\n",
    "hv.Histogram((edges, frequencies)).opts(width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e05d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096c76b-966e-4192-8d2d-764da3db9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tuning_shifts[tuning_shifts.is_sig_po == 1].groupby('mouse').apply(lambda x: np.histogram(x.delta_po.to_numpy(), 36)).to_list()\n",
    "layout = hv.Layout([hv.Histogram((edges, frequencies)).opts(width=400) for frequencies, edges in x]).opts(shared_axes=False)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b94bba-8eff-48d1-a7fa-76aa5516c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "datasets = [f'{session_types[0]}_matched_norm_spikes_viewed_still_props', f'{session_types[1]}_matched_norm_spikes_viewed_still_props']\n",
    "\n",
    "matched_vis_fig = interactive(plot_compare_all_vis_tuning,\n",
    "                              ds_list=widgets.fixed([agg_dict[dataset] for dataset in datasets]),\n",
    "                              cell=tuning_shifts[tuning_shifts.is_sig_po == 1].index, \n",
    "                              tuning_kind = widgets.fixed(['direction', 'orientation']),\n",
    "                              exp_name = widgets.fixed(session_types),\n",
    "                              error = ['std', 'sem'],\n",
    "                              polar=[True, False],\n",
    "                              norm=widgets.fixed(True),\n",
    "                              axes=widgets.fixed(None))\n",
    "matched_vis_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5922ef-9e52-46ec-b493-ca1680323fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_shifts.loc[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f230a-1505-44dc-a05f-cd9e77c32bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycircstat as circ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b454027-799a-4862-9418-6900db91f78f",
   "metadata": {},
   "source": [
    "# DSI/OSI Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568b3e4-e7d3-4b17-836a-a482c562680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_matched = [f'{session_types[1]}_matched_norm_spikes_viewed_props',\n",
    "                f'{session_types[1]}_matched_norm_spikes_viewed_still_props']\n",
    "fixed_matched = [f'{session_types[0]}_matched_norm_spikes_viewed_props',\n",
    "                 f'{session_types[0]}_matched_norm_spikes_viewed_still_props']\n",
    "matched_free_dir = free_matched[0:1]\n",
    "matched_fixed_dir = fixed_matched[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f078b7-1bbf-4b87-8af7-f0d991af7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list_matched_free = [agg_dict[d] for d in matched_free_dir]\n",
    "ds_list_matched_fixed = [agg_dict[d] for d in matched_fixed_dir]\n",
    "cols = ['osi', 'dsi_abs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594a1f09-2bca-4170-8b72-eb776cb58a7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Matched Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa9f51-b48f-4f00-9767-b59b2d2b6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "ds_list = [agg_dict[f'{s_type}_matched_norm_spikes_viewed_props'] for s_type in session_types]\n",
    "for ds, exp_type in zip(ds_list, session_shorthand):\n",
    "    frac_ori_tuned = []\n",
    "    frac_dir_tuned = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in ds.groupby('mouse'):\n",
    "        ori_tuned = np.abs(group.osi) > 0.5\n",
    "        dir_tuned = np.abs(group.dsi_abs) > 0.5\n",
    "\n",
    "        # ori_tuned = (np.abs(group.osi) > 0.25) & (np.abs(group.dsi_nasal_temporal) <= 0.25)\n",
    "        # dir_tuned = (np.abs(group.osi) <= 0.25) & (np.abs(group.dsi_nasal_temporal) > 0.25)\n",
    "        frac_ori_tuned.append(ori_tuned.sum() / ori_tuned.count())\n",
    "        frac_dir_tuned.append(dir_tuned.sum() / dir_tuned.count())\n",
    "\n",
    "\n",
    "    df['group'] = [exp_type] * len(frac_ori_tuned)\n",
    "    df['Ori. Tuned'] = frac_ori_tuned\n",
    "    df['Dir. Tuned'] = frac_dir_tuned\n",
    "    df_list.append(df)\n",
    "    plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "matched_dsi_osi = pd.concat(df_list, axis=0)\n",
    "matched_dsi_osi= pd.melt(matched_dsi_osi, id_vars=['group'], value_vars=['Ori. Tuned', 'Dir. Tuned'])\n",
    "\n",
    "violinplot_matched_dsi_osi = hv.Violin(matched_dsi_osi, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=600,\n",
    "                                                                  ylim=(0, 1.1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  cmap=[fp.hv_blue_hex, fp.hv_orange_hex],\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"matched_frac_ori_dir_tuned.png\")\n",
    "# violinplot\n",
    "violinplot_matched_dsi_osi = fp.save_figure(violinplot_matched_dsi_osi, save_path=save_path, fig_width=16, dpi=800, fontsize='screen', target='screen', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6236ba-3871-4cd6-a889-3b8204936f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "comp_tuning_rank_sum = matched_dsi_osi.groupby(['variable', 'group'], group_keys=True).value.agg(list).unstack(level=1)\n",
    "comp_tuning_stats = comp_tuning_rank_sum.apply(lambda x: st.mannwhitneyu(x[session_shorthand[0]], x[session_shorthand[1]], alternative='two-sided'), axis=1)\n",
    "p_vals = [comp_tuning_stats.to_numpy()[i][1] for i in np.arange(comp_tuning_stats.shape[0])]\n",
    "print(comp_tuning_stats)\n",
    "multipletests(p_vals, alpha=0.05, method='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07627043-2d22-4886-97e5-7e10a3162e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "ds_list = [agg_dict[f'{s_type}_matched_norm_spikes_viewed_props'] for s_type in session_types]\n",
    "for ds, exp_type in zip(ds_list, session_shorthand):\n",
    "    df = pd.DataFrame()\n",
    "    df['OSI'] = ds.osi.abs().to_numpy()\n",
    "    df['DSI'] = ds.dsi_abs.abs().to_numpy()\n",
    "    df['group'] = [exp_type] * len(ds.osi)\n",
    "    df_list.append(df)\n",
    "    \n",
    "    # plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "matched_selectivity = pd.concat(df_list, axis=0)\n",
    "matched_selectivity = pd.melt(matched_selectivity, id_vars=['group'], value_vars=['OSI', 'DSI'])\n",
    "\n",
    "violinplot_selectivity_matched = hv.Violin(matched_selectivity, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Selectivity', \n",
    "                                                                  width=1000, height=600,\n",
    "                                                                  ylim=(-0.1, 1.1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  cmap=[fp.hv_blue_hex, fp.hv_orange_hex],\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"matched_selectivity.png\")\n",
    "violinplot_selectivity_matched = fp.save_figure(violinplot_selectivity_matched, save_path=save_path, fig_width=16, dpi=800, fontsize='screen', target='screen', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e73588-f43c-4770-968b-65bcba4c9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_inf(x):\n",
    "    x[x > np.percentile(x, 99)] = np.percentile(x, 99)\n",
    "    return x\n",
    "\n",
    "a = matched_selectivity[matched_selectivity.variable == 'OSI'].fillna(0).drop(columns='variable')\n",
    "a = a.groupby('group').agg(list).T.reset_index(drop=True)\n",
    "\n",
    "\n",
    "frequencies_free_osi, edges_free_osi = np.histogram(np.clip(a['Freely Moving'][0], 0, 1)\t, 20)\n",
    "frequencies_fixed_osi, edges_fixed_osi = np.histogram(np.clip(a['Head Fixed'][0], 0, 1), 20)\n",
    "\n",
    "cell_match_hist_osi = hv.Overlay([hv.Histogram((frequencies_free_osi, edges_free_osi), label='Freely Moving').opts(alpha=0.5, fill_color=fp.hv_blue_rgb), \n",
    "                                  hv.Histogram((frequencies_fixed_osi, edges_fixed_osi), label='Head Fixed').opts(alpha=0.5, fill_color=fp.hv_orange_rgb)])\n",
    "\n",
    "b = matched_selectivity[matched_selectivity.variable == 'DSI'].fillna(0).drop(columns='variable')\n",
    "b = b.groupby('group').agg(list).T.reset_index(drop=True)\n",
    "\n",
    "frequencies_free_dsi, edges_free_dsi = np.histogram(np.clip(b['Freely Moving'][0], 0, 1), 20)\n",
    "frequencies_fixed_dsi, edges_fixed_dsi = np.histogram(np.clip(b['Head Fixed'][0], 0, 1), 20)\n",
    "\n",
    "cell_match_hist_dsi = hv.Overlay([hv.Histogram((frequencies_free_dsi, edges_free_dsi)).opts(alpha=0.5, fill_color=fp.hv_blue_rgb), \n",
    "                                  hv.Histogram((frequencies_fixed_dsi, edges_fixed_dsi)).opts(alpha=0.5, fill_color=fp.hv_orange_rgb)])\n",
    "\n",
    "layout_matched_still = cell_match_hist_dsi.opts(height=300, width=400, xlabel='DSI') + cell_match_hist_osi.opts(height=300, width=500, xlabel='OSI', ylabel='', legend_position='right', fontsize={'legend': 10})\n",
    "layout_matched_still\n",
    "# save_path = os.path.join(figure_save_path, \"Fig4\", \"unmatched_dsi_osi_hist.png\")\n",
    "# layout_matched_still = fp.save_figure(layout_matched_still, save_path=save_path, fig_width=18, dpi=1000, fontsize='poster', target='both', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1183a3a-1fd6-4e0f-999a-c3474401df7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unmatched Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30fe9e-fe0b-4b83-94e4-d24127c47808",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "ds_list = [agg_dict[f'{s_type}_unmatched_norm_spikes_viewed_props'] for s_type in session_types]\n",
    "for ds, exp_type in zip(ds_list, session_shorthand):\n",
    "    frac_ori_tuned = []\n",
    "    frac_dir_tuned = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in ds.groupby('mouse'):\n",
    "        ori_tuned = np.abs(group.osi) > 0.75\n",
    "        dir_tuned = np.abs(group.dsi_abs) > 0.75\n",
    "        frac_ori_tuned.append(ori_tuned.sum() / ori_tuned.count())\n",
    "        frac_dir_tuned.append(dir_tuned.sum() / dir_tuned.count())\n",
    "\n",
    "\n",
    "    df['group'] = [exp_type] * len(frac_ori_tuned)\n",
    "    df['Ori. Tuned'] = frac_ori_tuned\n",
    "    df['Dir. Tuned'] = frac_dir_tuned\n",
    "    df_list.append(df)\n",
    "    plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "unmatched_dsi_osi = pd.concat(df_list, axis=0)\n",
    "unmatched_dsi_osi= pd.melt(unmatched_dsi_osi, id_vars=['group'], value_vars=['Ori. Tuned', 'Dir. Tuned'])\n",
    "\n",
    "violinplot_dsi_osi_unmatched = hv.Violin(unmatched_dsi_osi, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=400,\n",
    "                                                                  ylim=(0, 1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  cmap=[fp.hv_blue_hex, fp.hv_orange_hex],\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"unmatched_frac_ori_dir_tuned.png\")\n",
    "# violinplot\n",
    "violinplot_dsi_osi_unmatched = fp.save_figure(violinplot_dsi_osi_unmatched, save_path=save_path, fig_width=16, dpi=1000, fontsize='screen', target='screen', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727ccf8-491a-40e0-aa56-efd7b0b35850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "comp_tuning_rank_sum = unmatched_dsi_osi.groupby(['variable', 'group'], group_keys=True).value.agg(list).unstack(level=1)\n",
    "comp_tuning_stats = comp_tuning_rank_sum.apply(lambda x: st.mannwhitneyu(x['Freely Moving'], x['Head Fixed'], alternative='two-sided'), axis=1)\n",
    "p_vals = [comp_tuning_stats.to_numpy()[i][1] for i in np.arange(comp_tuning_stats.shape[0])]\n",
    "print(comp_tuning_stats)\n",
    "multipletests(p_vals, alpha=0.05, method='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc3d79-fed5-4096-a04a-fe0a5c76c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "ds_list = [agg_dict[f'{s_type}_unmatched_norm_spikes_viewed_props'] for s_type in session_types]\n",
    "for ds, exp_type in zip(ds_list, session_shorthand):\n",
    "    df = pd.DataFrame()\n",
    "    df['OSI'] = ds.osi.abs().to_numpy()\n",
    "    df['DSI'] = ds.dsi_abs.abs().to_numpy()\n",
    "    df['group'] = [exp_type] * len(ds.osi)\n",
    "    df_list.append(df)\n",
    "    \n",
    "    # plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "unmatched_selectivity = pd.concat(df_list, axis=0)\n",
    "unmatched_selectivity = pd.melt(unmatched_selectivity, id_vars=['group'], value_vars=['OSI', 'DSI'])\n",
    "\n",
    "violinplot_selectivity_unmatched = hv.Violin(unmatched_selectivity, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Selectivity', \n",
    "                                                                  width=1000, height=400,\n",
    "                                                                  ylim=(-0.1, 1.1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"unmatched_selectivity.png\")\n",
    "violinplot_selectivity_unmatched = fp.save_figure(violinplot_selectivity_unmatched, save_path=save_path, fig_width=16, dpi=1000, fontsize='poster', target='screen', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd6cb8-313d-4cf0-b03b-c4cb97d474a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = unmatched_selectivity[unmatched_selectivity.variable == 'OSI'].fillna(0).drop(columns='variable')\n",
    "a = a.groupby('group').agg(list).T.reset_index(drop=True)\n",
    "\n",
    "frequencies_free_osi, edges_free_osi = np.histogram(a['Freely Moving'][0], 20)\n",
    "frequencies_fixed_osi, edges_fixed_osi = np.histogram(a['Head Fixed'][0], 20)\n",
    "\n",
    "unmatched_hist_osi = hv.Overlay([hv.Histogram((frequencies_free_osi, edges_free_osi), label='Freely Moving').opts(alpha=0.5, fill_color=fp.hv_blue_rgb), \n",
    "                                  hv.Histogram((frequencies_fixed_osi, edges_fixed_osi), label='Head Fixed').opts(alpha=0.5, fill_color=fp.hv_orange_rgb)])\n",
    "\n",
    "b = unmatched_selectivity[unmatched_selectivity.variable == 'DSI'].fillna(0).drop(columns='variable')\n",
    "b = b.groupby('group').agg(list).T.reset_index(drop=True)\n",
    "\n",
    "frequencies_free_dsi, edges_free_dsi = np.histogram(b['Freely Moving'][0], 20)\n",
    "frequencies_fixed_dsi, edges_fixed_dsi = np.histogram(b['Head Fixed'][0], 20)\n",
    "\n",
    "unmatched_hist_dsi = hv.Overlay([hv.Histogram((frequencies_free_dsi, edges_free_dsi)).opts(alpha=0.5, fill_color=fp.hv_blue_rgb), \n",
    "                                  hv.Histogram((frequencies_fixed_dsi, edges_fixed_dsi)).opts(alpha=0.5, fill_color=fp.hv_orange_rgb)])\n",
    "\n",
    "layout_unmatched = unmatched_hist_dsi.opts(height=300, width=400, xlabel='DSI') + unmatched_hist_osi.opts(height=300, width=500, xlabel='OSI', ylabel='', legend_position='right', fontsize={'legend': 10})\n",
    "layout_unmatched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31179cc2-6bad-4381-ab5f-cbf3260f9be7",
   "metadata": {},
   "source": [
    "## Compare matched/unmatched strongly tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6635ad-308a-4bae-b7b4-7e860956bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_selectivity['super_group'] = 'matched'\n",
    "unmatched_selectivity['super_group'] = 'unmatched'\n",
    "all_selectivity = pd.concat([matched_selectivity, unmatched_selectivity]).fillna(0)\n",
    "violinplot_selectivity = hv.Violin(all_selectivity, ['variable', 'group', 'super_group'], 'value').opts(xlabel='', ylabel='Selectivity', \n",
    "                                                                  width=1000, height=200,\n",
    "                                                                  ylim=(-0.05, 1.05),\n",
    "                                                                  violin_color=hv.dim('super_group'),\n",
    "                                                                  cmap='Category10',\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "\n",
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "rank_sum = all_selectivity.groupby(['variable', 'group', 'super_group'], group_keys=True).value.agg(list).unstack(level=-1)\n",
    "stats = rank_sum.apply(lambda x: st.ranksums(x['matched'], x['unmatched'], alternative='two-sided'), axis=1)\n",
    "p_vals = [stats.to_numpy()[i][1] for i in np.arange(stats.shape[0])]\n",
    "print(p_vals)\n",
    "print(multipletests(p_vals, alpha=0.05, method='bonferroni'))\n",
    "\n",
    "save_path = os.path.join(figure_save_path, \"selectivity_dist_comp.png\")\n",
    "violinplot_selectivity = fp.save_figure(violinplot_selectivity, save_path=save_path, fig_width=30, dpi=1200, fontsize='screen', target='screen', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4228625-61d6-4dd8-b850-9a1284a51681",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34466081-0ca4-44e0-89a4-245523c53c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_paths = []\n",
    "selectivity_array = all_selectivity.groupby(['variable', 'group', 'super_group']).agg(list).values\n",
    "num_comps = a.shape[0]/2\n",
    "\n",
    "selectivity_plot_list = []\n",
    "for i, (a, b) in enumerate(zip(selectivity_array[::2], selectivity_array[1::2])):\n",
    "    save_path = os.path.join(figure_save_path, f\"selectivity_dist_comp_histogram_{i}.png\")\n",
    "    \n",
    "    frequencies_matched, edges_matched = np.histogram(np.clip(a[0], 0, 1), 20)\n",
    "    frequencies_matched = frequencies_matched.astype(float) / np.max(frequencies_matched)\n",
    "    frequencies_unmatched, edges_unmatched = np.histogram(np.clip(b[0], 0, 1), 20)\n",
    "    frequencies_unmatched = frequencies_unmatched.astype(float) / np.max(frequencies_unmatched.astype(float))\n",
    "\n",
    "    matched_hist = hv.Histogram((frequencies_matched, edges_matched), label='matched').opts(alpha=0.5, xlabel='', width=800, height=600, fill_color=fp.hv_mpi_green_rgb, ylabel=\"Probability\")\n",
    "    unmatched_hist = hv.Histogram((frequencies_unmatched, edges_unmatched), label='unmatched').opts(alpha=0.5, xlabel='', width=800, height=600, fill_color=fp.hv_mpi_yellow_rgb)\n",
    "    \n",
    "    if i > 0:\n",
    "        matched_hist.opts(yaxis=None, width=600)\n",
    "        unmatched_hist.opts(yaxis=None, width=600)\n",
    "    \n",
    "    hist_overlay = hv.Overlay([matched_hist, unmatched_hist])\n",
    "    hist_overlay.opts(show_legend=False)\n",
    "\n",
    "    if i == 0:\n",
    "        hist_overlay = fp.save_figure(hist_overlay, save_path=save_path, fig_width=8, dpi=1200, fontsize='screen', target='screen', display_factor=0.1)\n",
    "    else:\n",
    "        hist_overlay = fp.save_figure(hist_overlay, save_path=save_path, fig_width=6, dpi=1200, fontsize='screen', target='screen', display_factor=0.1)\n",
    "\n",
    "    selectivity_plot_list.append(hist_overlay)\n",
    "\n",
    "selectivity_layout = hv.Layout(selectivity_plot_list)\n",
    "selectivity_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5203dd-8efa-4378-bb5b-842d3e606568",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_dsi_osi['super_group'] = 'matched'\n",
    "unmatched_dsi_osi['super_group'] = 'unmatched'\n",
    "all_dsi_osi = pd.concat([matched_dsi_osi, unmatched_dsi_osi]).fillna(0)\n",
    "violinplot = hv.Violin(all_dsi_osi, ['variable', 'group', 'super_group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=200,\n",
    "                                                                  ylim=(-0.05, 1),\n",
    "                                                                  violin_color=hv.dim('super_group'),\n",
    "                                                                  cmap=[fp.hv_mpi_green_hex, fp.hv_mpi_yellow_hex],\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "\n",
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "rank_sum = all_dsi_osi.groupby(['variable', 'group', 'super_group'], group_keys=True).value.agg(list).unstack(level=-1)\n",
    "stats = rank_sum.apply(lambda x: st.ranksums(x['matched'], x['unmatched'], alternative='two-sided'), axis=1)\n",
    "p_vals = [stats.to_numpy()[i][1] for i in np.arange(stats.shape[0])]\n",
    "print(p_vals)\n",
    "print(multipletests(p_vals, alpha=0.05, method='bonferroni'))\n",
    "\n",
    "save_path = os.path.join(figure_save_path, \"sig_frac_selectivity_dsi_osi.png\")\n",
    "violinplot = fp.save_figure(violinplot, save_path=save_path, fig_width=30, dpi=1200, fontsize='poster', target='both', display_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbd5f4-ef00-46a3-a7cd-dd5d93c2286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_dsi_osi_array = all_dsi_osi.groupby(['variable', 'group', 'super_group']).agg(list).values\n",
    "num_comps = a.shape[0]/2\n",
    "\n",
    "dsi_osi_plot_list = []\n",
    "for a, b in zip(sig_dsi_osi_array[::2], sig_dsi_osi_array[1::2]):\n",
    "    frequencies_matched, edges_matched = np.histogram(a[0], 20)\n",
    "    frequencies_unmatched, edges_unmatched = np.histogram(b[0], 20)\n",
    "\n",
    "    hist_overlay =  hv.Overlay([hv.Histogram((frequencies_unmatched, edges_unmatched), label='unmatched').opts(alpha=0.5, fill_color=fp.hv_orange_rgb), \n",
    "                                hv.Histogram((frequencies_matched, edges_matched), label='matched').opts(alpha=0.5, fill_color=fp.hv_blue_rgb)])\n",
    "\n",
    "    dsi_osi_plot_list.append(hist_overlay)\n",
    "\n",
    "dsi_osi_layout = hv.Layout(dsi_osi_plot_list)\n",
    "dsi_osi_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3299d8-1b28-4753-a776-8f23faf8e119",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deef3d6-2062-415d-84a6-bef6f11d5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap.umap_ import UMAP\n",
    "from rastermap import Rastermap\n",
    "import sklearn.preprocessing as preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeefade2-717d-4e86-a3de-9cc87ad843b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_subset = '_matched'\n",
    "kinem_label_list = processing_parameters.variable_list_free + processing_parameters.variable_list_fixed\n",
    "labels = kinem_label_list + ['norm_spikes_viewed_props']\n",
    "labels = ['_'.join((cell_subset, label)) for label in labels]\n",
    "\n",
    "data_dict = {}\n",
    "for label in labels:\n",
    "    agg_keys = [key for key in agg_dict.keys() if label in key]\n",
    "\n",
    "    for key in agg_keys:\n",
    "        ds = agg_dict[key]\n",
    "        base_label = '_'.join(label.split('_')[len(cell_subset.split('_')):])\n",
    "        if base_label in kinem_label_list: \n",
    "            tuning = ds['Qual_index']\n",
    "            data_dict[base_label] = tuning\n",
    "        else:\n",
    "            tuning_dsi = ds['dsi_abs']\n",
    "            tuning_osi = ds['osi']\n",
    "            data_dict['dsi'] = np.clip(tuning_dsi, 0, 1)\n",
    "            data_dict['osi'] = np.clip(tuning_osi, 0, 1)\n",
    "\n",
    "\n",
    "raw_tunings = pd.DataFrame.from_dict(data_dict)\n",
    "raw_tunings = raw_tunings.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f99a56-a840-412b-8631-8cb7ac50bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunings = preproc.StandardScaler().fit_transform(raw_tunings.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889338a-9d8c-45b6-a744-31c682278c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047ba5a-06f5-4fd0-8490-cdab8b3148c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_subset = tunings[np.random.choice(tunings.shape[0], tunings.shape[0], replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9b0a7-d6e9-4eac-8453-8e44f261bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform umap on the fit cell tuning\n",
    "reducer1 = UMAP(min_dist=0.1, n_neighbors=20)\n",
    "embedded_data1 = reducer1.fit_transform(tuning_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e85fe4-31db-4cc2-ab6b-062077e1b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = 99\n",
    "predictor_columns = data_dict.keys()    #['dsi', 'osi', 'responsivity']\n",
    "plot_list = []\n",
    "\n",
    "for predictor_column in predictor_columns:\n",
    "    label_idx = [idx for idx, el in enumerate(predictor_columns) if predictor_column == el]\n",
    "    raw_labels = tuning_subset[:, label_idx]\n",
    "    \n",
    "    raw_labels = np.abs(raw_labels)\n",
    "    \n",
    "    raw_labels[raw_labels>np.percentile(raw_labels, perc)] = np.percentile(raw_labels, perc)\n",
    "    raw_labels[raw_labels<np.percentile(raw_labels, 100-perc)] = np.percentile(raw_labels, 100-perc)\n",
    "    \n",
    "    plot_data = np.concatenate([embedded_data1, raw_labels.reshape((-1, 1))], axis=1)\n",
    "\n",
    "    umap_plot = hv.Scatter(plot_data, vdims=['Dim 2', 'Parameter'], kdims=['Dim 1'])\n",
    "    # umap_plot = hv.HexTiles(umap_data, kdims=['Dim 1', 'Dim 2'])\n",
    "    umap_plot.opts(colorbar=False, color='Parameter', cmap='Spectral_r', alpha=1, xaxis=None, yaxis=None, tools=['hover'])\n",
    "    umap_plot.opts(width=300, height=300, size=2, title=processing_parameters.wf_label_dictionary[predictor_column])\n",
    "\n",
    "    save_name = os.path.join(figure_save_path, f\"UMAP_{predictor_column}_{cell_subset}.png\")   \n",
    "    # umap_plot = fp.save_figure(umap_plot, save_path=save_name, fig_width=6, dpi=1000, fontsize='screen', target='save', display_factor=0.1)\n",
    "    plot_list.append(umap_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930e7a6-30eb-49e2-b4ff-ff7ffbafeb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = hv.Layout(plot_list).cols(5)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be989f38-a5ca-47fa-8064-cff2b81d0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_columns = data_dict.keys()\n",
    "target_field = 'dsi'\n",
    "\n",
    "\n",
    "label_idx = [idx for idx, el in enumerate(predictor_columns) if target_field == el]\n",
    "raw_labels = tuning_subset[:, label_idx]\n",
    "\n",
    "raw_labels = np.abs(raw_labels)\n",
    "\n",
    "raw_labels[raw_labels>np.percentile(raw_labels, perc)] = np.percentile(raw_labels, perc)\n",
    "raw_labels[raw_labels<np.percentile(raw_labels, 100-perc)] = np.percentile(raw_labels, 100-perc)\n",
    "\n",
    "plot_data = np.concatenate([embedded_data1, raw_labels.reshape((-1, 1))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0695f-e106-4334-8f49-13837f112825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# umap plot of the fit cell tunings\n",
    "umap_plot = hv.Scatter(plot_data, vdims=['Dim 2', 'Parameter'], kdims=['Dim 1'])\n",
    "# umap_plot = hv.HexTiles(plot_data, vdims=['Dim 2', 'Parameter'], kdims=['Dim 1'])\n",
    "umap_plot.opts(colorbar=True, color='Parameter', cmap='Spectral_r', tools=['hover'], alpha=1)\n",
    "umap_plot.opts(width=500, height=500, size=5)\n",
    "\n",
    "# assemble the file name\n",
    "# save_name = os.path.join(save_path, '_'.join(('poster', 'UMAP')) + '.png')\n",
    "# # save the figure\n",
    "# fig = fp.save_figure(umap_plot, save_name, fig_width=15, dpi=1200, fontsize='poster', target='screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebb446-2fd7-41e4-969c-7108364b5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the tunings from MINE\n",
    "ticks = [(idx+0.5, processing_parameters.wf_label_dictionary[el]) for idx, el in enumerate(predictor_columns)]\n",
    "plot_matrix = raw_tunings.dropna().to_numpy().copy().T\n",
    "plot_matrix[plot_matrix<0.05] = 0\n",
    "model = Rastermap(n_clusters=2, n_PCs=200)\n",
    "model.fit(plot_matrix)\n",
    "plot_matrix = plot_matrix[model.isort, :]\n",
    "plot = hv.Raster(plot_matrix)\n",
    "plot.opts(width=1000, height=600, cmap='RdBu_r', tools=['hover'], clim=(-1, 1), xticks=ticks, xrotation=45, xlabel='', ylabel='Cells', colorbar=True)\n",
    "\n",
    "# assemble the file name\n",
    "save_name = os.path.join(save_path, '_'.join(('Fig5', 'MINE_tunings')) + '.png')\n",
    "# save the figure\n",
    "fig = fp.save_figure(plot, save_name, fig_width=7, dpi=1200, fontsize='poster', target='screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802817f2-f8ad-4806-9502-d41059ef66a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
