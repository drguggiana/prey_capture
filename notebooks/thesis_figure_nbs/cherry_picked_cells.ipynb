{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "import paths\n",
    "import processing_parameters\n",
    "import functions_bondjango as bd\n",
    "import functions_misc as fmisc\n",
    "import functions_matching as fm\n",
    "import functions_data_handling as fdh\n",
    "import functions_tuning as tuning\n",
    "import functions_plotting as fp\n",
    "import functions_kinematic as fk\n",
    "from wirefree_experiment import WirefreeExperiment, DataContainer\n",
    "from functions_wirefree_trigger_fix import get_trial_duration_stats\n",
    "\n",
    "# fig_path = paths.wf_figures_path\n",
    "data_path = r\"D:\\thesis\\WF_Figures\\full\\repeat_normal_VTuningWF\"\n",
    "fig_path = r\"D:\\thesis\\figures\"\n",
    "\n",
    "session_shorthand = ['session1', 'session2']    # ['session1', 'session2'], ['free', 'fixed']\n",
    "sort = 'slug'   # 'rig', 'slug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_partial_or_long_trials(df, min_trial_length=4.5, max_trial_length=5.5):\n",
    "    \"\"\"\n",
    "    This function drops trials that are shorter than min_trial_length (partial trials) and\n",
    "    trials that are longer than max_trial_length (errors in trial number indexing) from the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The dataframe containing the trials.\n",
    "    min_trial_length (float): The minimum length for a trial. Defaults to 4.5.\n",
    "    max_trial_length (float): The maximum length for a trial. Defaults to 5.5.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The dataframe after dropping the partial and long trials.\n",
    "    \"\"\"\n",
    "\n",
    "    trial_lengths = df[df.trial_num > 0].groupby('trial_num').apply(lambda x: x.shape[0] / processing_parameters.wf_frame_rate)\n",
    "\n",
    "    # Drop trials that are shorter than min_trial_length (partial trials)\n",
    "    short_trials = trial_lengths[trial_lengths < min_trial_length].index\n",
    "    df = df.drop(df[df.trial_num.isin(short_trials)].index)\n",
    "\n",
    "    # Drop trials that are longer than max_trial_length (errors in trial number indexing)\n",
    "    long_trials = trial_lengths[trial_lengths > max_trial_length].index\n",
    "    df = df.drop(df[df.trial_num.isin(long_trials)].index).reset_index(drop=True)\n",
    "\n",
    "    return df   \n",
    "\n",
    "\n",
    "def filter_viewed_trials(kinematics, activity_df):\n",
    "\n",
    "    # Filter trials by head pitch if freely moving\n",
    "    pitch_lower_cutoff = processing_parameters.head_pitch_cutoff[0]\n",
    "    pitch_upper_cutoff = processing_parameters.head_pitch_cutoff[1]\n",
    "    view_fraction = processing_parameters.view_fraction\n",
    "    kinematics['viewed'] = np.logical_and(kinematics['head_pitch'].to_numpy() >= pitch_lower_cutoff,\n",
    "                                          kinematics['head_pitch'].to_numpy() <= pitch_upper_cutoff)\n",
    "    viewed_trials = kinematics.groupby('trial_num').filter(\n",
    "        lambda x: (x['viewed'].sum() / len(x['viewed'])) > view_fraction).trial_num.unique()\n",
    "\n",
    "    viewed_activity_df = activity_df.loc[activity_df.trial_num.isin(viewed_trials)].copy()\n",
    "    return viewed_activity_df\n",
    "\n",
    "\n",
    "def parse_trial_frames(df, pre_trial=0, post_trial=0):\n",
    "    trial_idx_frames = df[df.trial_num >= 1.0].groupby(['trial_num']).apply(\n",
    "        lambda x: [x.index[0] - (pre_trial * processing_parameters.wf_frame_rate), \n",
    "                   x.index[0], x.index[-1], \n",
    "                   x.index[-1] + (post_trial * processing_parameters.wf_frame_rate) + 1]\n",
    "        ).to_numpy()\n",
    "    trial_idx_frames = np.vstack(trial_idx_frames)\n",
    "\n",
    "    if trial_idx_frames[0, 0] < 0:\n",
    "        trial_idx_frames[0, 0] = 0\n",
    "\n",
    "    if trial_idx_frames[-1, -1] > df.index[-1]:\n",
    "        trial_idx_frames[-1, -1] = df.index[-1]\n",
    "\n",
    "    # Get the shifts from the zero point (important for plotting)\n",
    "    max_zero_idx_shift = np.max(trial_idx_frames[:, 1] - trial_idx_frames[:, 0])\n",
    "    \n",
    "    traces = []\n",
    "    for i, frame in enumerate(trial_idx_frames):\n",
    "        df_slice = df.iloc[frame[0]:frame[-1], :].copy()\n",
    "        df_slice['trial_num'] = df_slice.loc[frame[1], 'trial_num']\n",
    "        df_slice['direction'] = df_slice.loc[frame[1], 'direction']\n",
    "        df_slice['direction_wrapped'] = df_slice.loc[frame[1], 'direction_wrapped']\n",
    "        df_slice['orientation'] = df_slice.loc[frame[1], 'orientation']\n",
    "        zero_idx_shift = np.abs((frame[1] - frame[0]) - max_zero_idx_shift)\n",
    "        df_slice['zero_idx_shift'] = zero_idx_shift\n",
    "\n",
    "        traces.append(df_slice)\n",
    "    \n",
    "    traces = pd.concat(traces, axis=0).reset_index(drop=True)\n",
    "    return traces, trial_idx_frames\n",
    "\n",
    "\n",
    "def trial_average_response(ds, cells_to_match, stim_type):\n",
    "    \n",
    "    ds.dropna(inplace=True)\n",
    "    idxs_shifts = ds.groupby(['trial_num']).apply(lambda x: np.unique(x.zero_idx_shift)[0]).reset_index()\n",
    "    idxs_shifts = idxs_shifts.rename({0: 'zero_idx_shift'}, axis=1)\t\n",
    "\n",
    "    if stim_type in ['orientation', 'direction', 'direction_wrapped']:\n",
    "        trials_per_stim = ds.groupby([stim_type, 'trial_num'])[cells_to_match].agg(list).reset_index()\n",
    "        trials_per_stim = trials_per_stim.join(idxs_shifts.set_index('trial_num'), on='trial_num')\n",
    "        trials_per_stim = trials_per_stim.groupby([stim_type]).agg(list)\n",
    "\n",
    "        idxs_shifts = trials_per_stim['zero_idx_shift'].copy()\n",
    "        trial_array = trials_per_stim.copy()\n",
    "\n",
    "        for i, row in trials_per_stim.iterrows():\n",
    "            for cell in cells_to_match:\n",
    "                shifts = list(idxs_shifts.loc[row.name])\n",
    "                trial_array.loc[i, cell] = fmisc.list_lists_to_array(row[cell], alignment='left')\n",
    "\n",
    "        trial_averages = trial_array.applymap(np.nanmean, axis=0)\n",
    "        trial_averages = trial_averages.drop('zero_idx_shift', axis=1)\n",
    "        trial_array = trial_array.drop('zero_idx_shift', axis=1)  \n",
    "        \n",
    "    elif stim_type == 'vis':\n",
    "        trials_per_stim = ds.groupby('trial_num')[cells_to_match].agg(list)\n",
    "        trials_per_stim = trials_per_stim.join(idxs_shifts.set_index('trial_num'), on='trial_num')\n",
    "\n",
    "        idxs_shifts = trials_per_stim['zero_idx_shift'].copy()\n",
    "        trial_averages = trials_per_stim.iloc[0, :].copy()\n",
    "        trial_array = trials_per_stim.iloc[0, :].copy()\n",
    "\n",
    "        for cell in cells_to_match:\n",
    "            trials_agg = fmisc.list_lists_to_array(trials_per_stim[cell].to_list(), alignment='left')\n",
    "            trial_array[cell] = trials_agg\n",
    "            trial_averages[cell] = np.nanmean(trials_agg, axis=0) \n",
    "\n",
    "        trial_averages = trial_averages.drop('zero_idx_shift')\n",
    "        trial_array = trial_array.drop('zero_idx_shift')  \n",
    "        \n",
    "    else:\n",
    "        raise Exception('Invalid stim_type')\n",
    "    \n",
    "\n",
    "    return trial_averages, trial_array\n",
    "\n",
    "\n",
    "def hv_plot_vis_trial_averages(trial_averages, trials, cells, stim_type):\n",
    "\n",
    "    plt_list = []\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "\n",
    "        cell_resps = trials[cell]\n",
    "        cell_mean = trial_averages[cell]\n",
    "        \n",
    "        if stim_type in ['orientation', 'direction']:\n",
    "            \n",
    "            for k in range(cell_resps.shape[-1]):\n",
    "                resps = cell_resps.iloc[k]\n",
    "                mean = cell_mean.iloc[k]\n",
    "                \n",
    "                trials_list = [hv.Curve(resps[r, :]).opts(color='k', alpha=0.25, line_width=0.75) for r in np.arange(resps.shape[0])]\n",
    "                mean_list = [hv.Curve(mean).opts(color='r', xlabel='', ylabel='')]\n",
    "                \n",
    "                if i == 0:\n",
    "                    [mean_plot.opts(title=f\"{cell_resps.index[k]:.1f}\") for mean_plot in mean_list]\n",
    "\n",
    "                plt_list.append(hv.Overlay(trials_list + mean_list))\n",
    "                \n",
    "        elif stim_type == 'vis':\n",
    "            resps = cell_resps\n",
    "            mean = cell_mean\n",
    "\n",
    "            trials_list = [hv.Curve(resps[r, :]).opts(color='k', alpha=0.25, line_width=0.75) for r in np.arange(resps.shape[0])]\n",
    "            mean_list = [hv.Curve(mean).opts(color='r', xlabel='', ylabel='')]\n",
    "            plt_list.append(hv.Overlay(trials_list + mean_list))\n",
    "\n",
    "        else:\n",
    "            raise Exception('Invalid stim_type')\n",
    "            \n",
    "    return plt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(os.path.join(data_path, 'stats.hdf5'), 'r') as f:\n",
    "    ref = f['ref_cells_all_matches_both_vis_resp'][:]\n",
    "    comp = f['comp_cells_all_matches_both_vis_resp'][:]\n",
    "\n",
    "ref_sub = ref[['mouse', 'day', 'cell', 'is_vis_resp', 'vis_resp_pval', 'fit_osi', 'pref_ori', 'fit_dsi', 'pref_dir']]\n",
    "comp_sub = comp[['mouse', 'day', 'cell', 'is_vis_resp', 'vis_resp_pval', 'fit_osi', 'pref_ori', 'fit_dsi', 'pref_dir']]\n",
    "\n",
    "df = ref_sub.join(comp_sub, lsuffix=f'_{session_shorthand[0]}', rsuffix=f'_{session_shorthand[1]}')\n",
    "df.drop(columns=[f'mouse_{session_shorthand[0]}', f'day_{session_shorthand[0]}'], inplace=True)\n",
    "df.rename(columns={f'mouse_{session_shorthand[1]}': 'mouse', f'day_{session_shorthand[1]}': 'day'}, inplace=True)\n",
    "df = df.sort_values(by=['mouse', 'day']).reset_index(drop=True)\n",
    "\n",
    "slugs = df.groupby(['mouse', 'day'])[[f\"cell_{session_shorthand[0]}\", f\"cell_{session_shorthand[1]}\"]].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "preproc_df_list_fixed = []\n",
    "tc_df_list_fixed = []\n",
    "\n",
    "preproc_df_list_free = []\n",
    "tc_df_list_free = []\n",
    "\n",
    "preproc_cols = ['trial_num', 'time_vector', 'direction', 'direction_wrapped', 'orientation', 'grating_phase']\n",
    "\n",
    "for i, row in slugs.iterrows():\n",
    "    search_string = f'mouse:{row.mouse}, slug:{row.day}' \n",
    "    parsed_search = fdh.parse_search_string(search_string)\n",
    "\n",
    "    # get the paths from the database\n",
    "\n",
    "    # get the raw experiment\n",
    "    exp_query = bd.query_database('vr_experiment', search_string)\n",
    "    exp_query.sort(key=lambda x: x[sort])\n",
    "\n",
    "    # Get the preprocessing file\n",
    "    preproc_query = bd.query_database('analyzed_data', search_string + r', analysis_type:preprocessing')\n",
    "    preproc_query = [q for q in preproc_query if parsed_search['mouse'].lower() in q['slug']]\n",
    "    preproc_query.sort(key=lambda x: x[sort])\n",
    "    preproc_paths = np.array([el['analysis_path'] for el in preproc_query if (el['analysis_type'] == 'preprocessing') and\n",
    "                            (parsed_search['mouse'].lower() in el['slug'])])\n",
    "\n",
    "    # Get the tuning curve file\n",
    "    tc_query = bd.query_database('analyzed_data', search_string + r', analysis_type:tc_analysis')\n",
    "    tc_query = [q for q in tc_query if parsed_search['mouse'].lower() in q['slug']]\n",
    "    tc_query.sort(key=lambda x: x[sort])\n",
    "    tc_paths = np.array([el['analysis_path'] for el in tc_query if (el['analysis_type'] == 'tc_analysis') and\n",
    "                        (parsed_search['mouse'].lower() in el['slug'])])\n",
    "\n",
    "    # Parse the rigs\n",
    "    rigs = np.array([os.path.basename(file).split('_')[6] for file in preproc_paths])\n",
    "\n",
    "    # Load and save freely moving data\n",
    "    exp_free = WirefreeExperiment(exp_info=exp_query[0], preproc_info=preproc_query[0], tc_info=tc_query[0])\n",
    "    exp_free._load_preprocessing()\n",
    "    exp_free._load_tc()\n",
    "\n",
    "    exp_free.norm_deconv_fluor = tuning.normalize_responses(exp_free.deconv_fluor.copy(), columnwise=True)\n",
    "    exp_free.norm_deconv_fluor = drop_partial_or_long_trials(exp_free.norm_deconv_fluor.copy())\n",
    "    exp_free.norm_deconv_fluor_viewed = filter_viewed_trials(exp_free.kinematics, exp_free.norm_deconv_fluor.copy())\n",
    "    exp_free.norm_inferred_spikes = tuning.normalize_responses(exp_free.inferred_spikes.copy(), columnwise=True)\n",
    "    exp_free.norm_inferred_spikes = drop_partial_or_long_trials(exp_free.norm_inferred_spikes)\n",
    "\n",
    "    free_preproc_df = exp_free.norm_deconv_fluor_viewed.loc[:, preproc_cols + row[f'cell_{session_shorthand[0]}']].copy()\n",
    "    free_preproc_df['mouse'] = row.mouse\n",
    "    free_preproc_df['day'] = row.day\n",
    "    preproc_df_list_free.append(free_preproc_df)\n",
    "\n",
    "    free_tc_df = exp_free.visual_tcs.deconvolved_fluor_viewed_props.loc[row[f'cell_{session_shorthand[0]}'], :]\n",
    "    free_tc_df['mouse'] = row.mouse\n",
    "    free_tc_df['day'] = row.day\n",
    "    tc_df_list_free.append(free_tc_df)\n",
    "\n",
    "    # load head fixed data\n",
    "    exp_fixed = WirefreeExperiment(exp_info=exp_query[1], preproc_info=preproc_query[1], tc_info=tc_query[1])\n",
    "    exp_fixed._load_preprocessing()\n",
    "    exp_fixed._load_tc()\n",
    "\n",
    "    exp_fixed.norm_deconv_fluor = tuning.normalize_responses(exp_fixed.deconv_fluor.copy(), columnwise=True)\n",
    "    exp_fixed.norm_deconv_fluor = drop_partial_or_long_trials(exp_fixed.norm_deconv_fluor.copy())\n",
    "    exp_fixed.norm_deconv_fluor_viewed = exp_fixed.norm_deconv_fluor.copy()\n",
    "    exp_fixed.norm_inferred_spikes = tuning.normalize_responses(exp_fixed.inferred_spikes.copy(), columnwise=True)\n",
    "    exp_fixed.norm_inferred_spikes = drop_partial_or_long_trials(exp_fixed.norm_inferred_spikes)\n",
    "\n",
    "    fixed_preproc_df = exp_fixed.norm_deconv_fluor_viewed.loc[:, preproc_cols + row[f'cell_{session_shorthand[1]}']].copy()\n",
    "    fixed_preproc_df['mouse'] = row.mouse\n",
    "    fixed_preproc_df['day'] = row.day\n",
    "    preproc_df_list_fixed.append(fixed_preproc_df)\n",
    "\n",
    "    fixed_tc_df = exp_fixed.visual_tcs.deconvolved_fluor_viewed_props.loc[row[f'cell_{session_shorthand[1]}'], :]\n",
    "    fixed_tc_df['mouse'] = row.mouse\n",
    "    fixed_tc_df['day'] = row.day\n",
    "    tc_df_list_fixed.append(fixed_tc_df)\n",
    "\n",
    "tc_df_fixed = pd.concat(tc_df_list_fixed)\n",
    "tc_df_free = pd.concat(tc_df_list_free)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head Fixed\n",
    "\n",
    "fig_list = []\n",
    "for i, cell in enumerate(tc_df_fixed.index.to_list()):\n",
    "    fig = plt.figure(layout='constrained', figsize=(3/fp.constant_in2cm, 3/fp.constant_in2cm))\n",
    "\n",
    "    tc_df_row = tc_df_fixed.iloc[i].to_frame().T\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(tc_df_row, cell, subfig=fig, tuning_kind='direction', \n",
    "                                              plot_selectivity=False, font_size='paper', plot_trials=False)\n",
    "    save_path = os.path.join(fig_path, '19_cherry_picked_freely_moving_repeat_FOV_TCs', f'{session_shorthand[1]}_polar_plots', f'tc_{i}_{cell}.png')\n",
    "    fig.savefig(save_path, dpi=800, format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freely Moving\n",
    "\n",
    "fig_list = []\n",
    "for i, cell in enumerate(tc_df_free.index.to_list()):\n",
    "    fig = plt.figure(layout='constrained', figsize=(3/fp.constant_in2cm, 3/fp.constant_in2cm))\n",
    "\n",
    "    tc_df_row = tc_df_free.iloc[i].to_frame().T\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(tc_df_row, cell, subfig=fig, tuning_kind='direction', \n",
    "                                              plot_selectivity=False, font_size='paper', plot_trials=False)\n",
    "    save_path = os.path.join(fig_path, '19_cherry_picked_freely_moving_repeat_FOV_TCs', f'{session_shorthand[0]}_polar_plots', f'tc_{i}_{cell}.png')\n",
    "    fig.savefig(save_path, dpi=800, format='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Average Direction Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head Fixed\n",
    "pre_trial_period = 2\n",
    "post_trial_period = 2\n",
    "\n",
    "cell_count = 0\n",
    "fixed_plot_list = []\n",
    "for trials_df in preproc_df_list_fixed:\n",
    "        cells = [col for col in trials_df.columns if 'cell' in col] \n",
    "        trials_df.reset_index(drop=True, inplace=True)\n",
    "        dff_trials, tc_frames = parse_trial_frames(trials_df, pre_trial=pre_trial_period, post_trial=post_trial_period)\n",
    "        dir_averages, dir_trials = trial_average_response(dff_trials.copy(), cells, 'direction_wrapped')\n",
    "\n",
    "        time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "        trial_vector = np.zeros_like(time_vector)\n",
    "        trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "        trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.15)\n",
    "\n",
    "        norm_dff_dirs = hv_plot_vis_trial_averages(dir_averages, dir_trials, cells, 'direction')\n",
    "\n",
    "        save_paths = []\n",
    "        for cell in cells:\n",
    "                for dir in np.arange(dir_averages.shape[0]):\n",
    "                        save_paths.append(os.path.join(fig_path, '19_cherry_picked_freely_moving_repeat_FOV_TCs', f'{session_shorthand[0]}_tcs_by_dir', f'tc_{cell_count}_{cell}_dir_{dir}.png'))\n",
    "                cell_count += 1\n",
    "\n",
    "        for i, norm_dff_i in enumerate(norm_dff_dirs):\n",
    "                norm_dff_i = norm_dff_i * trial_plot\n",
    "                norm_dff_i = norm_dff_i.opts(hv.opts.Curve(width=100, height=100, xlabel=None, ylabel=None, xaxis=None, yaxis=None, title=''))\n",
    "                norm_dff_i = fp.save_figure(norm_dff_i, save_path=save_paths[i], fig_width=1, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "                fixed_plot_list.append(norm_dff_i)\n",
    "\n",
    "# hv.Layout(new_norm_dff_dirs).cols(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freely Moving\n",
    "pre_trial_period = 2\n",
    "post_trial_period = 2\n",
    "\n",
    "cell_count = 0\n",
    "free_plot_list = []\n",
    "for trials_df in preproc_df_list_free:\n",
    "        cells = [col for col in trials_df.columns if 'cell' in col] \n",
    "        trials_df.reset_index(drop=True, inplace=True)\n",
    "        trials, tc_frames = parse_trial_frames(trials_df, pre_trial=pre_trial_period, post_trial=post_trial_period)\n",
    "        dir_averages, dir_trials = trial_average_response(trials.copy(), cells, 'direction_wrapped')\n",
    "\n",
    "        time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "        trial_vector = np.zeros_like(time_vector)\n",
    "        trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "        trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.15)\n",
    "\n",
    "        norm_dff_dirs = hv_plot_vis_trial_averages(dir_averages, dir_trials, cells, 'direction')\n",
    "\n",
    "        save_paths = []\n",
    "        for cell in cells:\n",
    "                for dir in np.arange(dir_averages.shape[0]):\n",
    "                        save_paths.append(os.path.join(fig_path, '19_cherry_picked_freely_moving_repeat_FOV_TCs', f'{session_shorthand[1]}_tcs_by_dir', f'tc_{cell_count}_{cell}_dir_{dir}.png'))\n",
    "                cell_count += 1\n",
    "\n",
    "        for i, norm_dff_i in enumerate(norm_dff_dirs):\n",
    "                norm_dff_i = norm_dff_i * trial_plot\n",
    "                norm_dff_i = norm_dff_i.opts(hv.opts.Curve(width=100, height=100, xlabel=None, ylabel=None, xaxis=None, yaxis=None, title=''))\n",
    "                norm_dff_i = fp.save_figure(norm_dff_i, save_path=save_paths[i], fig_width=1, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "                free_plot_list.append(norm_dff_i)\n",
    "\n",
    "# hv.Layout(new_norm_dff_dirs).cols(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_list = [3, 4, 55, 59, 48, 31, 2, 6]   # Full exp\n",
    "# idx_list = [30, 33, 5, 10, 7]  # repeat HF\n",
    "idx_list = [7, 4, 5, 1, 3]  # repeat FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, :][[f'pref_ori_{session_shorthand[0]}', f'pref_ori_{session_shorthand[1]}', f'pref_dir_{session_shorthand[0]}', f'pref_dir_{session_shorthand[1]}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, :][['mouse', 'day', f'cell_{session_shorthand[0]}', f'cell_{session_shorthand[1]}', f'fit_osi_{session_shorthand[0]}', f'fit_osi_{session_shorthand[1]}', f'fit_dsi_{session_shorthand[0]}', f'fit_dsi_{session_shorthand[1]}',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['mouse', 'day', f'cell_{session_shorthand[0]}', f'cell_{session_shorthand[1]}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[f'fit_osi_{session_shorthand[0]}'] > 0.7) & (df[f'fit_osi_{session_shorthand[1]}'] > 0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prey_capture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
