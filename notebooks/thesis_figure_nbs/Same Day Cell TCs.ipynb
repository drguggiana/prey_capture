{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762146dc",
   "metadata": {},
   "source": [
    "# Same day FOVs, TCs, traces\n",
    "Make plots of the FOVs, dFF traces, kinematics, and tuning curves for two experiments on the same day in the same animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1825b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib widget\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import cv2\n",
    "import importlib\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from hmmlearn import hmm\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "import paths\n",
    "import processing_parameters\n",
    "import functions_bondjango as bd\n",
    "import functions_misc as fmisc\n",
    "import functions_matching as fm\n",
    "import functions_data_handling as fdh\n",
    "import functions_tuning as tuning\n",
    "import functions_plotting as fp\n",
    "import functions_kinematic as fk\n",
    "from wirefree_experiment import WirefreeExperiment, DataContainer\n",
    "from functions_wirefree_trigger_fix import get_trial_duration_stats\n",
    "\n",
    "# fig_path = paths.wf_figures_path\n",
    "fig_path = r\"H:\\thesis\\figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12daccfd",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_partial_or_long_trials(df, min_trial_length=4.5, max_trial_length=5.5):\n",
    "    \"\"\"\n",
    "    This function drops trials that are shorter than min_trial_length (partial trials) and\n",
    "    trials that are longer than max_trial_length (errors in trial number indexing) from the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The dataframe containing the trials.\n",
    "    min_trial_length (float): The minimum length for a trial. Defaults to 4.5.\n",
    "    max_trial_length (float): The maximum length for a trial. Defaults to 5.5.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The dataframe after dropping the partial and long trials.\n",
    "    \"\"\"\n",
    "\n",
    "    trial_lengths = df[df.trial_num > 0].groupby('trial_num').apply(lambda x: x.shape[0] / processing_parameters.wf_frame_rate)\n",
    "\n",
    "    # Drop trials that are shorter than min_trial_length (partial trials)\n",
    "    short_trials = trial_lengths[trial_lengths < min_trial_length].index\n",
    "    df = df.drop(df[df.trial_num.isin(short_trials)].index)\n",
    "\n",
    "    # Drop trials that are longer than max_trial_length (errors in trial number indexing)\n",
    "    long_trials = trial_lengths[trial_lengths > max_trial_length].index\n",
    "    df = df.drop(df[df.trial_num.isin(long_trials)].index).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_viewed_trials(kinematics, activity_df):\n",
    "\n",
    "    # Filter trials by head pitch if freely moving\n",
    "    pitch_lower_cutoff = processing_parameters.head_pitch_cutoff[0]\n",
    "    pitch_upper_cutoff = processing_parameters.head_pitch_cutoff[1]\n",
    "    view_fraction = processing_parameters.view_fraction\n",
    "    kinematics['viewed'] = np.logical_and(kinematics['head_pitch'].to_numpy() >= pitch_lower_cutoff,\n",
    "                                          kinematics['head_pitch'].to_numpy() <= pitch_upper_cutoff)\n",
    "    viewed_trials = kinematics.groupby('trial_num').filter(\n",
    "        lambda x: (x['viewed'].sum() / len(x['viewed'])) > view_fraction).trial_num.unique()\n",
    "\n",
    "    viewed_activity_df = activity_df.loc[activity_df.trial_num.isin(viewed_trials)].copy()\n",
    "    return viewed_activity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c80a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(processing_parameters)\n",
    "\n",
    "# get the search string\n",
    "search_string = 'mouse:MM_230705_b, slug:08_03_2023'     # for thesis: 'mouse:MM_221109_a, slug:01_11_2023,'\n",
    "parsed_search = fdh.parse_search_string(search_string)\n",
    "\n",
    "# get the paths from the database\n",
    "\n",
    "# get the raw experiment\n",
    "exp_query = bd.query_database('vr_experiment', search_string)\n",
    "exp_query.sort(key=lambda x: x['rig'])\n",
    "\n",
    "# Get the preprocessing file\n",
    "preproc_query = bd.query_database('analyzed_data', search_string + r', analysis_type:preprocessing')\n",
    "preproc_query = [q for q in preproc_query if parsed_search['mouse'].lower() in q['slug']]\n",
    "preproc_query.sort(key=lambda x: x['rig'])\n",
    "preproc_paths = np.sort(np.array([el['analysis_path'] for el in preproc_query if (el['analysis_type'] == 'preprocessing') and\n",
    "                        (parsed_search['mouse'].lower() in el['slug'])]))\n",
    "\n",
    "# Get the tuning curve file\n",
    "tc_query = bd.query_database('analyzed_data', search_string + r', analysis_type:tc_analysis')\n",
    "tc_query = [q for q in tc_query if parsed_search['mouse'].lower() in q['slug']]\n",
    "tc_query.sort(key=lambda x: x['rig'])\n",
    "tc_paths = np.sort(np.array([el['analysis_path'] for el in tc_query if (el['analysis_type'] == 'tc_analysis') and\n",
    "                    (parsed_search['mouse'].lower() in el['slug'])]))\n",
    "\n",
    "# Get the cell matching file\n",
    "cell_match_query = bd.query_database('analyzed_data', search_string + r', analysis_type:cellmatching')\n",
    "cell_match_query = [q for q in cell_match_query if parsed_search['mouse'].lower() in q['slug']]\n",
    "cell_match_query.sort(key=lambda x: x['rig'])\n",
    "cell_matching_path = np.array([el['analysis_path'] for el in cell_match_query if (el['analysis_type'] == 'cellmatching') and\n",
    "                                (parsed_search['mouse'].lower() in el['slug']) and ('daycellmatch' in el['slug'])])\n",
    "\n",
    "# Get the calcium file names\n",
    "calcium_paths = np.array([p.replace('preproc', 'calciumraw') for p in preproc_paths])\n",
    "\n",
    "# Parse the rigs\n",
    "rigs = np.array([os.path.basename(file).split('_')[6] for file in calcium_paths])\n",
    "sort_array = np.argsort(rigs)\n",
    "\n",
    "rigs = rigs[sort_array]\n",
    "calcium_paths = calcium_paths[sort_array]\n",
    "preproc_paths = preproc_paths[sort_array]\n",
    "tc_paths = tc_paths[sort_array]\n",
    "\n",
    "print(cell_matching_path)\n",
    "print(calcium_paths)\n",
    "print(preproc_paths)\n",
    "print(tc_paths)\n",
    "print(rigs)\n",
    "\n",
    "# For thesis\n",
    "parsed_search['lighting'] = 'normal'\n",
    "parsed_search['result'] = 'control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matching assignments and find the column that corresponds to each file\n",
    "assignments =  fm.match_cells(cell_matching_path[0])\n",
    "new_cols = [col.split('_')[-2] for col in assignments.columns]\n",
    "assignments.columns = new_cols\n",
    "col_sort_idx = np.argsort(assignments.columns)\n",
    "assignments = assignments[assignments.columns[col_sort_idx]]\n",
    "\n",
    "# Use number of non-NaNs in each row to filter out components that were not registered in enough sessions\n",
    "assignments_filtered = assignments.dropna().astype(int).to_numpy()\n",
    "unassigned = np.array(assignments[np.sum(~np.isnan(assignments), axis=1) < 2])\n",
    "unassigned = [unassigned[~np.isnan(unassigned[:, 0]), 0].astype(int), unassigned[~np.isnan(unassigned[:, 1]), 1].astype(int)]\n",
    "unassigned = [np.sort(np.unique(unassigned[0])), np.sort(np.unique(unassigned[1]))]\n",
    "\n",
    "# Specify the path to the curated cell matches file\n",
    "curated_cell_matches_path = os.path.join(r\"C:\\Users\\mmccann\\Desktop\", \n",
    "                                f\"curated_cell_matches_{parsed_search['result']}_{parsed_search['lighting']}_{parsed_search['rig']}.xlsx\")\n",
    "\n",
    "try:\n",
    "    # Read all sheets into a list of dataframes\n",
    "    curated_matches_dict = pd.read_excel(curated_cell_matches_path, sheet_name=None)\n",
    "\n",
    "    # Concatenate the dataframes into a single dataframe\n",
    "    curated_matches = pd.concat(curated_matches_dict.values(), ignore_index=True)\n",
    "\n",
    "    # Get the hand-picked matches for the current experiment\n",
    "    day_mouse_curated_idxs = curated_matches[(curated_matches['mouse'] == parsed_search['mouse']) & \n",
    "                                            (curated_matches['day'] == parsed_search['slug'])]['index'].values\n",
    "    \n",
    "    if len(day_mouse_curated_idxs) == 0:\n",
    "        raise Exception(\"No curated matches found for the current experiment. Continuing with CaImAn matches...\")\n",
    "    else:\n",
    "        day_mouse_curated_matches = assignments_filtered[day_mouse_curated_idxs, :]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not find the file {curated_cell_matches_path}. Continuing with CaImAn matches...\")\n",
    "    day_mouse_curated_matches = assignments_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e502ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load freely moving data\n",
    "exp_free = WirefreeExperiment(exp_info=exp_query[0], preproc_info=preproc_query[0], tc_info=tc_query[0])\n",
    "exp_free._load_preprocessing()\n",
    "exp_free._load_tc()\n",
    "\n",
    "exp_free.norm_deconv_fluor = tuning.normalize_responses(exp_free.deconv_fluor.copy())\n",
    "exp_free.norm_deconv_fluor = drop_partial_or_long_trials(exp_free.norm_deconv_fluor.copy())\n",
    "exp_free.norm_deconv_fluor_viewed = filter_viewed_trials(exp_free.kinematics, exp_free.norm_deconv_fluor.copy())\n",
    "exp_free.norm_inferred_spikes = tuning.normalize_responses(exp_free.inferred_spikes.copy())\n",
    "exp_free.norm_inferred_spikes = drop_partial_or_long_trials(exp_free.norm_inferred_spikes)\n",
    "\n",
    "# load head fixed data\n",
    "exp_fixed = WirefreeExperiment(exp_info=exp_query[1], preproc_info=preproc_query[1], tc_info=tc_query[1])\n",
    "exp_fixed._load_preprocessing()\n",
    "exp_fixed._load_tc()\n",
    "\n",
    "exp_fixed.norm_deconv_fluor = tuning.normalize_responses(exp_fixed.deconv_fluor.copy())\n",
    "exp_fixed.norm_deconv_fluor = drop_partial_or_long_trials(exp_fixed.norm_deconv_fluor.copy())\n",
    "exp_fixed.norm_deconv_fluor_viewed = exp_fixed.norm_deconv_fluor.copy()\n",
    "exp_fixed.norm_inferred_spikes = tuning.normalize_responses(exp_fixed.inferred_spikes.copy())\n",
    "exp_fixed.norm_inferred_spikes = drop_partial_or_long_trials(exp_fixed.norm_inferred_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the used dataset from processing params\n",
    "used_activity_ds = processing_parameters.activity_datasets[0]\n",
    "print(used_activity_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712573a",
   "metadata": {},
   "source": [
    "# Select cells with particular visual response properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd92746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vis_tuned_cells(ds, vis_stim='dir', sel_thresh=0.3, drop_na=True):\n",
    "    data = ds.copy()\n",
    "\n",
    "    if (vis_stim == 'dir'):\n",
    "        # Cells cannot be both responsive to all visual stimuli and to directions\n",
    "        cells = data[(data['is_dir_responsive'] == 1) & (data['fit_dsi'] >= sel_thresh)]\n",
    "                    #   & (data['fit_osi'] < sel_thresh)] & (data['is_vis_responsive'] == 0)\n",
    "        return cells\n",
    "    \n",
    "    elif (vis_stim == 'ori'):\n",
    "        # Cells cannot be both responsive to all visual stimuli and to orientations\n",
    "        cells = data[(data['is_ori_responsive'] == 1) & (data['fit_osi'] >= sel_thresh)]\n",
    "            #   & (data['fit_dsi'] < sel_thresh)] & (data['is_vis_responsive'] == 0)\n",
    "        return cells\n",
    "\n",
    "    elif (vis_stim == 'vis'):\n",
    "        cells = data[(data['is_vis_responsive'] == 1) & (data['is_gen_responsive'] == 0)]\n",
    "        return cells\n",
    "    \n",
    "    elif (vis_stim == 'gen') :\n",
    "        cells = data[data['is_gen_responsive'] == 1]\n",
    "        return cells\n",
    "\n",
    "    else:\n",
    "        return Exception('Invalid vis_stim')\n",
    "\n",
    "\n",
    "def filter_vis_selectivity(fixed_exp_tcs, free_exp_tcs, matches, vis_stim, sel_thresh=0.3):\n",
    "\n",
    "    # Get the right columns\n",
    "    if vis_stim == 'dir':\n",
    "        sel_var = 'fit_dsi'\n",
    "        resp_test = 'is_dir_responsive'\n",
    "    elif vis_stim == 'ori':\n",
    "        sel_var = 'fit_osi'\n",
    "        resp_test = 'is_ori_responsive'\n",
    "    else:\n",
    "        raise ValueError('Invalid vis_stim')\n",
    "\n",
    "    # Find matched_cells\n",
    "    free_matched = free_exp_tcs.iloc[matches[:, 0], :]\n",
    "    fixed_matched = fixed_exp_tcs.iloc[matches[:, 1], :]\n",
    "\n",
    "    # Get the selectivity values from the matched cells\n",
    "    free = free_matched[sel_var].abs()\n",
    "    fixed = fixed_matched[sel_var].abs()\n",
    "    diff = free.values - fixed.values\n",
    "    sel_matched = pd.DataFrame({'fixed': fixed.values, 'free': free.values, 'diff': diff})\n",
    "\n",
    "    # Find matches where both are responsive\n",
    "    free_responsive = free_matched[resp_test].values\n",
    "    fixed_responsive = fixed_matched[resp_test].values\n",
    "    diff_resp = free_responsive - fixed_responsive\n",
    "    both_resp_idxs = np.argwhere(diff_resp == 0).flatten()\n",
    "    gained_resp_idx = np.argwhere(diff_resp == 1).flatten()\n",
    "    lost_resp_idx = np.argwhere(diff_resp == -1).flatten()\n",
    "\n",
    "    # find cells that maintained, gained, or lost selectivity\n",
    "    kept_sel = sel_matched[(sel_matched['fixed'] >= sel_thresh) & (sel_matched['free'] >= sel_thresh)]\n",
    "    strengthened_sel = sel_matched[(sel_matched['fixed'] >= sel_thresh) & (sel_matched['free'] >= sel_thresh) & (sel_matched['diff'] > 0.15)]\n",
    "    weakened_sel = sel_matched[(sel_matched['fixed'] >= sel_thresh) & (sel_matched['free'] >= sel_thresh) & (sel_matched['diff'] < -0.15)]\n",
    "    gained_sel = sel_matched[(sel_matched['fixed'] < sel_thresh) & (sel_matched['free'] >= sel_thresh)]\n",
    "    lost_sel = sel_matched[(sel_matched['fixed'] >= sel_thresh) & (sel_matched['free'] < sel_thresh)]\n",
    "\n",
    "    sel_matched['kept'] = sel_matched.index.isin(kept_sel.index)\n",
    "    sel_matched['lost'] = sel_matched.index.isin(lost_sel.index)\n",
    "    sel_matched['gained'] = sel_matched.index.isin(gained_sel.index)\n",
    "    sel_matched['strengthened'] = sel_matched.index.isin(strengthened_sel.index)\n",
    "    sel_matched['weakened'] = sel_matched.index.isin(weakened_sel.index)\n",
    "    \n",
    "    return sel_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_tcs = getattr(exp_free.visual_tcs, f'{used_activity_ds}_props')\n",
    "fixed_tcs = getattr(exp_fixed.visual_tcs, f'{used_activity_ds}_props')\n",
    "\n",
    "# Cells that are generally responsive (but not specific for visual stimuli)\n",
    "free_gen_resp = get_vis_tuned_cells(free_tcs, vis_stim='gen', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "fixed_gen_resp = get_vis_tuned_cells(fixed_tcs, vis_stim='gen', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "# Cells that meet visual responsivity criteria\n",
    "free_vis_resp = get_vis_tuned_cells(free_tcs, vis_stim='vis', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "fixed_vis_resp = get_vis_tuned_cells(fixed_tcs, vis_stim='vis', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "# Cells that meet direction selectivity criteria\n",
    "free_dir_tuned = get_vis_tuned_cells(free_tcs, vis_stim='dir', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "fixed_dir_tuned = get_vis_tuned_cells(fixed_tcs, vis_stim='dir', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "# Cells that meet orientation selectivity criteria\n",
    "free_ori_tuned = get_vis_tuned_cells(free_tcs, vis_stim='ori', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "fixed_ori_tuned = get_vis_tuned_cells(fixed_tcs, vis_stim='ori', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "\n",
    "# Find cells that are both direction and orientation tuned, and figure out what to do with them.\n",
    "intersect, comm1, comm2 = np.intersect1d(free_dir_tuned.index, free_ori_tuned.index, return_indices=True)\n",
    "free_both_tuned = free_dir_tuned.iloc[comm1].copy()\n",
    "\n",
    "# Remove cells tuned to both from each category\n",
    "free_dir_tuned = free_dir_tuned.drop(free_dir_tuned.index[comm1])\n",
    "free_ori_tuned = free_ori_tuned.drop(free_ori_tuned.index[comm2])\n",
    "\n",
    "intersect, comm1, comm2 = np.intersect1d(fixed_dir_tuned.index, fixed_ori_tuned.index, return_indices=True)\n",
    "fixed_both_tuned = fixed_dir_tuned.iloc[comm1].copy()\n",
    "fixed_dir_tuned = fixed_dir_tuned.drop(fixed_dir_tuned.index[comm1])\n",
    "fixed_ori_tuned = fixed_ori_tuned.drop(fixed_ori_tuned.index[comm2])\n",
    "\n",
    "# Double check cells that are visually reposnsive, make sure that all are contained in the vis_resp\n",
    "free_resp_cells = np.unique(np.concatenate([free_dir_tuned.index, free_ori_tuned.index, free_both_tuned.index]))\n",
    "not_in_free_resp_cells = np.setdiff1d(free_vis_resp.index, free_resp_cells, assume_unique=True)\n",
    "free_vis_resp = pd.concat([free_vis_resp, free_tcs.loc[not_in_free_resp_cells, :]])\n",
    "free_vis_resp = free_vis_resp.reset_index().drop_duplicates(subset=['index'])\n",
    "\n",
    "fixed_resp_cells = np.unique(np.concatenate([fixed_dir_tuned.index, fixed_ori_tuned.index, fixed_both_tuned.index]))\n",
    "not_in_fixed_resp_cells = np.setdiff1d(fixed_vis_resp.index, fixed_resp_cells, assume_unique=True)\n",
    "fixed_vis_resp = pd.concat([fixed_vis_resp, fixed_tcs.loc[not_in_fixed_resp_cells, :]])\n",
    "fixed_vis_resp = fixed_vis_resp.reset_index().drop_duplicates(subset=['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec97316",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(free_dir_tuned.index.to_list(), free_ori_tuned.index.to_list())\n",
    "print(fixed_dir_tuned.index.to_list(), fixed_ori_tuned.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For thesis\n",
    "# final_idxs = [4, 11, 12, 21, 27, 36, 39, 19]\n",
    "# free ['cell_0013', 'cell_0026', 'cell_0027', 'cell_0049', 'cell_0075', 'cell_0119', 'cell_0133', 'cell_0045']\n",
    "# fixed ['cell_0014', 'cell_0036', 'cell_0039', 'cell_0054', 'cell_0092', 'cell_0128', 'cell_0141', 'cell_0061']\n",
    "\n",
    "num_matches = min(day_mouse_curated_matches.shape[0], 8)\n",
    "\n",
    "ori_matched = filter_vis_selectivity(fixed_tcs, free_tcs, day_mouse_curated_matches, 'ori', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "dir_matched = filter_vis_selectivity(fixed_tcs, free_tcs, day_mouse_curated_matches, 'dir', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "ori_kept = ori_matched[ori_matched['kept']].index.values\n",
    "ori_gained = ori_matched[ori_matched['gained']].index.values\n",
    "ori_lost = ori_matched[ori_matched['lost']].index.values\n",
    "ori_strong = ori_matched[ori_matched['strengthened']].index.values\n",
    "ori_weak = ori_matched[ori_matched['weakened']].index.values\n",
    "\n",
    "dir_kept = dir_matched[dir_matched['kept']].index.values\n",
    "dir_gained = dir_matched[dir_matched['gained']].index.values\n",
    "dir_lost = dir_matched[dir_matched['lost']].index.values\n",
    "dir_strong = dir_matched[dir_matched['strengthened']].index.values\n",
    "dir_weak = dir_matched[dir_matched['weakened']].index.values\n",
    "\n",
    "# Choose cells somewhat at random for the thesis: want 8 in total, one from each category + 2 random\n",
    "chosen_idxs = []\n",
    "for arr in [ori_kept, ori_lost, ori_gained, ori_strong, ori_weak, dir_kept, dir_lost, dir_gained, dir_strong, dir_weak]:\n",
    "    if arr.size > 0:\n",
    "        chosen_idxs.append(np.random.choice(arr, 1)[0])\n",
    "\n",
    "# Enforce no repeats\n",
    "chosen_idxs = np.unique(chosen_idxs)\n",
    "\n",
    "# randomly choose 2 more cells from those remaining\n",
    "remaining_idxs = np.setdiff1d(np.arange(len(day_mouse_curated_matches)), chosen_idxs)\n",
    "random_idxs = np.random.choice(remaining_idxs, num_matches - len(chosen_idxs), replace=False)\n",
    "final_idxs = np.concatenate([chosen_idxs, random_idxs]).astype(int)\n",
    "\n",
    "# enforce no repeats\n",
    "# final_idxs = np.unique(final_idxs)\n",
    "\n",
    "# final_idxs = [4, 11, 12, 21, 27, 36, 39, 19]\n",
    "final_cells = day_mouse_curated_matches[final_idxs, :]\n",
    "\n",
    "exp_free.cells_to_match = [f'cell_{id:04d}' for id in final_cells[:, 0]]\n",
    "exp_fixed.cells_to_match = [f'cell_{id:04d}' for id in final_cells[:, 1]]\n",
    "print(final_idxs)\n",
    "print(exp_free.cells_to_match)\n",
    "print(exp_fixed.cells_to_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40b881",
   "metadata": {},
   "source": [
    "# Generate Contour Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_footprint_centroids(calcium_data):\n",
    "    cents = []\n",
    "    for cell in calcium_data:\n",
    "        new_cell = cell.copy()\n",
    "        new_cell[new_cell > 0] == 1 \n",
    "        M = cv2.moments(new_cell)\n",
    "        \n",
    "        # centroid calciulation\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cents.append([cX, cY])\n",
    "    return cents\n",
    "\n",
    "def get_footprint_contours(calcium_data):\n",
    "    contour_list = []\n",
    "    contour_stats = []\n",
    "    for frame in calcium_data:\n",
    "        frame = frame * 255.\n",
    "        frame = frame.astype(np.uint8)\n",
    "        thresh = cv2.threshold(frame, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # # get contours and filter out small defects\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        # Only take the largest contour\n",
    "        cntr = max(contours, key=cv2.contourArea)\n",
    "        area = cv2.contourArea(cntr)\n",
    "        perimeter = cv2.arcLength(cntr, True)\n",
    "        compactness = 4*np.pi*area / (perimeter + 1e-16)**2\n",
    "        \n",
    "        contour_list.append(cntr)\n",
    "        contour_stats.append((area, perimeter, compactness))\n",
    "\n",
    "    return contour_list, np.array(contour_stats)\n",
    "\n",
    "def make_contour_projection(contour_list, shape, threshold=0.1):\n",
    "    contour_img = np.zeros(shape)\n",
    "    for i, cntr in enumerate(contour_list):\n",
    "        cv2.drawContours(contour_img[i, :], [cntr], 0, 1, 1)\n",
    "\n",
    "    contour_img = np.sum(contour_img, axis=0)\n",
    "    contour_img[contour_img > threshold] = 1.0\n",
    "    return contour_img\n",
    "\n",
    "def get_binary_footprints(footprint_pic, threshold=0.1):\n",
    "    bin_pic = np.zeros_like(footprint_pic)\n",
    "    bin_pic[footprint_pic > threshold] = 1\n",
    "    return bin_pic\n",
    "\n",
    "def make_rgb_overlay(max_proj, footprints, contour_img, channel='r'):\n",
    "    max_proj -= max_proj.min()\n",
    "    max_proj /= max_proj.max()\n",
    "\n",
    "    # Make RGB max projection\n",
    "    max_proj_rgb = np.dstack((max_proj, max_proj, max_proj))\n",
    "\n",
    "    # mak RGB footprint image\n",
    "    footprint_rgb = np.zeros((*max_proj.shape, 3))\n",
    "\n",
    "    footprints /= footprints.max()\n",
    "    if channel == 'r':\n",
    "        footprint_rgb[:, :, 0] = footprints\n",
    "    elif channel == 'g':\n",
    "        footprint_rgb[:, :, 1] = footprints\n",
    "    elif channel == 'b':\n",
    "        footprint_rgb[:, :, 2] = footprints\n",
    "    else:\n",
    "        raise ValueError('channel must be r, g, or b')\n",
    "    \n",
    "    # Convert RGB max proj and RGB footprints to HSV colorspace\n",
    "    max_proj_hsv = color.rgb2hsv(max_proj_rgb)\n",
    "    footprint_mask_hsv = color.rgb2hsv(footprint_rgb)\n",
    "\n",
    "    # Overlay the footprint mask on the max projection\n",
    "    max_proj_hsv[..., 0] = footprint_mask_hsv[..., 0]\n",
    "    max_proj_hsv[..., 1] = footprint_mask_hsv[..., 1]\n",
    "\n",
    "    # Return to RGB colorspace\n",
    "    overlay = color.hsv2rgb(max_proj_hsv)\n",
    "    overlay[:] += np.expand_dims(contour_img, -1).astype(float)\n",
    "\n",
    "    return overlay\n",
    "\n",
    "def hv_plot_FOVs(rigs, binary_footprints, contour_images, alpha=0, labels=None, overlay=True):\n",
    "    binary_images = []\n",
    "\n",
    "    for i, (rig, bin_pic) in enumerate(zip(rigs, binary_footprints)):\n",
    "        # Plot all binarized ROIS with contours\n",
    "        alpha_mask = np.ones_like(bin_pic) * alpha\n",
    "        bin_pic = np.dstack((bin_pic, alpha_mask))\n",
    "        binary_image = hv.RGB(bin_pic.astype(float), bounds=(0, 0, 320, 320)).opts(title=rig)\n",
    "        \n",
    "        if labels is not None:\n",
    "            cents = labels[i][:, :2].copy()\n",
    "            cents[:,1] = 320 - cents[:,1]\n",
    "            label = labels[i][:, -1]\n",
    "            label_plot = hv.Labels({('x', 'y'): cents, 'text': label}, ['x', 'y'], 'text').opts(text_color='white', xoffset=0.05, yoffset=0.05, text_font_size='8pt')\n",
    "            binary_image = binary_image * label_plot\n",
    "\n",
    "        binary_images.append(binary_image)\n",
    "\n",
    "    if overlay:\n",
    "        binary_overlay = hv.RGB(np.dstack((contour_images[1], np.zeros_like(contour_images[0]), contour_images[0])), bounds=(0, 0, 320, 320)).opts(title='Overlay')\n",
    "        binary_images.append(binary_overlay)\n",
    "        \n",
    "    layout = hv.Layout(binary_images).cols(len(binary_images))\n",
    "\n",
    "    return layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8446cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data for the matching\n",
    "calcium_list = []\n",
    "max_proj_list = []\n",
    "footprint_list = []\n",
    "contour_list = []\n",
    "size_list = []\n",
    "template_list = []\n",
    "footprint_pics = []\n",
    "countour_pics = []\n",
    "centroids_list = []\n",
    "binary_footprints = []\n",
    "overlay_footprints = []\n",
    "overlay_binary_footprints = []\n",
    "\n",
    "\n",
    "# load the calcium data\n",
    "for files, channel in zip(calcium_paths, ['b', 'r']):\n",
    "\n",
    "    with h5py.File(files, mode='r') as f:\n",
    "\n",
    "        try:\n",
    "            calcium_data = np.array(f['A'])\n",
    "            max_proj = np.array(f['max_proj'])     \n",
    "\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    # if there are no ROIs, skip\n",
    "    if (type(calcium_data) == np.ndarray) and np.any(calcium_data.astype(str) == 'no_ROIs'):\n",
    "        continue\n",
    "        \n",
    "    # clear the rois that don't pass the size or compactness criteria\n",
    "    roi_stats = fmisc.get_roi_stats(calcium_data)\n",
    "    contours, contour_stats = get_footprint_contours(calcium_data)\n",
    "\n",
    "    if len(roi_stats.shape) == 1:\n",
    "        roi_stats = roi_stats.reshape(1, -1)\n",
    "        contour_stats = contour_stats.reshape(1, -1)\n",
    "\n",
    "    areas = roi_stats[:, -1]\n",
    "    compactness = contour_stats[:, -1]\n",
    "\n",
    "    keep_vector = (areas > processing_parameters.roi_parameters['area_min']) & \\\n",
    "                  (areas < processing_parameters.roi_parameters['area_max']) & \\\n",
    "                  (compactness > 0.5)\n",
    "\n",
    "    if np.all(keep_vector == False):\n",
    "        continue\n",
    "\n",
    "    calcium_data = calcium_data[keep_vector, :, :]\n",
    "    contours = [contours[i] for i, keep in enumerate(keep_vector) if keep]\n",
    "\n",
    "    centroids = get_footprint_centroids(calcium_data)\n",
    "    footprint_proj = np.sum(calcium_data, axis=0)\n",
    "    binary_footprint_proj = get_binary_footprints(footprint_proj)\n",
    "    contour_proj = make_contour_projection(contours, calcium_data.shape, threshold=0.5)\n",
    "    \n",
    "    # format and masks and store for matching\n",
    "    calcium_list.append(calcium_data)\n",
    "    footprint_list.append(np.moveaxis(calcium_data, 0, -1).reshape((-1, calcium_data.shape[0])))\n",
    "    contour_list.append(contours)\n",
    "    countour_pics.append(contour_proj)\n",
    "\n",
    "    size_list.append(calcium_data.shape[1:])\n",
    "    template_list.append(max_proj)\n",
    "    max_proj_list.append((max_proj - max_proj.min())/ max_proj.max())\n",
    "    footprint_pics.append(footprint_proj)\n",
    "    binary_footprints.append(binary_footprint_proj)\n",
    "    centroids_list.append(np.array(centroids))\n",
    "\n",
    "    overlay_footprints.append(make_rgb_overlay(max_proj, footprint_proj, contour_proj, channel=channel))\n",
    "    overlay_binary_footprints.append(make_rgb_overlay(max_proj, binary_footprint_proj, contour_proj, channel=channel))\n",
    "\n",
    "# Filter footprints and contours based on the matching\n",
    "match_ca1 = calcium_list[0][day_mouse_curated_matches[:, sort_array[0]], :]\n",
    "match_ca2 = calcium_list[1][day_mouse_curated_matches[:, sort_array[1]], :]\n",
    "\n",
    "match_footprint_projs = [np.sum(match_ca1, axis=0),  np.sum(match_ca2, axis=0)]\n",
    "match_binary_footprint_projs = [get_binary_footprints(fp_proj) for fp_proj in match_footprint_projs]\n",
    "match_centroids = [np.array(get_footprint_centroids(match_ca1)), np.array(get_footprint_centroids(match_ca2))]\n",
    "\n",
    "match_contours1, _ = get_footprint_contours(match_ca1)\n",
    "match_contours2, _ = get_footprint_contours(match_ca2)\n",
    "match_contour_proj1 = make_contour_projection(match_contours1, match_ca1.shape)\n",
    "match_contour_proj2 = make_contour_projection(match_contours2, match_ca2.shape)\n",
    "match_binary_contour_projs = [match_contour_proj1, match_contour_proj2]\n",
    "match_contours = [match_contours1, match_contours2]\n",
    "\n",
    "match_overlay_binary_footprints = []\n",
    "for i, channel in enumerate(['b', 'r']):\n",
    "    match_overlay_binary_footprints.append(make_rgb_overlay(max_proj_list[i], match_binary_footprint_projs[i], match_binary_contour_projs[i], channel=channel))\n",
    "\n",
    "# Filter unmatched footprints and contours based on the matching\n",
    "unmatch_ca1 = calcium_list[0][unassigned[sort_array[0]], :]\n",
    "unmatch_ca2 = calcium_list[1][unassigned[sort_array[1]], :]\n",
    "\n",
    "unmatch_footprint_projs = [np.sum(unmatch_ca1, axis=0),  np.sum(unmatch_ca2, axis=0)]\n",
    "unmatch_binary_footprint_projs = [get_binary_footprints(fp_proj) for fp_proj in unmatch_footprint_projs]\n",
    "unmatch_centroids = [np.array(get_footprint_centroids(unmatch_ca1)), np.array(get_footprint_centroids(unmatch_ca2))]\n",
    "\n",
    "unmatch_contours1, _ = get_footprint_contours(unmatch_ca1)\n",
    "unmatch_contours2, _ = get_footprint_contours(unmatch_ca2)\n",
    "unmatch_contour_proj1 = make_contour_projection(unmatch_contours1, unmatch_ca1.shape)\n",
    "unmatch_contour_proj2 = make_contour_projection(unmatch_contours2, unmatch_ca2.shape)\n",
    "unmatch_binary_contour_projs = [unmatch_contour_proj1, unmatch_contour_proj2]\n",
    "unmatch_contours = [unmatch_contours1, unmatch_contours2]\n",
    "\n",
    "unmatch_overlay_binary_footprints = []\n",
    "for i, channel in enumerate(['b', 'r']):\n",
    "    unmatch_overlay_binary_footprints.append(make_rgb_overlay(max_proj_list[i], unmatch_binary_footprint_projs[i], unmatch_binary_contour_projs[i], channel=channel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a17b81",
   "metadata": {},
   "source": [
    "## Plot all cells, matches, and not matched cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6591e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_labels = [np.concatenate((centroids, np.arange(centroids.shape[0]).reshape(-1,1)), axis=1) for centroids in centroids_list]\n",
    "all_cells = hv_plot_FOVs(rigs, overlay_binary_footprints, countour_pics, overlay=True, labels=all_cell_labels)\n",
    "\n",
    "matched_cell_labels = [np.concatenate((match_centroids[i], day_mouse_curated_matches[:, i].reshape(-1,1)), axis=1) for i in np.arange(len(match_centroids))]\n",
    "match_cells = hv_plot_FOVs(rigs, match_overlay_binary_footprints, match_binary_contour_projs, \n",
    "                           overlay=True, labels=matched_cell_labels).opts(hv.opts.RGB(title=''))\n",
    "\n",
    "unmatched_cell_labels = [np.concatenate((unmatch_centroids[i], unassigned[i].reshape(-1,1)), axis=1) for i in np.arange(len(unmatch_centroids))]\n",
    "unmatch_cells = hv_plot_FOVs(rigs, unmatch_overlay_binary_footprints, unmatch_binary_contour_projs, \n",
    "                             overlay=True, labels=unmatched_cell_labels).opts(hv.opts.RGB(title=''))\n",
    "\n",
    "match_plot = hv.Layout(all_cells + match_cells + unmatch_cells).cols(3).opts(hv.opts.RGB(xlabel=None, ylabel=None, xaxis=None, yaxis=None))\n",
    "\n",
    "match_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a292b81",
   "metadata": {},
   "source": [
    "## Plot randomly selected matched cells from the hand curated set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idxs = np.random.choice(np.arange(len(day_mouse_curated_matches)), 5)\n",
    "\n",
    "match_subset_countour_projs = []\n",
    "\n",
    "for contours in match_contours:\n",
    "    random_contours = [contours[i] for i in random_idxs]\n",
    "    match_subset_countour_projs.append(make_contour_projection(random_contours, (len(random_contours), 320, 320)))\n",
    "\n",
    "random_matched_cell_labels = [matched_cell_labels[i][random_idxs, :] for i in np.arange(len(matched_cell_labels))]\n",
    "random_match_cells = hv_plot_FOVs(rigs, match_overlay_binary_footprints, match_subset_countour_projs, \n",
    "                                  overlay=True, labels=random_matched_cell_labels)\n",
    "random_match_cells.opts(hv.opts.RGB(width=500, height=500, xlabel=None, ylabel=None, xaxis=None, yaxis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7278a64",
   "metadata": {},
   "source": [
    "# Figures 1, 2, 3, 6, 7, 10: FOV with labeled ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508dd6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_cell_labels = [np.concatenate((match_centroids[i], day_mouse_curated_matches[:, i].reshape(-1,1)), axis=1) for i in np.arange(len(match_centroids))]\n",
    "\n",
    "match_subset_countour_projs = []\n",
    "\n",
    "for contours in match_contours:\n",
    "    random_contours = [contours[i] for i in final_idxs]\n",
    "    match_subset_countour_projs.append(make_contour_projection(random_contours, (len(random_contours), 320, 320)))\n",
    "\n",
    "subset_matched_cell_labels = [matched_cell_labels[i][final_idxs, :] for i in np.arange(len(matched_cell_labels))]\n",
    "subset_free_overlay = make_rgb_overlay(max_proj_list[0], binary_footprints[0], countour_pics[0], channel='g')\n",
    "match_free_green = hv_plot_FOVs(rigs[:-1], [subset_free_overlay], match_binary_contour_projs[:-1], \n",
    "                           overlay=False, labels=subset_matched_cell_labels[:-1])\n",
    "match_free_green = match_free_green.opts(hv.opts.RGB(title='',), hv.opts.Labels(text_color='red', xoffset=-0.5, yoffset=0.5, text_font_size='10pt'))\n",
    "match_free_green = match_free_green.opts(hv.opts.RGB(width=500, height=500, xlabel=None, ylabel=None, xaxis=None, yaxis=None))\n",
    "\n",
    "save_path = os.path.join(fig_path, '3_freely_moving_cells_traces_ethogram', 'FOV.png')\n",
    "_ = fp.save_figure(match_free_green[0], save_path=save_path, fig_width=10, dpi=800, fontsize='poster', target='save', display_factor=0.2)\n",
    "\n",
    "match_cells = hv_plot_FOVs(rigs, overlay_binary_footprints, match_subset_countour_projs, \n",
    "                           overlay=True, labels=subset_matched_cell_labels)\n",
    "match_cells = match_cells.opts(hv.opts.RGB(title='',), hv.opts.Labels(text_color='red', xoffset=-0.5, yoffset=0.5, text_font_size='10pt'))\n",
    "match_cells = match_cells.opts(hv.opts.RGB(width=500, height=500, xlabel=None, ylabel=None, xaxis=None, yaxis=None))\n",
    "\n",
    "save_path = os.path.join(fig_path, '3_freely_moving_cells_traces_ethogram', 'FOV_match.png')\n",
    "_ = fp.save_figure(match_cells[0], save_path=save_path, fig_width=5, dpi=800, fontsize='poster', target='save', display_factor=0.2)\n",
    "\n",
    "save_path = os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram', 'FOV_match.png')\n",
    "_ = fp.save_figure(match_cells[1], save_path=save_path, fig_width=5, dpi=800, fontsize='poster', target='save', display_factor=0.2)\n",
    "\n",
    "save_path = os.path.join(fig_path, '10_matched_cells_example_tuning_shift', 'matched_contours.png')\n",
    "_ = fp.save_figure(match_cells[2], save_path=save_path, fig_width=5, dpi=800, fontsize='poster', target='save', display_factor=0.2)\n",
    "\n",
    "match_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440f4ee",
   "metadata": {},
   "source": [
    "# Figures 2 and 3: Ethogram + dFF traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781da9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dff_spikes_trials(exp, save_dir, save=True, plot_spikes=True, plot_trials=True, plot_running=False, **kwargs):\n",
    "\n",
    "    basename_modifier = kwargs.pop('basename_modifier', '')\n",
    "    fig_width = kwargs.pop('fig_width', 7)\n",
    "    dpi = kwargs.pop('dpi', 800)\n",
    "    fontsize = kwargs.pop('fontsize', 'poster')\n",
    "    \n",
    "    dff_plots = []\n",
    "    cells_to_plot = kwargs.pop('cells_to_plot', exp.cells_to_match)\n",
    "    for i, cell in enumerate(cells_to_plot):\n",
    "        basename = f\"dff_{i}{basename_modifier}\"\n",
    "\n",
    "        # Plot the dff\n",
    "        out_fig = hv.Curve(exp.norm_deconv_fluor[['time_vector', cell]]).opts(color='black', \n",
    "                                                                              height=kwargs.pop('height', 75), \n",
    "                                                                              width=kwargs.pop('width', 1000), \n",
    "                                                                              **kwargs)\n",
    "\n",
    "        if plot_spikes:\n",
    "            spikes_plot = hv.Curve(exp.norm_inferred_spikes[['time_vector', cell]]).opts(color='green', alpha=0.5)\n",
    "            out_fig = hv.Overlay([spikes_plot, out_fig])\n",
    "            basename += '_spikes'\n",
    "\n",
    "        if plot_trials:\n",
    "            trials_on = exp.norm_deconv_fluor['trial_num'] > 0\n",
    "            time = exp.norm_deconv_fluor['time_vector']\n",
    "            trials_plot = hv.Area((time, trials_on)).opts(color='gray', alpha=0.25)\n",
    "            out_fig = hv.Overlay([trials_plot, out_fig]).opts(hv.opts.Area(yaxis=None, xaxis=None, xlabel=None, ylabel=None, show_legend=False))\n",
    "            basename += '_trials'\n",
    "\n",
    "        if plot_running:\n",
    "            try:\n",
    "                running_plot = hv.Curve(exp.norm_dff[['time_vector', 'running_speed']]).opts(color='red', alpha=0.5)\n",
    "            except KeyError:\n",
    "                running_plot = hv.Curve(exp.norm_dff[['time_vector', 'wheel_speed_abs']]).opts(color='red', alpha=0.5)\n",
    "\n",
    "            out_fig = hv.Overlay([out_fig, running_plot])\n",
    "            basename += '_running'\n",
    "\n",
    "        # Final options for the figure\n",
    "        out_fig = out_fig.opts(hv.opts.Curve(yaxis=None, xaxis=None, xlabel=None, ylabel=None, show_legend=False))\n",
    "        \n",
    "        # Save the figure\n",
    "        save_path = os.path.join(save_dir, f'{basename}.png')\n",
    "\n",
    "        if save:\n",
    "            out_fig = fp.save_figure(out_fig, save_path=save_path, fig_width=fig_width, dpi=dpi, fontsize=fontsize, target='save', display_factor=0.3)\n",
    "        else:\n",
    "            out_fig = fp.save_figure(out_fig, save_path=save_path, fig_width=fig_width, dpi=dpi, fontsize=fontsize, target='screen', display_factor=0.3)\n",
    "\n",
    "        dff_plots.append(out_fig)\n",
    "\n",
    "    return dff_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fad5c",
   "metadata": {},
   "source": [
    "## Head Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6151eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_fixed = plot_dff_spikes_trials(exp_fixed, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=True,\n",
    "                                   plot_spikes=False, plot_trials=False, plot_running=False, \n",
    "                                   fig_width=7, fontsize='paper')\n",
    "# dff_fixed = hv.Layout(dff_fixed).cols(1)\n",
    "# dff_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_fixed_zoom = plot_dff_spikes_trials(exp_fixed, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=True,\n",
    "                                       plot_spikes=False, plot_trials=True, plot_running=False,\n",
    "                                       xlim=(770, 890), basename_modifier='_zoom', fig_width=6, fontsize='paper')\n",
    "# dff_fixed_zoom = hv.Layout(dff_fixed_zoom).cols(1)\n",
    "# dff_fixed_zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews Ethogram - Head Fixed\n",
    "plt_list = []\n",
    "trials_on = np.argwhere(np.diff(exp_fixed.norm_deconv_fluor['trial_num']) > 0).squeeze() + 1\n",
    "trials_off = np.argwhere(np.diff(exp_fixed.norm_deconv_fluor['trial_num']) < 0).squeeze() + 1\n",
    "\n",
    "trials_plot_list = []\n",
    "for on, off in zip(trials_on, trials_off):\n",
    "    time_on = exp_fixed.norm_deconv_fluor['time_vector'].iloc[on]\n",
    "    time_off = exp_fixed.norm_deconv_fluor['time_vector'].iloc[off]\n",
    "    trials_plot_list.append(hv.VSpan(time_on, time_off).opts(color='gray', alpha=0.25))\n",
    "trials_plot = hv.Overlay(trials_plot_list)\n",
    "\n",
    "for variable in processing_parameters.variable_list_fixed:\n",
    "    save_path = os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram', f'{variable}.png')\n",
    "    if variable == 'pupil_diameter':\n",
    "        diam = np.unwrap(fk.jump_killer(exp_fixed.kinematics[variable].to_numpy(), 2), 10)\n",
    "        var_plot = hv.Curve(diam).opts(color='black', height=50, width=1000, xaxis=None, xlabel=None, ylabel=None,)\n",
    "    else:\n",
    "        var_plot = hv.Curve(exp_fixed.kinematics[['time_vector', variable]]).opts(color='black', height=50, width=1000, xaxis=None, xlabel=None, ylabel=None,)\n",
    "\n",
    "    var_plot = var_plot # * trials_plot\n",
    "    var_plot = fp.save_figure(var_plot.opts(yaxis=None), save_path=save_path, fig_width=7, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "    plt_list.append(var_plot)\n",
    "\n",
    "# ethogram = hv.Layout(plt_list).cols(1)\n",
    "# ethogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67584cd",
   "metadata": {},
   "source": [
    "## Freely Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_free = plot_dff_spikes_trials(exp_free, os.path.join(fig_path, '3_freely_moving_cells_traces_ethogram'), save=True,\n",
    "                                  plot_spikes=False, plot_trials=False, plot_running=False, \n",
    "                                  fig_width=7, fontsize='paper')\n",
    "# dff_free = hv.Layout(dff_free).cols(1)\n",
    "# dff_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_free_zoom = plot_dff_spikes_trials(exp_free, os.path.join(fig_path, '3_freely_moving_cells_traces_ethogram'), save=True,\n",
    "                                       plot_spikes=False, plot_trials=True, plot_running=False,\n",
    "                                       xlim=(1050, 1170), basename_modifier='_zoom', fig_width=6, fontsize='paper')\n",
    "# dff_free_zoom = hv.Layout(dff_free_zoom).cols(1)\n",
    "# dff_free_zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews Ethogram - Freely Moving\n",
    "plt_list = []\n",
    "trials_on = np.argwhere(np.diff(exp_free.norm_deconv_fluor['trial_num']) > 0).squeeze() + 1\n",
    "trials_off = np.argwhere(np.diff(exp_free.norm_deconv_fluor['trial_num']) < 0).squeeze() + 1\n",
    "\n",
    "trials_plot_list = []\n",
    "for on, off in zip(trials_on, trials_off):\n",
    "    time_on = exp_free.norm_deconv_fluor['time_vector'].iloc[on]\n",
    "    time_off = exp_free.norm_deconv_fluor['time_vector'].iloc[off]\n",
    "    trials_plot_list.append(hv.VSpan(time_on, time_off).opts(color='gray', alpha=0.25))\n",
    "trials_plot = hv.Overlay(trials_plot_list)\n",
    "\n",
    "for variable in processing_parameters.variable_list_free:\n",
    "    save_path = os.path.join(fig_path, '3_freely_moving_cells_traces_ethogram', f'{variable}.png')\n",
    "    var_plot = hv.Curve(exp_free.kinematics[['time_vector', variable]]).opts(color='black', height=50, width=1000, xaxis=None, xlabel=None, ylabel=None,)\n",
    "    var_plot = var_plot #* trials_plot\n",
    "    var_plot = fp.save_figure(var_plot.opts(yaxis=None), save_path=save_path, fig_width=9, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "    plt_list.append(var_plot)\n",
    "\n",
    "# ethogram = hv.Layout(plt_list).cols(1)\n",
    "# ethogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8d855",
   "metadata": {},
   "source": [
    "# Figures 6, 7, 10: Polar vis TC plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50726bd",
   "metadata": {},
   "source": [
    "## Head Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polar tuning curves for the matched head fixed cells\n",
    "fig_list = []\n",
    "for i, cell in enumerate(exp_fixed.cells_to_match):\n",
    "    fig = plt.figure(layout='constrained', figsize=(3/fp.constant_in2cm, 3/fp.constant_in2cm))\n",
    "\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(fixed_tcs, cell, subfig=fig, tuning_kind='direction', \n",
    "                                              plot_selectivity=False, font_size='paper', plot_trials=False)\n",
    "    \n",
    "    save_path = os.path.join(fig_path, '6_head_fixed_example_cells_fov_dir_selectivity', f'tc_{i}.png')\n",
    "    fig.savefig(save_path, dpi=800, format='png')\n",
    "\n",
    "# For nb display\n",
    "# fig = plt.figure(layout='constrained', figsize=(len(fig_list)%2 * 3/fp.constant_in2cm, 3/fp.constant_in2cm * 2))\n",
    "# gs = fig.add_gridspec(len(fig_list)//2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a25930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polar tuning curves for the matched head fixed cells\n",
    "fig_list = []\n",
    "for i, cell in enumerate(exp_fixed.cells_to_match):\n",
    "    fig = plt.figure(layout='constrained', figsize=(2.5/fp.constant_in2cm, 2.5/fp.constant_in2cm))\n",
    "\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(fixed_tcs, cell, subfig=fig,\n",
    "                                 tuning_kind='direction', plot_selectivity=False, \n",
    "                                 plot_trials=False, plot_pref_angle=False, font_size='paper',)\n",
    "    \n",
    "    save_path = os.path.join(fig_path, '10_matched_cells_example_tuning_shift', f'fixed_tc_{i}.png')\n",
    "    fig.savefig(save_path, dpi=800, format='png')\n",
    "\n",
    "# For nb display\n",
    "# fig = plt.figure(layout='constrained', figsize=(len(fig_list)%2 * 3/fp.constant_in2cm, 3/fp.constant_in2cm * 2))\n",
    "# gs = fig.add_gridspec(len(fig_list)//2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca55f6f",
   "metadata": {},
   "source": [
    "## Freely Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_list = []\n",
    "for i, cell in enumerate(exp_free.cells_to_match):\n",
    "    fig = plt.figure(layout='constrained', figsize=(3/fp.constant_in2cm, 3/fp.constant_in2cm))\n",
    "\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(free_tcs, cell, subfig=fig,\n",
    "                                 tuning_kind='direction', plot_selectivity=False, font_size='paper')\n",
    "    \n",
    "    save_path = os.path.join(fig_path, '7_freely_moving_example_cells_fov_dir_selectivity', f'tc_{i}.png')\n",
    "    fig.savefig(save_path, dpi=800, format='png')\n",
    "\n",
    "# For nb display\n",
    "# fig = plt.figure(layout='constrained', figsize=(len(fig_list)%2 * 3/fp.constant_in2cm, 3/fp.constant_in2cm * 2))\n",
    "# gs = fig.add_gridspec(len(fig_list)//2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polar tuning curves for the matched head fixed cells\n",
    "fig_list = []\n",
    "for i, cell in enumerate(exp_free.cells_to_match):\n",
    "    fig = plt.figure(layout='constrained', figsize=(2.5/fp.constant_in2cm, 2.5/fp.constant_in2cm))\n",
    "\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(free_tcs, cell, subfig=fig,\n",
    "                                 tuning_kind='direction', plot_selectivity=False, \n",
    "                                 plot_trials=False, plot_pref_angle=False, font_size='paper',)\n",
    "    \n",
    "    save_path = os.path.join(fig_path, '10_matched_cells_example_tuning_shift', f'free_tc_{i}.png')\n",
    "    fig.savefig(save_path, dpi=800, format='png')\n",
    "\n",
    "# For nb display\n",
    "# fig = plt.figure(layout='constrained', figsize=(len(fig_list)%2 * 3/fp.constant_in2cm, 3/fp.constant_in2cm * 2))\n",
    "# gs = fig.add_gridspec(len(fig_list)//2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e761fbf",
   "metadata": {},
   "source": [
    "# Figures 4, 6, and 7: Trial Average Responses to Visual Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62066b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trial_frames(df, pre_trial=0, post_trial=0):\n",
    "    trial_idx_frames = df[df.trial_num >= 1.0].groupby(['trial_num']).apply(\n",
    "        lambda x: [x.index[0] - (pre_trial * processing_parameters.wf_frame_rate), \n",
    "                   x.index[0], x.index[-1], \n",
    "                   x.index[-1] + (post_trial * processing_parameters.wf_frame_rate) + 1]\n",
    "        ).to_numpy()\n",
    "    trial_idx_frames = np.vstack(trial_idx_frames)\n",
    "\n",
    "    if trial_idx_frames[0, 0] < 0:\n",
    "        trial_idx_frames[0, 0] = 0\n",
    "\n",
    "    if trial_idx_frames[-1, -1] > df.index[-1]:\n",
    "        trial_idx_frames[-1, -1] = df.index[-1]\n",
    "\n",
    "    # Get the shifts from the zero point (important for plotting)\n",
    "    max_zero_idx_shift = np.max(trial_idx_frames[:, 1] - trial_idx_frames[:, 0])\n",
    "    \n",
    "    traces = []\n",
    "    for i, frame in enumerate(trial_idx_frames):\n",
    "        df_slice = df.iloc[frame[0]:frame[-1], :].copy()\n",
    "        df_slice['trial_num'] = df_slice.loc[frame[1], 'trial_num']\n",
    "        df_slice['direction'] = df_slice.loc[frame[1], 'direction']\n",
    "        df_slice['direction_wrapped'] = df_slice.loc[frame[1], 'direction_wrapped']\n",
    "        df_slice['orientation'] = df_slice.loc[frame[1], 'orientation']\n",
    "        zero_idx_shift = np.abs((frame[1] - frame[0]) - max_zero_idx_shift)\n",
    "        df_slice['zero_idx_shift'] = zero_idx_shift\n",
    "\n",
    "        traces.append(df_slice)\n",
    "    \n",
    "    traces = pd.concat(traces, axis=0).reset_index(drop=True)\n",
    "    return traces, trial_idx_frames\n",
    "\n",
    "\n",
    "def trial_average_response(ds, cells_to_match, stim_type):\n",
    "    \n",
    "    ds.dropna(inplace=True)\n",
    "    idxs_shifts = ds.groupby(['trial_num']).apply(lambda x: np.unique(x.zero_idx_shift)[0]).reset_index()\n",
    "    idxs_shifts = idxs_shifts.rename({0: 'zero_idx_shift'}, axis=1)\t\n",
    "\n",
    "    if stim_type in ['orientation', 'direction', 'direction_wrapped']:\n",
    "        trials_per_stim = ds.groupby([stim_type, 'trial_num'])[cells_to_match].agg(list).reset_index()\n",
    "        trials_per_stim = trials_per_stim.join(idxs_shifts.set_index('trial_num'), on='trial_num')\n",
    "        trials_per_stim = trials_per_stim.groupby([stim_type]).agg(list)\n",
    "\n",
    "        idxs_shifts = trials_per_stim['zero_idx_shift'].copy()\n",
    "        trial_array = trials_per_stim.copy()\n",
    "\n",
    "        for i, row in trials_per_stim.iterrows():\n",
    "            for cell in cells_to_match:\n",
    "                shifts = list(idxs_shifts.loc[row.name])\n",
    "                trial_array.loc[i, cell] = fmisc.list_lists_to_array(row[cell], alignment='left')\n",
    "\n",
    "        trial_averages = trial_array.applymap(np.nanmean, axis=0)\n",
    "        trial_averages = trial_averages.drop('zero_idx_shift', axis=1)\n",
    "        trial_array = trial_array.drop('zero_idx_shift', axis=1)  \n",
    "        \n",
    "    elif stim_type == 'vis':\n",
    "        trials_per_stim = ds.groupby('trial_num')[cells_to_match].agg(list)\n",
    "        trials_per_stim = trials_per_stim.join(idxs_shifts.set_index('trial_num'), on='trial_num')\n",
    "\n",
    "        idxs_shifts = trials_per_stim['zero_idx_shift'].copy()\n",
    "        trial_averages = trials_per_stim.iloc[0, :].copy()\n",
    "        trial_array = trials_per_stim.iloc[0, :].copy()\n",
    "\n",
    "        for cell in cells_to_match:\n",
    "            trials_agg = fmisc.list_lists_to_array(trials_per_stim[cell].to_list(), alignment='left')\n",
    "            trial_array[cell] = trials_agg\n",
    "            trial_averages[cell] = np.nanmean(trials_agg, axis=0) \n",
    "\n",
    "        trial_averages = trial_averages.drop('zero_idx_shift')\n",
    "        trial_array = trial_array.drop('zero_idx_shift')  \n",
    "        \n",
    "    else:\n",
    "        raise Exception('Invalid stim_type')\n",
    "    \n",
    "\n",
    "    return trial_averages, trial_array\n",
    "\n",
    "\n",
    "def hv_plot_vis_trial_averages(trial_averages, trials, cells, stim_type):\n",
    "\n",
    "    plt_list = []\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "\n",
    "        cell_resps = trials[cell]\n",
    "        cell_mean = trial_averages[cell]\n",
    "        \n",
    "        if stim_type in ['orientation', 'direction']:\n",
    "            \n",
    "            for k in range(cell_resps.shape[-1]):\n",
    "                resps = cell_resps.iloc[k]\n",
    "                mean = cell_mean.iloc[k]\n",
    "                \n",
    "                trials_list = [hv.Curve(resps[r, :]).opts(color='k', alpha=0.25, line_width=0.75) for r in np.arange(resps.shape[0])]\n",
    "                mean_list = [hv.Curve(mean).opts(color='r', xlabel='', ylabel='')]\n",
    "                \n",
    "                if i == 0:\n",
    "                    [mean_plot.opts(title=f\"{cell_resps.index[k]:.1f}\") for mean_plot in mean_list]\n",
    "\n",
    "                plt_list.append(hv.Overlay(trials_list + mean_list))\n",
    "                \n",
    "        elif stim_type == 'vis':\n",
    "            resps = cell_resps\n",
    "            mean = cell_mean\n",
    "\n",
    "            trials_list = [hv.Curve(resps[r, :]).opts(color='k', alpha=0.25, line_width=0.75) for r in np.arange(resps.shape[0])]\n",
    "            mean_list = [hv.Curve(mean).opts(color='r', xlabel='', ylabel='')]\n",
    "            plt_list.append(hv.Overlay(trials_list + mean_list))\n",
    "\n",
    "        else:\n",
    "            raise Exception('Invalid stim_type')\n",
    "            \n",
    "    return plt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trial_period = 2\n",
    "post_trial_period = 2\n",
    "fixed_dff_trials, fixed_tc_frames = parse_trial_frames(exp_fixed.norm_deconv_fluor.copy(), pre_trial=pre_trial_period, post_trial=post_trial_period)\n",
    "free_dff_trials, free_tc_frames = parse_trial_frames(exp_free.norm_deconv_fluor.copy(), pre_trial=pre_trial_period, post_trial=post_trial_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8065d4",
   "metadata": {},
   "source": [
    "## Fig 4: Visually Evoked Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb54d8",
   "metadata": {},
   "source": [
    "### Head fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ef0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_averages, vis_trials = trial_average_response(fixed_dff_trials.copy(), exp_fixed.cells_to_match, 'vis')\n",
    "\n",
    "time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "trial_vector = np.zeros_like(time_vector)\n",
    "trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.15)\n",
    "\n",
    "norm_dff_vis = hv_plot_vis_trial_averages(vis_averages, vis_trials, exp_fixed.cells_to_match, 'vis')\n",
    "norm_dff_vis = [trial_plot * vis_plot for vis_plot in norm_dff_vis]\n",
    "norm_dff_vis = hv.Layout(norm_dff_vis).cols(len(exp_fixed.cells_to_match)).opts(hv.opts.Curve(width=100, height=160))\n",
    "\n",
    "new_norm_dff_vis = []\n",
    "for i, cell_vis_plot in enumerate(norm_dff_vis):\n",
    "        save_path = os.path.join(fig_path, '4_visually_evoked_responses', f'cell_{i}_fixed.png')\n",
    "        cell_vis_plot = cell_vis_plot * trial_plot\n",
    "        cell_vis_plot = cell_vis_plot.opts(hv.opts.Curve(width=150, height=150, xlabel=None, ylabel=None, xaxis=None, yaxis=None, title=''))\n",
    "        cell_vis_plot = fp.save_figure(cell_vis_plot, save_path=save_path, fig_width=3, dpi=800, fontsize='poster', target='save', display_factor=0.2)\n",
    "        new_norm_dff_vis.append(cell_vis_plot)\n",
    "\n",
    "hv.Layout(new_norm_dff_vis).cols(10).opts(hv.opts.Curve(width=150, height=150, xlabel=None, ylabel=None, xaxis=None, yaxis=None, title=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cde3db",
   "metadata": {},
   "source": [
    "### Freely Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7264f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_averages, vis_trials = trial_average_response(free_dff_trials.copy(), exp_free.cells_to_match, 'vis')\n",
    "\n",
    "time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "trial_vector = np.zeros_like(time_vector)\n",
    "trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.15)\n",
    "\n",
    "norm_dff_vis = hv_plot_vis_trial_averages(vis_averages, vis_trials, exp_free.cells_to_match, 'vis')\n",
    "norm_dff_vis = [trial_plot * vis_plot for vis_plot in norm_dff_vis]\n",
    "norm_dff_vis = hv.Layout(norm_dff_vis).cols(len(exp_free.cells_to_match)).opts(hv.opts.Curve(width=100, height=160))\n",
    "\n",
    "new_norm_dff_vis = []\n",
    "for i, cell_vis_plot in enumerate(norm_dff_vis):\n",
    "        save_path = os.path.join(fig_path, '4_visually_evoked_responses', f'cell_{i}_free.png')\n",
    "        cell_vis_plot = cell_vis_plot * trial_plot\n",
    "        cell_vis_plot = cell_vis_plot.opts(hv.opts.Curve(width=150, height=150, xlabel=None, ylabel=None, xaxis=None, yaxis=None, title=''))\n",
    "        cell_vis_plot = fp.save_figure(cell_vis_plot, save_path=save_path, fig_width=3, dpi=800, fontsize='poster', target='save', display_factor=0.2)\n",
    "        new_norm_dff_vis.append(cell_vis_plot)\n",
    "\n",
    "hv.Layout(new_norm_dff_vis).cols(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92405800",
   "metadata": {},
   "source": [
    "## Direction Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74f168",
   "metadata": {},
   "source": [
    "### Figure 6: Head Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_dir_averages, fixed_dir_trials = trial_average_response(fixed_dff_trials.copy(), exp_fixed.cells_to_match, 'direction_wrapped')\n",
    "\n",
    "time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "trial_vector = np.zeros_like(time_vector)\n",
    "trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.15)\n",
    "\n",
    "norm_dff_dirs = hv_plot_vis_trial_averages(fixed_dir_averages, fixed_dir_trials, exp_fixed.cells_to_match, 'direction')\n",
    "\n",
    "save_paths = []\n",
    "for cell in np.arange(fixed_dir_averages.shape[1]):\n",
    "    for dir in np.arange(fixed_dir_averages.shape[0]):\n",
    "        save_paths.append(os.path.join(fig_path, '6_head_fixed_example_cells_fov_dir_selectivity', f'tc_cell_{cell}_{dir}.png'))\n",
    "\n",
    "new_norm_dff_dirs = []\n",
    "for i, norm_dff_i in enumerate(norm_dff_dirs):\n",
    "        norm_dff_i = norm_dff_i * trial_plot\n",
    "        norm_dff_i = norm_dff_i.opts(hv.opts.Curve(width=100, height=100, xlabel=None, ylabel=None, xaxis=None, yaxis=None, title=''))\n",
    "        norm_dff_i = fp.save_figure(norm_dff_i, save_path=save_paths[i], fig_width=1, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "        new_norm_dff_dirs.append(norm_dff_i)\n",
    "\n",
    "# hv.Layout(new_norm_dff_dirs).cols(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffb06b",
   "metadata": {},
   "source": [
    "### Figure 7: Freely Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_dir_averages, free_dir_trials = trial_average_response(free_dff_trials.copy(), exp_free.cells_to_match, 'direction_wrapped',)\n",
    "\n",
    "time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "trial_vector = np.zeros_like(time_vector)\n",
    "trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.15)\n",
    "\n",
    "norm_dff_dirs = hv_plot_vis_trial_averages(free_dir_averages, free_dir_trials, exp_free.cells_to_match, 'direction')\n",
    "\n",
    "save_paths = []\n",
    "for cell in np.arange(free_dir_averages.shape[1]):\n",
    "    for dir in np.arange(free_dir_averages.shape[0]):\n",
    "        save_paths.append(os.path.join(fig_path, '7_freely_moving_example_cells_fov_dir_selectivity', f'tc_cell_{cell}_{dir}.png'))\n",
    "\n",
    "new_norm_dff_dirs = []\n",
    "for i, norm_dff_i in enumerate(norm_dff_dirs):\n",
    "        norm_dff_i = norm_dff_i * trial_plot\n",
    "        norm_dff_i = norm_dff_i.opts(hv.opts.Curve(width=100, height=100, xlabel=None, ylabel=None, xaxis=None, yaxis=None, title=''))\n",
    "        norm_dff_i = fp.save_figure(norm_dff_i, save_path=save_paths[i], fig_width=1, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "        new_norm_dff_dirs.append(norm_dff_i)\n",
    "\n",
    "# hv.Layout(new_norm_dff_dirs).cols(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e20874",
   "metadata": {},
   "source": [
    "## Orientation Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260df1ca",
   "metadata": {},
   "source": [
    "### Head Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_averages, ori_trials = trial_average_response(fixed_dff_trials.copy(), exp_fixed.cells_to_match, 'orientation')\n",
    "\n",
    "time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "trial_vector = np.zeros_like(time_vector)\n",
    "trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.25)\n",
    "\n",
    "norm_dff_oris = hv_plot_vis_trial_averages(ori_averages, ori_trials, exp_fixed.cells_to_match, 'orientation')\n",
    "norm_dff_oris = [ori_plot * trial_plot for ori_plot in norm_dff_oris]\n",
    "norm_dff_oris = hv.Layout(norm_dff_oris).cols(12).opts(hv.opts.Curve(width=100, height=160))\n",
    "norm_dff_oris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd8c08",
   "metadata": {},
   "source": [
    "### Freely Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13791b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_averages, ori_trials = trial_average_response(free_dff_trials.copy(), exp_free.cells_to_match, 'orientation')\n",
    "\n",
    "time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "trial_vector = np.zeros_like(time_vector)\n",
    "trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.25)\n",
    "\n",
    "norm_dff_oris = hv_plot_vis_trial_averages(ori_averages, ori_trials, exp_free.cells_to_match, 'orientation')\n",
    "norm_dff_oris = [ori_plot * trial_plot for ori_plot in norm_dff_oris]\n",
    "norm_dff_oris = hv.Layout(norm_dff_oris).cols(12).opts(hv.opts.Curve(width=100, height=160))\n",
    "norm_dff_oris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44fc52b",
   "metadata": {},
   "source": [
    "# Figure 5: Running Triggered Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac089ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_running_gmm_hmm(running_trace, n_components=2):\n",
    "    scores = list()\n",
    "    models = list()\n",
    "\n",
    "    for idx in range(10):  # ten different random starting states\n",
    "        # define our hidden Markov model\n",
    "        model = hmm.GMMHMM(n_components=n_components, random_state=idx, n_iter=100)\n",
    "        model.fit(running_trace)\n",
    "        models.append(model)\n",
    "        scores.append(model.score(running_trace))\n",
    "\n",
    "    # get the best model\n",
    "    model = models[np.argmax(scores)]\n",
    "    print(f'The best model had a score of {max(scores)} and '\n",
    "          f'{model.n_components} components')\n",
    "\n",
    "    # use the Viterbi algorithm to predict the most likely sequence of states\n",
    "    # given the model\n",
    "    states = model.predict(running_trace)\n",
    "    return states\n",
    "\n",
    "\n",
    "def get_running_modulated_cells(activity_df, running_bouts_idxs, ci_interval=0.95):\n",
    "    cells = [col for col in activity_df.columns if 'cell' in col]\n",
    "\n",
    "    # Find cells that are significantly modulated by running in general\n",
    "    still_bouts_idxs = np.setdiff1d(activity_df.index, running_bouts_idxs)\n",
    "    cell_running_activity = activity_df.loc[running_bouts_idxs, cells].apply(np.nanmean, axis=0)\n",
    "    cell_still_activity = activity_df.loc[still_bouts_idxs, cells].apply(np.nanmean, axis=0)\n",
    "    running_diff = cell_running_activity - cell_still_activity\n",
    "    running_cis = t.interval(ci_interval, len(running_diff) - 1,\n",
    "                             loc=np.mean(running_diff), scale=sem(running_diff))\n",
    "    sig_running_modulated = (running_diff < running_cis[0]) | (running_diff > running_cis[1])\n",
    "\n",
    "    # Find cells that are significantly modulated by running during visual stimulus\n",
    "    vis_stim_idxs = activity_df[activity_df.trial_num >= 1].index\n",
    "    vis_running_idxs = np.intersect1d(running_bouts_idxs, vis_stim_idxs)\n",
    "    vis_still_idxs = np.intersect1d(still_bouts_idxs, vis_stim_idxs)\n",
    "    vis_cell_running_activity = activity_df.loc[vis_running_idxs, cells].apply(np.nanmean, axis=0)\n",
    "    vis_cell_still_activity = activity_df.loc[vis_still_idxs, cells].apply(np.nanmean, axis=0)\n",
    "    vis_running_diff = vis_cell_running_activity - vis_cell_still_activity\n",
    "    vis_running_cis = t.interval(ci_interval, len(vis_running_diff) - 1,\n",
    "                                 loc=np.mean(vis_running_diff), scale=sem(vis_running_diff))\n",
    "    sig_vis_running_modulated = (vis_running_diff < vis_running_cis[0]) | (vis_running_diff > vis_running_cis[1])\n",
    "\n",
    "    df = pd.DataFrame({'cell': cells, 'run_activity': cell_running_activity, 'still_activity': cell_still_activity,\n",
    "                       'run_diff': running_diff, 'sig_run_modulated': sig_running_modulated,\n",
    "                       'vis_run_activity': cell_running_activity, 'vis_still_activity': cell_still_activity,\n",
    "                       'vis_run_diff': vis_running_diff, 'sig_vis_run_modulated': sig_vis_running_modulated})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def running_triggered_averages(activity, running, running_idxs, min_duration=0.5, pre_trial=0, post_trial=0):\n",
    "\n",
    "    activity.dropna(inplace=True)\n",
    "\n",
    "    # Group contiuous bouts\n",
    "    min_duration *= processing_parameters.wf_frame_rate    # convert to frames\n",
    "    bouts = [bout for bout in fmisc.consecutive(running_idxs, stepsize=int(min_duration)) if len(bout) >= min_duration]\n",
    "    bouts = np.array([[bout[0], bout[0] + post_trial*processing_parameters.wf_frame_rate] for bout in bouts])\n",
    "\n",
    "    bouts[:, 0] -= pre_trial * processing_parameters.wf_frame_rate\n",
    "\n",
    "    if bouts[-1, 1] > activity.index[-1]:\n",
    "        bouts[-1, 1] = activity.index[-1]\n",
    "    if bouts[0, 0] < 0:\n",
    "        bouts[0, 0] = 0\n",
    "\n",
    "    # Get the shifts from the zero point (important for plotting)\n",
    "    max_zero_idx_shift = np.max(bouts[:, 1] - bouts[:, 0])\n",
    "\n",
    "    traces = []\n",
    "    for i, frame in enumerate(bouts):\n",
    "        ds_slice = activity.iloc[frame[0]:frame[1], :].copy()\n",
    "        ds_slice['trial_num'] = i\n",
    "\n",
    "        zero_idx_shift = np.abs((frame[1] - frame[0]) - max_zero_idx_shift)\n",
    "        ds_slice['zero_idx_shift'] = zero_idx_shift\n",
    "\n",
    "        traces.append(ds_slice)\n",
    "\n",
    "\n",
    "    traces = pd.concat(traces, axis=0).reset_index(drop=True)\n",
    "    # traces.drop(['trial_num', 'direction', 'direction_wrapped', 'orientation'], axis=1, inplace=True)\n",
    "    # traces = traces.groupby('trial_num').agg(list)\n",
    "    return traces, bouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bba482",
   "metadata": {},
   "source": [
    "## Head Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfc81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for running speed with log spaced bins\n",
    "lower_lim = 0.1\n",
    "zeros = exp_fixed.kinematics['wheel_speed_abs'][exp_fixed.kinematics['wheel_speed_abs'] <= lower_lim].count()\n",
    "print(zeros)\n",
    "counts, edges = np.histogram(exp_fixed.kinematics['wheel_speed_abs'][exp_fixed.kinematics['wheel_speed_abs'] >= 0.1], bins=np.logspace(np.log10(lower_lim),np.log10(100), 50))\n",
    "hv.Histogram((edges, counts)).opts(xlabel='Running Wheel Speed [cm/s]', ylabel='Frequency', logx=True, logy=False).opts(width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7162a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed_fixed = exp_fixed.kinematics['wheel_speed_abs'].max() + 3\n",
    "run_plot = hv.Curve(exp_fixed.kinematics[['time_vector', 'wheel_speed_abs']]).opts(color='k')\n",
    "\n",
    "# Use GMM - HMM to predict running state\n",
    "running_prediction = predict_running_gmm_hmm(exp_fixed.kinematics['wheel_speed_abs'].to_numpy().reshape(-1,1), n_components=2)\n",
    "running_idxs = np.argwhere(running_prediction > 0).flatten()\n",
    "still_idxs = np.argwhere(running_prediction == 0).flatten()\n",
    "\n",
    "run_times = exp_fixed.kinematics['time_vector'].iloc[running_idxs].values\n",
    "scatter_y = np.ones_like(run_times) * max_speed_fixed\n",
    "scatter_points = np.column_stack((run_times, scatter_y))\n",
    "run_highlight = hv.Scatter(scatter_points).opts(color='r', alpha=0.5)\n",
    "fixed_speed_plot = hv.Overlay([run_highlight, run_plot]).opts(height=140, width=1400, yaxis=None, xaxis=None, xlabel=None, ylabel=None)\n",
    "\n",
    "save_path = os.path.join(fig_path, '5_running_evoked_responses', 'fixed_speed_annotated.png')\n",
    "fixed_speed_plot = fp.save_figure(fixed_speed_plot, save_path=save_path, fig_width=14, dpi=800, fontsize='paper', target='save', display_factor=0.3)\n",
    "\n",
    "print(exp_fixed.kinematics['wheel_speed_abs'].min(), exp_fixed.kinematics['wheel_speed_abs'].max())\n",
    "fixed_speed_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c982d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_traces, run_bouts = running_triggered_averages(exp_fixed.norm_deconv_fluor.copy(), exp_fixed.kinematics['wheel_speed_abs'], running_idxs, min_duration=0.1, pre_trial=1, post_trial=4)\n",
    "idxs_shifts = run_traces.groupby(['trial_num']).apply(lambda x: np.unique(x.zero_idx_shift)[0]).reset_index().rename({0: 'zero_idx_shift'}, axis=1)\t\n",
    "run_traces = run_traces[list(exp_fixed.cells_to_match) + ['trial_num', 'zero_idx_shift']].groupby('trial_num').agg(list)\n",
    "\n",
    "plot_list = []\n",
    "\n",
    "for i, cell in enumerate(exp_fixed.cells_to_match):\n",
    "    save_path = os.path.join(fig_path, '5_running_evoked_responses', f'fixed_cell_{i}.png')\n",
    "\n",
    "    resps = fmisc.list_lists_to_array(run_traces[cell].tolist(), alignment='left')\n",
    "    mean = np.nanmean(resps, axis=0)\n",
    "\n",
    "    trials_list = [hv.Curve(resps[r, :]).opts(color='gray', alpha=0.25) for r in np.arange(resps.shape[0])]\n",
    "    mean_list = [hv.Curve((np.arange(0, mean.shape[0]), mean)).opts(color='r', xticks=[(0, -2), (40, 0), (90, 2.5), (140, 5)], xlabel='', ylabel='', title=cell, fontsize={'xticks': 10, 'yticks': 10,})]\n",
    "    vlines = [hv.VLine(20).opts(color='k', alpha=1, line_width=0.5)]\n",
    "    run_evoked_plot = hv.Overlay(trials_list + mean_list + vlines).opts(width=150, height=150, yaxis=None, xaxis=None, xlabel=None, ylabel=None, title='')\n",
    "    run_evoked_plot = fp.save_figure(run_evoked_plot, save_path=save_path, fig_width=3, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "    plot_list.append(run_evoked_plot)\n",
    "\n",
    "running_trig_avg = hv.Layout(plot_list)\n",
    "running_trig_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f36ff2",
   "metadata": {},
   "source": [
    "## Freely Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1672ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for running speed\n",
    "\n",
    "# create a histogram with log spaced bins\n",
    "lower_lim = 0.1\n",
    "zeros = exp_free.kinematics['mouse_speed'][exp_free.kinematics['mouse_speed'] <= lower_lim].count()\n",
    "print(zeros)\n",
    "counts, edges = np.histogram(exp_free.kinematics['mouse_speed'][exp_free.kinematics['mouse_speed'] >= 0.1], bins=np.logspace(np.log10(lower_lim),np.log10(100), 50))\n",
    "hv.Histogram((edges, counts)).opts(xlabel='Running Speed [cm/s]', ylabel='Frequency', logx=True, logy=False).opts(width=500, height=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_free.kinematics['mouse_speed'][exp_free.kinematics['mouse_speed'] > 50] = exp_free.kinematics['mouse_speed'].mean()\n",
    "max_speed_fixed = exp_free.kinematics['mouse_speed'].max() + 3\n",
    "run_plot = hv.Curve(exp_free.kinematics[['time_vector', 'mouse_speed']]).opts(color='k', ylim=(0, 55))\n",
    "\n",
    "# Use GMM - HMM to predict running state\n",
    "running_prediction = predict_running_gmm_hmm(exp_free.kinematics['mouse_speed'].to_numpy().reshape(-1,1), n_components=2)\n",
    "running_idxs = np.argwhere(running_prediction > 0).flatten()\n",
    "still_idxs = np.argwhere(running_prediction == 0).flatten()\n",
    "\n",
    "run_times = exp_free.kinematics['time_vector'].iloc[running_idxs].values\n",
    "scatter_y = np.ones_like(run_times) * max_speed_fixed\n",
    "scatter_points = np.column_stack((run_times, scatter_y))\n",
    "run_highlight = hv.Scatter(scatter_points).opts(color='r', alpha=0.5)\n",
    "free_speed_plot = hv.Overlay([run_highlight, run_plot]).opts(height=140, width=1400, yaxis=None, xaxis=None, xlabel=None, ylabel=None)\n",
    "\n",
    "save_path = os.path.join(fig_path, '5_running_evoked_responses', f'free_speed_annotated.png')\n",
    "free_speed_plot = fp.save_figure(free_speed_plot, save_path=save_path, fig_width=14, dpi=800, fontsize='paper', target='save', display_factor=0.3)\n",
    "\n",
    "print(exp_free.kinematics['mouse_speed'].min(), exp_free.kinematics['mouse_speed'].max())\n",
    "free_speed_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_traces, run_bouts = running_triggered_averages(exp_free.norm_deconv_fluor.copy(), exp_free.kinematics['mouse_speed'], running_idxs, min_duration=0.1, pre_trial=1, post_trial=4)\n",
    "idxs_shifts = run_traces.groupby(['trial_num']).apply(lambda x: np.unique(x.zero_idx_shift)[0]).reset_index().rename({0: 'zero_idx_shift'}, axis=1)\t\n",
    "run_traces = run_traces[list(exp_free.cells_to_match) + ['trial_num', 'zero_idx_shift']].groupby('trial_num').agg(list)\n",
    "\n",
    "plot_list = []\n",
    "\n",
    "for i, cell in enumerate(exp_free.cells_to_match):\n",
    "    save_path = os.path.join(fig_path, '5_running_evoked_responses', f'free_cell_{i}.png')\n",
    "\n",
    "    resps = fmisc.list_lists_to_array(run_traces[cell].tolist(), alignment='left')\n",
    "    mean = np.nanmean(resps, axis=0)\n",
    "\n",
    "    trials_list = [hv.Curve(resps[r, :]).opts(color='gray', alpha=0.25) for r in np.arange(resps.shape[0])]\n",
    "    mean_list = [hv.Curve((np.arange(0, mean.shape[0]), mean)).opts(color='r', xticks=[(0, -2), (40, 0), (90, 2.5), (140, 5)], xlabel='', ylabel='', title=cell, fontsize={'xticks': 10, 'yticks': 10,})]\n",
    "    vlines = [hv.VLine(20).opts(color='k', alpha=1, line_width=0.5)]\n",
    "    run_evoked_plot = hv.Overlay(trials_list + mean_list + vlines).opts(width=150, height=150, yaxis=None, xaxis=None, xlabel=None, ylabel=None, title='')\n",
    "    run_evoked_plot = fp.save_figure(run_evoked_plot, save_path=save_path, fig_width=3, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "    plot_list.append(run_evoked_plot)\n",
    "\n",
    "running_trig_avg = hv.Layout(plot_list)\n",
    "running_trig_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfff66",
   "metadata": {},
   "source": [
    "# Figure 13: Kinematic Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158dd4c5",
   "metadata": {},
   "source": [
    "## Head Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53dfb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fixed.self_motion_tcs.list_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c038aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_plot_list = []\n",
    "for c, cell in enumerate(exp_fixed.cells_to_match):\n",
    "    cell_int = int(cell.split('_')[-1])\n",
    "    for i, variable in enumerate(exp_fixed.self_motion_tcs.list_attributes()):\n",
    "        data = getattr(exp_fixed.self_motion_tcs, variable)\n",
    "        bin_cols = [col for col in data.columns if ('half' not in col) and ('bin'in col)]\n",
    "        half_0_bin_cols = [col for col in data.columns if ('half_0' in col) and ('bin'in col)]\n",
    "        half_1_bin_cols = [col for col in data.columns if ('half_1' in col) and ('bin'in col)]\n",
    "\n",
    "        current_bins = processing_parameters.tc_params[variable]\n",
    "        bins0 = np.linspace(current_bins[0], current_bins[1], processing_parameters.bin_number)\n",
    "        var = processing_parameters.wf_label_dictionary[variable]\n",
    "        if current_bins[0] == -1*current_bins[1]:\n",
    "            x_ticks = [current_bins[0], 0, current_bins[-1]]\n",
    "        else:\n",
    "            x_ticks = [current_bins[0], (current_bins[-1] - current_bins[0]) // 2, current_bins[-1]]\n",
    "        \n",
    "        half_0_curve = hv.Curve((bins0, data[half_0_bin_cols].iloc[cell_int].fillna(0).to_numpy()), label='half_0')\n",
    "        half_1_curve = hv.Curve((bins0, data[half_1_bin_cols].iloc[cell_int].fillna(0).to_numpy()), label='half_1')\n",
    "        full_tc_curve = hv.Curve((bins0, data[bin_cols].iloc[cell_int].fillna(0).to_numpy()), label='full').opts(ylabel='Activity [a.u.]')\n",
    "        tcs = hv.Overlay([half_0_curve, half_1_curve, full_tc_curve]).opts(hv.opts.Curve(ylim=(0, 0.1)))\n",
    "        \n",
    "        if variable == 'pupil_diameter':\n",
    "            tcs = tcs.opts(hv.opts.Curve(xlim=(0, 150), xticks=[(0,''), (75, ''), (150,'')]))\n",
    "        else:\n",
    "            tcs = tcs.opts(hv.opts.Curve(xticks=[(xt,'') for xt in x_ticks]))\n",
    "\n",
    "        tcs = tcs.opts(hv.opts.Curve(show_legend=False, width=900, height=450, xlabel='', ylabel=None, yaxis=None, xaxis='bare'))\n",
    "\n",
    "        save_path = os.path.join(fig_path, '13_example_cells_kinem_tuning_schematic', f'tc_cell_{c}_{variable}.png')\n",
    "        tcs = fp.save_figure(tcs, save_path=save_path, fig_width=2.5, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "\n",
    "        tc_plot_list.append(tcs)\n",
    "\n",
    "# hv.Layout(tc_plot_list).opts(shared_axes=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6300d",
   "metadata": {},
   "source": [
    "## Freely Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619937e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_plot_list = []\n",
    "for c, cell in enumerate(exp_free.cells_to_match):\n",
    "    cell_int = int(cell.split('_')[-1])\n",
    "    for i, variable in enumerate(exp_free.self_motion_tcs.list_attributes()):\n",
    "        data = getattr(exp_free.self_motion_tcs, variable)\n",
    "        bin_cols = [col for col in data.columns if ('half' not in col) and ('bin'in col)]\n",
    "        half_0_bin_cols = [col for col in data.columns if ('half_0' in col) and ('bin'in col)]\n",
    "        half_1_bin_cols = [col for col in data.columns if ('half_1' in col) and ('bin'in col)]\n",
    "\n",
    "        current_bins = processing_parameters.tc_params[variable]\n",
    "        bins0 = np.linspace(current_bins[0], current_bins[1], processing_parameters.bin_number)\n",
    "        var = processing_parameters.wf_label_dictionary[variable]\n",
    "        if current_bins[0] == -1*current_bins[1]:\n",
    "            x_ticks = [current_bins[0], 0, current_bins[-1]]\n",
    "        else:\n",
    "            x_ticks = [current_bins[0], (current_bins[-1] - current_bins[0]) // 2, current_bins[-1]]\n",
    "        \n",
    "        half_0_curve = hv.Curve((bins0, data[half_0_bin_cols].iloc[cell_int].fillna(0).to_numpy()), label='half_0')\n",
    "        half_1_curve = hv.Curve((bins0, data[half_1_bin_cols].iloc[cell_int].fillna(0).to_numpy()), label='half_1')\n",
    "        full_tc_curve = hv.Curve((bins0, data[bin_cols].iloc[cell_int].fillna(0).to_numpy()), label='full').opts(ylabel='Activity [a.u.]')\n",
    "        tcs = hv.Overlay([half_0_curve, half_1_curve, full_tc_curve]).opts(hv.opts.Curve(ylim=(0, 0.1)))\n",
    "\n",
    "        if variable == 'mouse_speed':\n",
    "            tcs = tcs.opts(hv.opts.Curve(xlim=(0, 50), xticks=[(0,''), (25, ''), (50,'')]))\n",
    "        elif variable == 'mouse_angular_speed':\n",
    "            tcs = tcs.opts(hv.opts.Curve(xlim=(-250, 250), xticks=[(-250,''), (0, ''), (250,'')]))\n",
    "        else:\n",
    "            tcs = tcs.opts(hv.opts.Curve(xticks=[(xt,'') for xt in x_ticks]))\n",
    "\n",
    "        tcs = tcs.opts(hv.opts.Curve(show_legend=False, width=900, height=450, xlabel='', ylabel=None, yaxis=None, xaxis='bare'))\n",
    "\n",
    "        save_path = os.path.join(fig_path, '13_example_cells_kinem_tuning_schematic', f'tc_cell_{c}_{variable}.png')\n",
    "        tcs = fp.save_figure(tcs, save_path=save_path, fig_width=2.5, dpi=800, fontsize='paper', target='save', display_factor=0.2)\n",
    "\n",
    "        tc_plot_list.append(tcs)\n",
    "\n",
    "# hv.Layout(tc_plot_list).opts(shared_axes=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9e541",
   "metadata": {},
   "source": [
    "# Still Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41022ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "still_trials = exp.kinematics.groupby('trial_num').filter(lambda x: x[speed_column].mean() < speed_cutoff).trial_num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5410107",
   "metadata": {},
   "outputs": [],
   "source": [
    "still_ori_averages, still_ori_trials = trial_average_response(dff_trials.loc[dff_trials.trial_num.isin(still_trials)].copy(), 'orientation')\n",
    "\n",
    "time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "trial_vector = np.zeros_like(time_vector)\n",
    "trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.25)\n",
    "\n",
    "norm_dff_oris_still = hv_plot_trial_averages(still_ori_averages, still_ori_trials, cells_to_match).cols(12).opts(hv.opts.Curve(width=100, height=160))\n",
    "norm_dff_oris_still = norm_dff_oris_still * trial_plot\n",
    "norm_dff_oris_still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c812636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "still_dir_averages, still_dir_trials = trial_average_response(dff_trials.loc[dff_trials.trial_num.isin(still_trials)].copy(), 'direction_wrapped')\n",
    "\n",
    "time_vector = np.linspace(-pre_trial_period, 5 + post_trial_period, (5 + pre_trial_period + post_trial_period) * processing_parameters.wf_frame_rate) \n",
    "trial_vector = np.zeros_like(time_vector)\n",
    "trial_vector[(time_vector >= 0) & (time_vector <= 5)] = 1\n",
    "trial_plot = hv.Area(trial_vector).opts(color='gray', alpha=0.25)\n",
    "\n",
    "norm_dff_dirs_still = hv_plot_trial_averages(still_dir_averages, still_dir_trials, cells_to_match).cols(12).opts(hv.opts.Curve(width=100, height=160))\n",
    "norm_dff_dirs_still = norm_dff_dirs_still * trial_plot\n",
    "norm_dff_dirs_still"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd3478",
   "metadata": {},
   "source": [
    "# Test thresholding for all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf74f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vis_ori_dir_responsivity(trial_activity, iti_mean_activity, iti_std_activity, trial_info, num_std=6):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the visual, direction, and orientation responsivity of cells based on trial activity.\n",
    "\n",
    "    Args:\n",
    "        trial_activity (DataFrame): DataFrame containing trial activity data.\n",
    "        iti_mean_activity (DataFrame): DataFrame containing ITI mean activity data.\n",
    "        iti_std_activity (DataFrame): DataFrame containing ITI standard deviation activity data.\n",
    "        num_std (int, optional): Number of standard deviations above the ITI mean to consider a cell visually responsive. Defaults to 6.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three boolean arrays indicating the visual, direction, and orientation responsivity of cells.\n",
    "    \"\"\"\n",
    "\n",
    "    cells = [col for col in trial_activity.index.to_list() if 'cell' in col]\n",
    "\n",
    "    # Determine if cell is visually responsive\n",
    "    #    A cell is responsive if during a trial its max response during that trial is greater than 6 stds above the\n",
    "    #    ITI mean. To be considered visually responsive, a cell must respond during at least 50% of the trials\n",
    "\n",
    "    a = trial_activity[cells] - iti_mean_activity[cells]\n",
    "    b = num_std * iti_std_activity[cells] #+ iti_mean_activity[cells]\n",
    "    aa = np.array(a.to_list()).T\n",
    "    bb = np.array(b.to_list()).T\n",
    "    vis_trial_resps = pd.DataFrame(aa >= bb, columns=cells)\n",
    "    vis_trial_resps = trial_info.join(vis_trial_resps)\n",
    "\n",
    "    is_vis_responsive = vis_trial_resps[cells].apply(lambda x: x.sum() >= np.ceil(x.count() / 2))\n",
    "\n",
    "    # Determine if a cell is direction responsive\n",
    "    #    To be considered direction responsive, a cell must respond to at least 50% of the trials for at least one\n",
    "    #    direction stimulus\n",
    "    is_direction_responsive = (vis_trial_resps.groupby(['direction_wrapped'])[cells].agg(list)\n",
    "                               .applymap(lambda x: np.sum(x) >= np.ceil(len(x) / 2)))\n",
    "    is_direction_responsive = is_direction_responsive[cells].apply(lambda x: x.sum() > 0)\n",
    "\n",
    "    # Determine if a cell is orientation responsive\n",
    "    #    To be considered direction responsive, a cell must respond to at least 50% of the trials for at least one\n",
    "    #    orientation stimulus\n",
    "    is_orientation_responsive = (vis_trial_resps.groupby(['orientation'])[cells].agg(list)\n",
    "                                 .applymap(lambda x: np.sum(x) >= np.ceil(len(x) / 2)))\n",
    "    is_orientation_responsive = is_orientation_responsive[cells].apply(lambda x: x.sum() > 0)\n",
    "\n",
    "    return vis_trial_resps, is_vis_responsive, is_direction_responsive, is_orientation_responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_exp = 'free'\n",
    "this_std = 8\n",
    "\n",
    "if use_exp == 'free':\n",
    "    this_exp = exp_free\n",
    "    this_tc = free_tcs\n",
    "else:\n",
    "    this_exp = exp_fixed\n",
    "    this_tc = fixed_tcs\n",
    "\n",
    "trial_max_activity = this_tc.max_vis_activity\n",
    "trial_mean_activity = this_tc.mean_vis_activity\n",
    "trial_std_activity = this_tc.std_vis_activity\n",
    "trial_auc_activity = this_tc.auc_vis_activity\n",
    "\n",
    "iti_max_activity = this_tc.max_baseline_activity\n",
    "iti_mean_activity = this_tc.mean_baseline_activity\n",
    "iti_std_activity = this_tc.std_baseline_activity\n",
    "iti_auc_activity = this_tc.auc_baseline_activity\n",
    "is_gen_responsive = ~this_tc.is_gen_responsive.astype(bool)\n",
    "\n",
    "trial_info = this_exp.norm_deconv_fluor_viewed.loc[this_exp.norm_deconv_fluor_viewed.trial_num > 0, ['trial_num', 'direction_wrapped', 'orientation']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "vis_trial_resps, is_vis_responsive, is_direction_responsive, is_orientation_responsive = \\\n",
    "        calculate_vis_ori_dir_responsivity(trial_max_activity, iti_mean_activity, iti_std_activity, trial_info, num_std=this_std)\n",
    "\n",
    "resp_df = pd.DataFrame({'gen': is_gen_responsive, 'vis': is_vis_responsive, 'dir': is_direction_responsive, 'ori': is_orientation_responsive})\n",
    "print(resp_df.sum())\n",
    "\n",
    "gen_resp_cells = resp_df[resp_df.gen].index.to_list()\n",
    "\n",
    "vis_gen_cells = resp_df.loc[resp_df.vis & resp_df.gen].index.to_list()\n",
    "vis_no_gen_cells = resp_df.loc[resp_df.vis & ~resp_df.gen].index.to_list()\n",
    "\n",
    "dir_gen_cells = resp_df.loc[resp_df.dir & resp_df.gen].index.to_list()\n",
    "dir_no_gen_cells = resp_df.loc[resp_df.dir & ~resp_df.gen].index.to_list()\n",
    "\n",
    "ori_gen_cells = resp_df.loc[resp_df.ori & resp_df.gen].index.to_list()\n",
    "ori_no_gen_cells = resp_df.loc[resp_df.ori & ~resp_df.gen].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [col for col in trial_auc_activity.index.to_list() if 'cell' in col]\n",
    "a = trial_max_activity - iti_mean_activity\n",
    "b = this_std * iti_std_activity\n",
    "aa = np.array(a.to_list()).T\n",
    "bb = np.array(b.to_list()).T\n",
    "vis_trial_resps = pd.DataFrame(aa >= bb, columns=cells)\n",
    "\n",
    "plt.scatter(aa.flatten(), bb.flatten(), c=vis_trial_resps.values.flatten())\n",
    "plt.xlabel('trial_max - iti_mean')\n",
    "plt.ylabel(f'{std} * iti_std_activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                                   plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                                   fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(gen_resp_cells, min(10, len(gen_resp_cells)), replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                                   plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                                   fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(vis_gen_cells, min(10, len(vis_gen_cells)), replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                                   plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                                   fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(vis_no_gen_cells, min(10, len(vis_no_gen_cells)), replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d37795",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                                   plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                                   fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(dir_gen_cells, min(10, len(dir_gen_cells)), replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                                   plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                                   fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(dir_no_gen_cells, min(10, len(dir_no_gen_cells)), replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae4967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
