{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc22c5e-f78c-4e1d-afc8-c1b2651cbd50",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import datashader as dshade\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.io import export_svgs, export_png\n",
    "from bokeh.plotting import show\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation import histogram\n",
    "from holoviews.operation.datashader import datashade, shade\n",
    "hv.extension('bokeh')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "import paths\n",
    "import processing_parameters\n",
    "import functions_bondjango as bd\n",
    "import functions_plotting as fp\n",
    "import functions_data_handling as fdh\n",
    "import functions_kinematic as fk\n",
    "import functions_misc as misc\n",
    "from wirefree_experiment import WirefreeExperiment, DataContainer\n",
    "\n",
    "importlib.reload(fp)\n",
    "# set up the figure theme\n",
    "fp.set_theme()\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "cm = 1./2.54\n",
    "figure_save_path = r\"C:\\Users\\mmccann\\Dropbox\\bonhoeffer lab\\thesis\\figures\\figure_media\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6fc95b12-72a0-4cf3-a724-7058f205419e",
   "metadata": {},
   "source": [
    "# Load aggregate files from all mice to make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d5f81",
   "metadata": {},
   "source": [
    "# If saving file for the first time, set save to True\n",
    "save = False\n",
    "agg_dict = {}\n",
    "search_string = f\"result:repeat, lighting:normal\"\n",
    "\n",
    "\n",
    "if save:\n",
    "    # get the search string\n",
    "    search_string += f\", analysis_type:agg_tc\"\n",
    "    parsed_search = fdh.parse_search_string(search_string)\n",
    "    output_path = os.path.join(paths.analysis_path, f\"AGG_{'_'.join(parsed_search.values())}.hdf5\")\n",
    "\n",
    "    # get the paths from the database\n",
    "    file_infos = bd.query_database(\"analyzed_data\", search_string)\n",
    "    input_paths = np.array([el['analysis_path'] for el in file_infos if ('agg' in el['slug'])])\n",
    "\n",
    "    data_list = []\n",
    "    for file in tqdm(input_paths, desc=\"Loading files\"):\n",
    "        print(file)\n",
    "        data_dict = {}\n",
    "        mouse = '_'.join(os.path.basename(file).split('_')[10:13])\n",
    "\n",
    "        with pd.HDFStore(file, 'r') as tc:\n",
    "\n",
    "            if 'no_ROIs'in tc.keys():\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                \n",
    "                for key in tc.keys():\n",
    "                    label = \"_\".join(key.split('/')[1:])\n",
    "                    data = tc[key]\n",
    "                    if 'animal' in data.columns:\n",
    "                        data = data.drop(columns='animal')\n",
    "\n",
    "                    if '08_31_2023_VWheelWF_fixed2' in data.columns:\n",
    "                        data.drop(columns='08_31_2023_VWheelWF_fixed2', inplace=True)\n",
    "\n",
    "                    data['mouse'] = mouse\n",
    "                    data_dict[label] = data\n",
    "                        \n",
    "                data_list.append(data_dict)\n",
    "\n",
    "    # Aggregate it all\n",
    "    agg_dict = {}\n",
    "    \n",
    "    for key in data_list[0].keys():\n",
    "        df = pd.concat([d[key] for d in data_list]).reset_index(drop=True)\n",
    "        df.to_hdf(output_path, key)\n",
    "        agg_dict[key] = df\n",
    "\n",
    "    # assemble the entry data\n",
    "    entry_data = {\n",
    "        'analysis_type': 'agg_all',\n",
    "        'analysis_path': output_path,\n",
    "        'date': '',\n",
    "        'pic_path': '',\n",
    "        'result': parsed_search['result'],\n",
    "        'rig': parsed_search['rig'],\n",
    "        'lighting': parsed_search['lighting'],\n",
    "        'imaging': 'wirefree',\n",
    "        'slug': misc.slugify(os.path.basename(output_path)[:-5]),\n",
    "        }\n",
    "\n",
    "    # check if the entry already exists, if so, update it, otherwise, create it\n",
    "    update_url = '/'.join((paths.bondjango_url, 'analyzed_data', entry_data['slug'], ''))\n",
    "    output_entry = bd.update_entry(update_url, entry_data)\n",
    "    if output_entry.status_code == 404:\n",
    "        # build the url for creating an entry\n",
    "        create_url = '/'.join((paths.bondjango_url, 'analyzed_data', ''))\n",
    "        output_entry = bd.create_entry(create_url, entry_data)\n",
    "\n",
    "    print('The output status was %i, reason %s' % (output_entry.status_code, output_entry.reason))\n",
    "    if output_entry.status_code in [500, 400]:\n",
    "        print(entry_data)\n",
    "\n",
    "else:\n",
    "    search_string += f\", analysis_type:agg_all\"\n",
    "    parsed_search = fdh.parse_search_string(search_string)\n",
    "\n",
    "    file_infos = bd.query_database(\"analyzed_data\", search_string)\n",
    "    input_paths = np.array([el['analysis_path'] for el in file_infos])\n",
    "    print(np.sort(input_paths))\n",
    "\n",
    "    with pd.HDFStore(input_paths[0], 'r') as tc:\n",
    "        for key in tc.keys():\n",
    "            label = \"_\".join(key.split('/')[1:])\n",
    "            data = tc[key]\n",
    "            agg_dict[label] = data\n",
    "\n",
    "if parsed_search['result'] == 'repeat':\n",
    "    if parsed_search['rig'] == 'VWheelWF':\n",
    "        session_types = ['fixed0', 'fixed1']\n",
    "    else:\n",
    "        session_types = ['free0', 'free1']\n",
    "    session_shorthand = session_types\n",
    "else:\n",
    "    session_types = ['VWheelWF', 'VTuningWF']\n",
    "    session_shorthand = ['fixed', 'free']\n",
    "\n",
    "save_suffix = f\"{parsed_search['result']}_{parsed_search['lighting']}_{parsed_search['rig']}\"\n",
    "\n",
    "# Specify the path to the curated cell matches file\n",
    "excel_file_path = os.path.join(r\"C:\\Users\\mmccann\\Desktop\", \n",
    "                               f\"curated_cell_matches_{parsed_search['result']}_{parsed_search['lighting']}_{parsed_search['rig']}.xlsx\")\n",
    "\n",
    "try:\n",
    "    # Read all sheets into a list of dataframes\n",
    "    curated_matches_dict = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "\n",
    "    # Concatenate the dataframes into a single dataframe\n",
    "    curated_matches = pd.concat(curated_matches_dict.values(), ignore_index=True)\n",
    "except:\n",
    "    print(f\"Could not find the file {excel_file_path}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b224e",
   "metadata": {},
   "source": [
    "cell_kind = 'all_cells'\n",
    "activity_dataset = 'norm_spikes_viewed_props'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2e2cb504-1c48-4330-916b-9c3e8dff4dda",
   "metadata": {},
   "source": [
    "# Cell matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "match_nums = agg_dict['cell_matches'].groupby(['mouse', 'day']).apply(lambda x: x.loc[:, session_types[0]].count()).values\n",
    "\n",
    "num0 = agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'].groupby(['mouse', 'day']).apply(lambda x: len(x)).values\n",
    "num1 = agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'].groupby(['mouse', 'day']).apply(lambda x: len(x)).values\n",
    "\n",
    "match_frac0 = match_nums/num0\n",
    "match_frac1 = match_nums/num1\n",
    "\n",
    "frequencies0, edges0 = np.histogram(match_frac0, 20)\n",
    "frequencies1, edges1 = np.histogram(match_frac1, 20)\n",
    "\n",
    "# print('Values: %s, Edges: %s' % (frequencies.shape[0], edges.shape[0]))\n",
    "frac_cell_match_hist0 = hv.Histogram((edges0, frequencies0), label=session_shorthand[0]).opts(xlabel='Frac. Matched Cells', ylabel='Freq.', alpha=0.5)\n",
    "frac_cell_match_hist1 = hv.Histogram((edges1, frequencies1), label=session_shorthand[1]).opts(xlabel='Frac. Matched Cells', ylabel='Freq.', alpha=0.5)\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"frac_cells_matched_{parsed_search['result']}_{parsed_search['rig']}.png\")\n",
    "\n",
    "frac_cell_match_overlay = frac_cell_match_hist0 * frac_cell_match_hist1\n",
    "frac_cell_match_overlay = fp.save_figure(frac_cell_match_overlay, save_path=save_path, fig_width=10, dpi=800, fontsize='screen', target='screen', display_factor=0.2)"
   ],
   "id": "9d7d979a2f7c0517",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c71a6d",
   "metadata": {},
   "source": [
    "scatter = hv.Points((match_frac0, match_frac1))\n",
    "scatter.opts(xlim=(0, 1), xlabel=f'Frac. Match {session_shorthand[0].title()}',\n",
    "             ylim=(0, 1), ylabel=f'Frac. Match {session_shorthand[1].title()}',\n",
    "             size=10, color='blue', width=500, height=500)\n",
    "line = hv.Curve((np.linspace(0, 1, 101), np.linspace(0, 1, 101))).opts(color='gray')\n",
    "frac_cell_match_scatter = line * scatter\n",
    "frac_cell_match_scatter\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"frac_cells_matched_{save_suffix}.png\")\n",
    "frac_cell_match_scatter = fp.save_figure(frac_cell_match_scatter, save_path=save_path, fig_width=5, dpi=500, fontsize='paper', target='both', display_factor=0.4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "41b0a313",
   "metadata": {},
   "source": [
    "# Fraction visually responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def violin_swarm(ds, save_path, backend='hvplot', save=False, cmap='blue', \n",
    "                 xlabel='', ylabel='',\n",
    "                 width=1500, height=1000, font_size='screen', dpi=800):\n",
    "\n",
    "    rename_dict = dict(zip(list(ds.columns), [processing_parameters.wf_label_dictionary_wo_units[col] for col in list(ds.columns)]))\n",
    "\n",
    "    ds = ds.rename(columns=rename_dict)\n",
    "\n",
    "    if backend=='hvplot':\n",
    "        violinplot = ds[list(rename_dict.values())].hvplot.violin(legend=False, inner='quartiles', color=cmap)\n",
    "        violinplot.opts(xlabel=xlabel, ylabel=ylabel, ylim=(-0.05, 1.05), xrotation=45, width=width, height=height)\n",
    "        if save:\n",
    "            violinplot = fp.save_figure(violinplot, save_path=save_path, fig_width=width, dpi=dpi, fontsize='screen', target='both', display_factor=0.1)\n",
    "        else:\n",
    "            violinplot = fp.save_figure(violinplot, save_path=save_path, fig_width=width, dpi=dpi, fontsize='screen', target='screen', display_factor=0.1)\n",
    "        return violinplot\n",
    "    \n",
    "    elif backend=='seaborn':\n",
    "        swarm_palette = {k:'k' for k in rename_dict.values()}\n",
    "        fig, ax = plt.subplots(figsize=(width, height))\n",
    "        violinplot = sns.violinplot(data=ds[list(rename_dict.values())], color=cmap, native_scale=True, width=1)\n",
    "        violinplot = sns.stripplot(data=ds[list(rename_dict.values())], size=2, palette=swarm_palette, marker=\"x\", linewidth=1)\n",
    "        ax.set_ylim((-0.05, 1.05))\n",
    "        violinplot.spines[['right', 'top']].set_visible(False)\n",
    "        font_size = int(fp.font_sizes_raw[font_size]['xlabel'][:-2])\n",
    "        violinplot.set_xlabel(xlabel, fontsize=font_size)\n",
    "        violinplot.set_ylabel(ylabel, fontsize=font_size)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(save_path, dpi=dpi, format='png')\n",
    "\n",
    "        return violinplot\n",
    "    else:\n",
    "        return Exception('Invalid backend')\n",
    "    \n",
    "def hv_hist(ds, key, label, drop_na=True, xlabel=''):\n",
    "    data = ds[key].copy()\n",
    "\n",
    "    if drop_na:\n",
    "        data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        data.dropna(inplace=True)\n",
    "        data = data[data >= 0]\n",
    "        \n",
    "    frequencies, edges = np.histogram(data, 20)\n",
    "    hist = hv.Histogram((edges, frequencies), label=label).opts(xlabel=xlabel, ylabel='Freq.')\n",
    "    return hist"
   ],
   "id": "87d9a9b8ac24def",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738376d",
   "metadata": {},
   "source": [
    "def vis_frac_responsive(ds):\n",
    "    is_ori_resp = ds['osi'] > 0.5\n",
    "    is_dir_resp = ds['dsi_abs'] > 0.5\n",
    "    frac_ori_resp = is_ori_resp.sum() / is_ori_resp.count()\n",
    "    frac_dir_resp = is_dir_resp.sum() / is_dir_resp.count()\n",
    "\n",
    "    is_vis_resp = is_ori_resp + is_dir_resp\n",
    "    is_vis_resp = is_vis_resp > 0\n",
    "    frac_vis_resp = is_vis_resp.sum() / is_vis_resp.count()\n",
    "\n",
    "    return is_vis_resp, frac_vis_resp, frac_ori_resp, frac_dir_resp\n",
    "\n",
    "def get_sig_tuned_vis_cells(agg_dict, exp_kind, which_cells):\n",
    "    ds_name = '_'.join([exp_kind, which_cells, 'norm_spikes_viewed_props'])\n",
    "    data = agg_dict[ds_name]\n",
    "    df = pd.DataFrame(columns=['is_vis_resp', 'frac_vis_resp', 'frac_ori_resp', 'frac_dir_resp'])\n",
    "\n",
    "    # Assign direction vs orientation selectivity\n",
    "    data['is_dir_seleective'] = data['dsi_abs'] > 0.3\n",
    "\n",
    "    return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2a60cce9",
   "metadata": {},
   "source": [
    "## Responsivity to orientation or direction stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7ba67",
   "metadata": {},
   "source": [
    "resp_dir_fixed = hv_hist(agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'], 'responsivity_dir', 'fixed', xlabel='responsivity')\n",
    "resp_dir_free = hv_hist(agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'], 'responsivity_dir', 'free', xlabel='responsivity')\n",
    "overlay_resp_dir = resp_dir_free.opts(alpha=0.5) * resp_dir_fixed.opts(alpha=0.5) \n",
    "\n",
    "resp_ori_fixed = hv_hist(agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'], 'responsivity_ori', 'fixed', xlabel='responsivity')\n",
    "resp_ori_free = hv_hist(agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'], 'responsivity_ori', 'free', xlabel='responsivity')\n",
    "overlay_resp_ori = resp_ori_free.opts(alpha=0.5) * resp_ori_fixed.opts(alpha=0.5) \n",
    "\n",
    "responsivity_hists = overlay_resp_dir.opts(title='Resp. Dir.', width=500) + overlay_resp_ori.opts(title='Resp. Ori.', width=500)\n",
    "responsivity_hists"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "29bbec51",
   "metadata": {},
   "source": [
    "## Distributions of direction and orientation selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2dbc2",
   "metadata": {},
   "source": [
    "dsi_fixed = hv_hist(agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'], 'dsi_abs', 'fixed', xlabel='selectivity')\n",
    "dsi_free = hv_hist(agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'], 'dsi_abs', 'free', xlabel='selectivity')\n",
    "overlay_dsi = dsi_free.opts(alpha=0.5) * dsi_fixed.opts(alpha=0.5)\n",
    "\n",
    "osi_fixed = hv_hist(agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'], 'osi', 'fixed', xlabel='selectivity')\n",
    "osi_free = hv_hist(agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'], 'osi', 'free', xlabel='selectivity')\n",
    "overlay_osi = osi_free.opts(alpha=0.5) * osi_fixed.opts(alpha=0.5)\n",
    "\n",
    "selctivity_hists = overlay_dsi.opts(title='DSI', width=500) + overlay_osi.opts(title='OSI', width=500)\n",
    "selctivity_hists"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "861b2465",
   "metadata": {},
   "source": [
    "## Define cells as direction or orientation tuned\n",
    "This means that a cell must be responsive to direction or orientation (resp > 0.3) and have a DSI or OSI > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c0e9be",
   "metadata": {},
   "source": [
    "def get_vis_tuned_cells(ds, vis_stim='dir', resp_thresh=0.3, sel_tresh=0.5, drop_na=True):\n",
    "    data = ds.copy()\n",
    "\n",
    "    if vis_stim == 'dir':\n",
    "        resp_type = f'responsivity_{vis_stim}'\n",
    "        sel_type = 'dsi_abs'\n",
    "    elif vis_stim == 'ori':\n",
    "        resp_type = f'responsivity_{vis_stim}'\n",
    "        sel_type = 'osi'\n",
    "    elif (vis_stim == 'vis') or (vis_stim == 'untuned') :\n",
    "        resp_type = ['responsivity_dir', 'responsivity_ori']\n",
    "    else:\n",
    "        return Exception('Invalid vis_stim')\n",
    "    \n",
    "    if vis_stim == 'vis':\n",
    "        cells = data[(data[resp_type[0]].abs() >= resp_thresh) & (data[resp_type[1]].abs() >= resp_thresh)]\n",
    "    elif vis_stim == 'untuned':\n",
    "        cells = data[(data[resp_type[0]].abs() < resp_thresh) & (data[resp_type[1]].abs() < resp_thresh)]\n",
    "    else:\n",
    "        cells = data[(data[resp_type].abs() >= resp_thresh) & (data[sel_type].abs() >= sel_tresh)]\n",
    "    return cells"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a4f6f",
   "metadata": {},
   "source": [
    "# Create dataframes to store binary tuning information\n",
    "fixed_cell_tunings = agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'][['old_index', 'mouse', 'day']].copy()\n",
    "free_cell_tunings = agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'][['old_index', 'mouse', 'day']].copy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fdb5d",
   "metadata": {},
   "source": [
    "# Cells that meet direction selectivity criteria\n",
    "free_dir_tuned = get_vis_tuned_cells(agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'], vis_stim='dir', resp_thresh=0.5)\n",
    "free_ori_tuned = get_vis_tuned_cells(agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'], vis_stim='ori', resp_thresh=0.5)\n",
    "\n",
    "# Cells that meet orientation selectivity criteria\n",
    "fixed_dir_tuned = get_vis_tuned_cells(agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'], vis_stim='dir', resp_thresh=0.5)\n",
    "fixed_ori_tuned = get_vis_tuned_cells(agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'], vis_stim='ori', resp_thresh=0.5)\n",
    "\n",
    "# Cells that meet visual responsivity criteria\n",
    "free_vis_resp = get_vis_tuned_cells(agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'], vis_stim='vis', resp_thresh=0.5)\n",
    "fixed_vis_resp = get_vis_tuned_cells(agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'], vis_stim='vis', resp_thresh=0.5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f41619",
   "metadata": {},
   "source": [
    "# Find cells that are both direction and orientation tuned, and figure out what to do with them.\n",
    "intersect, comm1, comm2 = np.intersect1d(free_dir_tuned.index, free_ori_tuned.index, return_indices=True)\n",
    "free_both_tuned = free_dir_tuned.iloc[comm1].copy()\n",
    "\n",
    "# Remove cells tuned to both from each category\n",
    "free_dir_tuned = free_dir_tuned.drop(free_dir_tuned.index[comm1])\n",
    "free_ori_tuned = free_ori_tuned.drop(free_ori_tuned.index[comm2])\n",
    "\n",
    "intersect, comm1, comm2 = np.intersect1d(fixed_dir_tuned.index, fixed_ori_tuned.index, return_indices=True)\n",
    "fixed_both_tuned = fixed_dir_tuned.iloc[comm1].copy()\n",
    "fixed_dir_tuned = fixed_dir_tuned.drop(fixed_dir_tuned.index[comm1])\n",
    "fixed_ori_tuned = fixed_ori_tuned.drop(fixed_ori_tuned.index[comm2])\n",
    "\n",
    "# Double check cells that are visually reposnsive, make sure that all are contained in the vis_resp\n",
    "free_resp_cells = np.unique(np.concatenate([free_dir_tuned.index, free_ori_tuned.index, free_both_tuned.index]))\n",
    "not_in_free_resp_cells = np.setdiff1d(free_vis_resp.index, free_resp_cells, assume_unique=True)\n",
    "free_vis_resp = pd.concat([free_vis_resp, agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'].iloc[not_in_free_resp_cells, :]])\n",
    "free_vis_resp = free_vis_resp.reset_index().drop_duplicates(subset=['index'])\n",
    "\n",
    "fixed_resp_cells = np.unique(np.concatenate([fixed_dir_tuned.index, fixed_ori_tuned.index, fixed_both_tuned.index]))\n",
    "not_in_fixed_resp_cells = np.setdiff1d(fixed_vis_resp.index, fixed_resp_cells, assume_unique=True)\n",
    "fixed_vis_resp = pd.concat([fixed_vis_resp, agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'].iloc[not_in_fixed_resp_cells, :]])\n",
    "fixed_vis_resp = fixed_vis_resp.reset_index().drop_duplicates(subset=['index'])\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fcadf8",
   "metadata": {},
   "source": [
    "# Assign the tunings to the dataframes\n",
    "free_cell_tunings['is_vis_resp'] = free_cell_tunings.index.isin(free_vis_resp.index)\n",
    "free_cell_tunings['is_dir_tuned'] = free_cell_tunings.index.isin(free_dir_tuned.index)\n",
    "free_cell_tunings['is_ori_tuned'] = free_cell_tunings.index.isin(free_ori_tuned.index)\n",
    "fixed_cell_tunings['is_vis_resp'] = fixed_cell_tunings.index.isin(fixed_vis_resp.index)\n",
    "fixed_cell_tunings['is_dir_tuned'] = fixed_cell_tunings.index.isin(fixed_dir_tuned.index)\n",
    "fixed_cell_tunings['is_ori_tuned'] = fixed_cell_tunings.index.isin(fixed_ori_tuned.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165343b8",
   "metadata": {},
   "source": [
    "# Get fraction of cells that are orientation. direction, and visually tuned\n",
    "free_cell_per_day = free_cell_tunings.groupby(['mouse', 'day']).apply(lambda x: len(x))\n",
    "frac_free_dir_tuned = free_dir_tuned.groupby(['mouse', 'day']).apply(lambda x: len(x)) / free_cell_per_day\n",
    "frac_free_dir_tuned = frac_free_dir_tuned.reset_index().rename(columns={0: 'direction'})\n",
    "frac_free_ori_tuned = free_ori_tuned.groupby(['mouse', 'day']).apply(lambda x: len(x)) / free_cell_per_day\n",
    "frac_free_ori_tuned = frac_free_ori_tuned.reset_index().rename(columns={0: 'orientation'})\n",
    "frac_free_vis_resp = free_vis_resp.groupby(['mouse', 'day']).apply(lambda x: len(x)) / free_cell_per_day\n",
    "frac_free_vis_resp = frac_free_vis_resp.reset_index().rename(columns={0: 'visual'})\n",
    "frac_vis_resp_free = pd.concat([frac_free_dir_tuned, frac_free_ori_tuned, frac_free_vis_resp], axis=1).drop(['mouse', 'day'], axis=1)\n",
    "\n",
    "fixed_cell_per_day = fixed_cell_tunings.groupby(['mouse', 'day']).apply(lambda x: len(x))\n",
    "frac_fixed_dir_tuned = fixed_dir_tuned.groupby(['mouse', 'day']).apply(lambda x: len(x)) / fixed_cell_per_day\n",
    "frac_fixed_dir_tuned = frac_fixed_dir_tuned.reset_index().rename(columns={0: 'direction'})\n",
    "frac_fixed_ori_tuned = fixed_ori_tuned.groupby(['mouse', 'day']).apply(lambda x: len(x)) / fixed_cell_per_day\n",
    "frac_fixed_ori_tuned = frac_fixed_ori_tuned.reset_index().rename(columns={0: 'orientation'})\n",
    "frac_fixed_vis_resp = fixed_vis_resp.groupby(['mouse', 'day']).apply(lambda x: len(x)) / fixed_cell_per_day\n",
    "frac_fixed_vis_resp = frac_fixed_vis_resp.reset_index().rename(columns={0: 'visual'})\n",
    "frac_vis_resp_fixed = pd.concat([frac_fixed_dir_tuned, frac_fixed_ori_tuned, frac_fixed_vis_resp], axis=1).drop(['mouse', 'day'], axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70728f4",
   "metadata": {},
   "source": [
    "save_path = os.path.join(figure_save_path, f\"frac_vis_tuned_free.png\")\n",
    "violinplot_free_vis = violin_swarm(frac_vis_resp_free, save_path, cmap=fp.hv_blue_hex, font_size='poster', backend='seaborn', width=4.5, height=5, save=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b050b1",
   "metadata": {},
   "source": [
    "save_path = os.path.join(figure_save_path, f\"frac_vis_tuned_fixed.png\")\n",
    "violinplot_fixed_vis = violin_swarm(frac_vis_resp_fixed, save_path, cmap='red', font_size='poster', backend='seaborn', width=4.5, height=5, save=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fcb0a670",
   "metadata": {},
   "source": [
    "### Histograms of only dir or ori tuned cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131e5f9",
   "metadata": {},
   "source": [
    "# Visualize the non-overlapping cells\n",
    "dsi_free = hv_hist(free_dir_tuned, 'dsi_abs', 'free', xlabel='selectivity')\n",
    "dsi_fixed = hv_hist(fixed_dir_tuned, 'dsi_abs', 'fixed', xlabel='selectivity')\n",
    "overlay_dsi = dsi_fixed.opts(alpha=0.5) * dsi_free.opts(alpha=0.5)\n",
    "\n",
    "osi_free = hv_hist(free_ori_tuned, 'osi', 'free', xlabel='selectivity')\n",
    "osi_fixed = hv_hist(fixed_ori_tuned, 'osi', 'fixed', xlabel='selectivity')\n",
    "overlay_osi = osi_fixed.opts(alpha=0.5) * osi_free.opts(alpha=0.5)\n",
    "\n",
    "selctivity_hists = overlay_dsi.opts(title='DSI - dir selective', width=500) + overlay_osi.opts(title='OSI - ori selective', width=500)\n",
    "\n",
    "\n",
    "resp_dir_free = hv_hist(free_dir_tuned, 'responsivity_dir', 'free', xlabel='responsivity')\n",
    "resp_dir_fixed = hv_hist(fixed_dir_tuned, 'responsivity_dir', 'fixed', xlabel='responsivity')\n",
    "overlay_resp_dir = resp_dir_fixed.opts(alpha=0.5) * resp_dir_free.opts(alpha=0.5)\n",
    "\n",
    "resp_ori_free = hv_hist(free_ori_tuned, 'responsivity_ori', 'free', xlabel='responsivity')\n",
    "resp_ori_fixed = hv_hist(fixed_ori_tuned, 'responsivity_ori', 'fixed', xlabel='responsivity')\n",
    "overlay_resp_ori = resp_ori_fixed.opts(alpha=0.5) * resp_ori_free.opts(alpha=0.5)\n",
    "\n",
    "responsivity_hists = overlay_resp_dir.opts(title='Resp. Dir.', width=500) + overlay_resp_ori.opts(title='Resp. Ori.', width=500)\n",
    "\n",
    "both_hists = responsivity_hists + selctivity_hists\n",
    "both_hists.cols(2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9fc000e0",
   "metadata": {},
   "source": [
    "### Histograms of cells that are both ori and dir tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d1809",
   "metadata": {},
   "source": [
    "# Visualize the overlapping cells\n",
    "dsi_free = hv_hist(free_both_tuned, 'dsi_abs', 'free', xlabel='selectivity')\n",
    "dsi_fixed = hv_hist(fixed_both_tuned, 'dsi_abs', 'fixed', xlabel='selectivity')\n",
    "overlay_dsi = dsi_free.opts(alpha=0.5) * dsi_fixed.opts(alpha=0.5)\n",
    "\n",
    "osi_free = hv_hist(free_both_tuned, 'osi', 'free', xlabel='selectivity')\n",
    "osi_fixed = hv_hist(fixed_both_tuned, 'osi', 'fixed', xlabel='selectivity')\n",
    "overlay_osi = osi_free.opts(alpha=0.5) * osi_fixed.opts(alpha=0.5)\n",
    "\n",
    "selctivity_hists = overlay_dsi.opts(title='DSI - both selective', width=500) + overlay_osi.opts(title='OSI - both selective', width=500)\n",
    "\n",
    "resp_dir_free = hv_hist(free_both_tuned, 'responsivity_dir', 'free', xlabel='responsivity')\n",
    "resp_dir_fixed = hv_hist(fixed_both_tuned, 'responsivity_dir', 'fixed', xlabel='responsivity')\n",
    "overlay_resp_dir = resp_dir_free.opts(alpha=0.5) * resp_dir_fixed.opts(alpha=0.5)\n",
    "\n",
    "resp_ori_free = hv_hist(free_both_tuned, 'responsivity_ori', 'free', xlabel='responsivity')\n",
    "resp_ori_fixed = hv_hist(fixed_both_tuned, 'responsivity_ori', 'fixed', xlabel='responsivity')\n",
    "overlay_resp_ori = resp_ori_free.opts(alpha=0.5) * resp_ori_fixed.opts(alpha=0.5)\n",
    "\n",
    "responsivity_hists = overlay_resp_dir.opts(title='Resp. Dir.- both selective', width=500) + overlay_resp_ori.opts(title='Resp. Ori.- both selective', width=500)\n",
    "\n",
    "both_hists = responsivity_hists + selctivity_hists\n",
    "both_hists.cols(2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "81c0b951-d489-4e3a-946a-daeb63a68911",
   "metadata": {},
   "source": [
    "# Fraction self-motion responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca120e12",
   "metadata": {},
   "source": [
    "def kine_fraction_tuned(ds, use_test=True, include_responsivity=True, include_consistency=False):\n",
    "    if use_test:\n",
    "        resp = ds['Resp_test']\n",
    "        qual = ds['Qual_test']\n",
    "        cons = ds['Cons_test']\n",
    "\n",
    "    else:\n",
    "        resp = ds['Resp_index'] >= processing_parameters.tc_resp_qual_cutoff/100\n",
    "        qual = ds['Qual_index'] >= processing_parameters.tc_resp_qual_cutoff/100\n",
    "        cons = ds['Cons_index'] >= processing_parameters.tc_consistency_cutoff/100\n",
    "\n",
    "    # is tuned if quality is true\n",
    "    is_tuned = qual\n",
    "\n",
    "    if include_responsivity:\n",
    "        is_tuned = is_tuned + resp\n",
    "        is_tuned = is_tuned > 1\n",
    "\n",
    "    if include_consistency:\n",
    "        is_tuned = is_tuned + cons\n",
    "        is_tuned = is_tuned > 1\n",
    "\n",
    "    frac_is_tuned = is_tuned.sum() / is_tuned.count()\n",
    "    return frac_is_tuned\n",
    "\n",
    "def get_sig_tuned_kinem_cells(agg_dict, exp_kind, which_cells, vars, use_test=True, include_responsivity=True, include_consistency=False):\n",
    "    keys = ['_'.join([exp_kind, which_cells, var]) for var in vars]\n",
    "    df = pd.DataFrame(columns=vars)\n",
    "\n",
    "    for key, var in zip(keys, vars):\n",
    "        if key in agg_dict.keys():\n",
    "            df[var] = agg_dict[key].groupby(['mouse', 'day']).apply(kine_fraction_tuned, use_test, include_responsivity, include_consistency)\n",
    "\n",
    "    return df\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35406e",
   "metadata": {},
   "source": [
    "# get the head fixed tunings\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256fd25",
   "metadata": {},
   "source": [
    "agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7998b36-83d3-44a3-a58c-f442700daacb",
   "metadata": {},
   "source": [
    "save_path = os.path.join(figure_save_path, \"sig_frac_kinem_free.png\")\n",
    "\n",
    "# Within-animal fraction kinematic\n",
    "frac_kine_resp_free = get_sig_tuned_kinem_cells(agg_dict, 'VTuningWF', cell_kind, processing_parameters.variable_list_free, use_test=True, include_responsivity=True, include_consistency=False)\n",
    "violinplot_free_kinem = fp.violin_swarm(frac_kine_resp_free, save_path, cmap=fp.hv_blue_hex, backend='seaborn', width=15, height=5, save=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e934bd-15ac-4b03-a44d-ee7ddd3061dc",
   "metadata": {},
   "source": [
    "# Within-animal fraction kinematic\n",
    "save_path = os.path.join(figure_save_path, \"sig_frac_kinem_fixed.png\")\n",
    "\n",
    "frac_kine_resp_fixed = get_sig_tuned_kinem_cells(agg_dict, 'VWheelWF', cell_kind, processing_parameters.variable_list_fixed, use_test=True, include_responsivity=True, include_consistency=False)\n",
    "violinplot_free_kinem = fp.violin_swarm(frac_kine_resp_fixed, save_path, cmap='red', backend='seaborn', width=3, height=5, save=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c236fbfa",
   "metadata": {},
   "source": [
    "# Fraction Visual, Self-Motion, or Multimodal Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db032f7f-5013-4341-923b-e47ba7a025fb",
   "metadata": {},
   "source": [
    "def get_frac_tuned(df):\n",
    "    kinem_cols = list(df.columns[1:-5])\n",
    "    vis_cols = list(df.columns[-5:-3])\n",
    "    \n",
    "    df['sum_kinem'] = df[kinem_cols].sum(axis=1)\n",
    "    df['sum_vis'] = df[vis_cols].sum(axis=1)\n",
    "    df['sum_mix'] = df[['sum_kinem', 'sum_vis']].sum(axis=1)\n",
    "   \n",
    "    frac_vis_tuned = df['sum_vis'].loc[df['sum_vis'] > 0].count() / df.shape[0]\n",
    "    frac_kinem_tuned = df['sum_kinem'].loc[df['sum_kinem'] > 0].count() / df.shape[0]\n",
    "\n",
    "    frac_only_kinem = df[(df[vis_cols].sum(axis=1) == 0) & (df[kinem_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "    frac_only_vis = df[(df[kinem_cols].sum(axis=1) == 0) & (df[vis_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "    frac_mix_tuned = df[(df[vis_cols].sum(axis=1) > 0) & (df[kinem_cols].sum(axis=1) > 0)].shape[0] / df.shape[0]\n",
    "\n",
    "    return frac_only_kinem, frac_only_vis, frac_vis_tuned, frac_kinem_tuned, frac_mix_tuned"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edf58b-cf4e-410b-b28a-87ad0692987b",
   "metadata": {},
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "for ds, exp_type in zip([agg_dict['VTuningWF_multimodal_tuned'], agg_dict['VWheelWF_multimodal_tuned']], ['Freely Moving', 'Head Fixed']):\n",
    "    only_kinem = []\n",
    "    only_vis = []\n",
    "    vis_tuned = []\n",
    "    kinem_tuned = []\n",
    "    mix_tuned = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in ds.groupby('mouse'):\n",
    "        frac_only_kinem, frac_only_vis, frac_vis_tuned, frac_kinem_tuned, frac_mix_tuned = get_frac_tuned(group)\n",
    "        only_kinem.append(frac_only_kinem)\n",
    "        only_vis.append(frac_only_vis)\n",
    "        vis_tuned.append(frac_vis_tuned)\n",
    "        kinem_tuned.append(frac_kinem_tuned)\n",
    "        mix_tuned.append(frac_mix_tuned)\n",
    "\n",
    "    df['group'] = [exp_type] * len(vis_tuned)\n",
    "    df[' Visual Only'] = only_vis\n",
    "    df[' Postural Only'] = only_kinem\n",
    "    df[' Visual'] = vis_tuned\n",
    "    df[' Postural'] = kinem_tuned\n",
    "    df['Multimodal'] = mix_tuned\n",
    "    df_list.append(df)\n",
    "    plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "comp_tuning = pd.concat(df_list, axis=0)\n",
    "comp_tuning = pd.melt(comp_tuning, id_vars=['group'], value_vars=[' Visual Only', ' Postural Only', ' Visual', ' Postural', 'Multimodal'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ff456-4a20-4af4-b332-33263ad9a116",
   "metadata": {},
   "source": [
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "comp_tuning_rank_sum = comp_tuning.groupby(['variable', 'group'], group_keys=True).value.agg(list).unstack(level=1)\n",
    "comp_tuning_stats = comp_tuning_rank_sum.apply(lambda x: st.mannwhitneyu(x['Freely Moving'], x['Head Fixed'], alternative='two-sided'), axis=1)\n",
    "p_vals = [comp_tuning_stats.to_numpy()[i][1] for i in np.arange(comp_tuning_stats.shape[0])]\n",
    "multipletests(p_vals, alpha=0.05, method='bonferroni')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e093530-12dc-4ebb-8f20-1ae6d769d835",
   "metadata": {},
   "source": [
    "violinplot = hv.Violin(comp_tuning, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=400,\n",
    "                                                                  # ylim=(-0.05, 1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  cmap=['red', fp.hv_blue_hex],\n",
    "                                                                  show_legend=False, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"frac_multimodal.png\")\n",
    "# violinplot\n",
    "violinplot = fp.save_figure(violinplot, save_path=save_path, fig_width=25, dpi=800, fontsize='screen', target='both', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b1ed5-be24-463c-ba6b-1976d72b8504",
   "metadata": {},
   "source": [
    "ax = sns_scatter_swarm(comp_tuning, \"variable\", \"value\", \"group\")\n",
    "ax.set_ylabel('Significant Frac.')\n",
    "plt.savefig(os.path.join(figure_save_path, 'frac_multimodal_alt.png'), dpi=800, format='png')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "510b7ae6-7f3d-402c-ae7d-8c2f64afa5aa",
   "metadata": {},
   "source": [
    "# Bootstrapped tuning shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d035992-f770-4f78-9fa4-d44ff27f9574",
   "metadata": {},
   "source": [
    "def plot_compare_matched_vis_tuning(ds_list, cell, tuning_kind='direction', exp_name='', error='std', norm=True, polar=True, axes=None):\n",
    "    if axes is None:\n",
    "        axes = []\n",
    "        fig = plt.figure(layout='constrained', figsize=(18*cm, 2*len(data_list)*cm))\n",
    "        fig.suptitle(f\"Cell {cell}\", fontsize='x-large')\n",
    "        subfigs = fig.subfigures(nrows=len(ds_list), ncols=1, hspace=0.07)\n",
    "    \n",
    "        for i, subfig in enumerate(subfigs):\n",
    "            subfig.suptitle(processing_parameters.wf_label_dictionary[exp_name[i]].title())\n",
    "            \n",
    "            if polar:\n",
    "                ax1 = subfig.add_subplot(121, projection=\"polar\") # direction tuning\n",
    "            else:\n",
    "                ax1 = subfig.add_subplot(121) # tuning\n",
    "                \n",
    "            ax2 = subfig.add_subplot(222) #  resp\n",
    "            ax3 = subfig.add_subplot(224) #  error\n",
    "            ax = np.array([ax1, ax2, ax3])\n",
    "            axes.append(ax)\n",
    "\n",
    "    for sub_ax, ds in zip(axes, ds_list):\n",
    "        sub_ax = fp.plot_tuning_with_stats(ds, cell, tuning_kind=tuning_kind, error=error, norm=norm, polar=polar, axes=sub_ax)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "def plot_compare_all_vis_tuning(ds_list, cell, tuning_kind=['direction', 'orientation'], exp_name='', error='std', norm=True, polar=True, axes=None):\n",
    "    if axes is None:\n",
    "        axes = []\n",
    "        fig = plt.figure(layout='constrained', figsize=(36*cm, 2*len(data_list)*cm))\n",
    "        fig.suptitle(f\"Cell {cell}\", fontsize='x-large')\n",
    "        subfigs = fig.subfigures(nrows=2, ncols=2, hspace=0.07)\n",
    "    \n",
    "        for i, subfig in enumerate(subfigs.flatten()):\n",
    "            subfig.suptitle(processing_parameters.wf_label_dictionary[exp_name[i//2]].title())\n",
    "            \n",
    "            if polar:\n",
    "                ax1 = subfig.add_subplot(121, projection=\"polar\") # tuning\n",
    "            else:\n",
    "                ax1 = subfig.add_subplot(121) # tuning\n",
    "                \n",
    "            ax2 = subfig.add_subplot(222) #  resp\n",
    "            ax3 = subfig.add_subplot(224) #  error\n",
    "            ax = np.array([ax1, ax2, ax3])\n",
    "            axes.append(ax)\n",
    "\n",
    "    tuning_kind = ['direction', 'orientation'] * 2\n",
    "    for i, (ds, sub_ax) in enumerate(zip(ds_list, axes)):\n",
    "        sub_ax = fp.plot_tuning_with_stats(ds, cell, tuning_kind=tuning_kind[i], error=error, norm=norm, polar=polar, axes=sub_ax)\n",
    "\n",
    "    return fig, axes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489028f4-5efe-40c5-a633-ec70d1908137",
   "metadata": {},
   "source": [
    "def find_tuned_cell_indices(ref_data, comp_data, stim_kind='orientation', cutoff=0.5, tuning_criteria='both',):\n",
    "\n",
    "    # Find the cells in the reference dataset that are tuned\n",
    "    if stim_kind == 'orientation':\n",
    "        index_ref = ref_data.loc[ref_data.osi.abs() >= cutoff].index.to_numpy()\n",
    "        index_comp = comp_data.loc[comp_data.osi.abs() >= cutoff].index.to_numpy()\n",
    "    elif stim_kind == 'direction':\n",
    "        index_ref = ref_data.loc[ref_data.dsi_abs.abs() >= cutoff].index.to_numpy()\n",
    "        index_comp = comp_data.loc[comp_data.dsi_abs.abs() >= cutoff].index.to_numpy()\n",
    "    else:\n",
    "        return Exception('Invalid stim_kind')\n",
    "\n",
    "    if tuning_criteria == 'both':\n",
    "        indices = np.intersect1d(index_ref, index_comp)\n",
    "    elif tuning_criteria == 'ref':\n",
    "        indices = index_ref\n",
    "    elif tuning_criteria == 'comp':\n",
    "        indices = index_comp\n",
    "    else:\n",
    "        return Exception('Invalid tuning_criteria')\n",
    "\n",
    "    return indices\n",
    "\n",
    "def tuning_shifts(ds1, ds2, ci_width_cutoff=20, stim_kind='orientation', method='fit'):\n",
    "    shifts = []\n",
    "\n",
    "    stim_kind = stim_kind[:3]\n",
    "    if stim_kind == 'ori':\n",
    "        multiplier = 2\n",
    "    else:\n",
    "        multiplier = 1\n",
    "\n",
    "    if method == 'fit':\n",
    "        dist_key = f'bootstrap_pref_{stim_kind}'\n",
    "        pref_key = f'pref_{stim_kind}'\n",
    "    elif method == 'resultant':\n",
    "        dist_key = f'bootstrap_resultant_{stim_kind}'\n",
    "        pref_key = f'resultant_{stim_kind}'\n",
    "    else:\n",
    "        return Exception('Invalid method')\n",
    "\n",
    "    for (idxRow, cell_1), (_, cell_2) in zip(ds1.iterrows(), ds2.iterrows()):\n",
    "\n",
    "        # Get preferred angle\n",
    "        pref_1 = cell_1[pref_key]\n",
    "        pref_2 = cell_2[pref_key]\n",
    "\n",
    "        # Get bootstrap distributions\n",
    "        pref_dist_1 = cell_1[dist_key]\n",
    "        pref_dist_2 = cell_2[dist_key]\n",
    "\n",
    "        if method == 'resultant':\n",
    "            pref_1 = pref_1[-1]\n",
    "            pref_2 = pref_2[-1]\n",
    "            pref_dist_1 = pref_dist_1[:, -1]\n",
    "            pref_dist_2 = pref_dist_2[:, -1]\n",
    "\n",
    "            if np.isnan(pref_1) or np.isnan(pref_2):\n",
    "                pass\n",
    "\n",
    "        pref_dist_1 = pref_dist_1[~np.isnan(pref_dist_1)]\n",
    "        pref_dist_2 = pref_dist_2[~np.isnan(pref_dist_2)]\n",
    "\n",
    "        if pref_dist_1.size == 0 or pref_dist_2.size == 0:\n",
    "            pass\n",
    "\n",
    "        # Wrap angles\n",
    "        pref_dist_1 = fk.wrap(pref_dist_1, 360/multiplier + 0.1)\n",
    "        pref_dist_2 = fk.wrap(pref_dist_2, 360/multiplier + 0.1)\n",
    "        delta_pref = np.abs(pref_2 - pref_1)\n",
    "\n",
    "        # Calculate confidence intervals\n",
    "        ci_1 = st.norm.interval(confidence=0.95, loc=np.nanmean(pref_dist_1), scale=st.sem(pref_dist_1, nan_policy='omit')) \n",
    "        ci_2 = st.norm.interval(confidence=0.95, loc=np.nanmean(pref_dist_2), scale=st.sem(pref_dist_2, nan_policy='omit')) \n",
    "\n",
    "        # Get CI widths\n",
    "        ci_width_1 = np.abs(ci_1[-1] - ci_1[0])      \n",
    "        ci_width_2 = np.abs(ci_2[-1] - ci_2[0])\n",
    "\n",
    "        # Check if tuned or not\n",
    "        if (ci_width_1 <= ci_width_cutoff) and (ci_width_2 <= ci_width_cutoff):\n",
    "            \n",
    "            # determine significance of shift\n",
    "            if ~(ci_1[0] <= pref_2 <= ci_1[-1]) and ~(ci_2[0] <= pref_1 <= ci_2[-1]):\n",
    "                # Shift is significant\n",
    "                sig_shift = 1\n",
    "            else:\n",
    "                # Shift is not significant    \n",
    "                sig_shift = 0\n",
    "        else:\n",
    "            # The cell is not tuned\n",
    "            sig_shift = 0\n",
    "\n",
    "        # wrap to negative domain for plotting\n",
    "        pref_1 = fk.wrap_negative(pref_1, bound=360/(2*multiplier) + 0.1)\n",
    "        pref_2 = fk.wrap_negative(pref_2, bound=360/(2*multiplier) + 0.1)\n",
    "\n",
    "        shifts.append([idxRow, pref_1, ci_width_1, pref_2, ci_width_2, delta_pref, sig_shift, cell_1.mouse, cell_1.day])\n",
    "    \n",
    "    shifts = pd.DataFrame(data=shifts, columns=['', 'pref_1', 'ci_width_1', 'pref_2', 'ci_width_2', 'delta_pref', 'is_sig', 'mouse', 'date'])\n",
    "    shifts = shifts.set_index(shifts.columns[0])\n",
    "\n",
    "    return shifts"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f2297",
   "metadata": {},
   "source": [
    "curated_matches"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1e792",
   "metadata": {},
   "source": [
    "curated_matches[['day', 'mouse']].drop_duplicates().to_numpy()\n",
    "fixed_matches = agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}']\n",
    "free_matches = agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}']\n",
    "\n",
    "curated_ref_df_list = []\n",
    "curated_comp_df_list = []\n",
    "for day, mouse in curated_matches[['day', 'mouse']].drop_duplicates().to_numpy():\n",
    "    curated_idxs = curated_matches.loc[(curated_matches.mouse == mouse) & (curated_matches.day == day)]['index'].to_numpy()\n",
    "\n",
    "    ref_df = fixed_matches.loc[(fixed_matches.mouse == mouse) & (fixed_matches.day == day)]\n",
    "    comp_df = free_matches.loc[(free_matches.mouse == mouse) & (free_matches.day == day)]\n",
    "\n",
    "    curated_ref_df = ref_df.loc[ref_df.old_index.isin(curated_idxs)]\n",
    "    curated_comp_df = comp_df.loc[comp_df.old_index.isin(curated_idxs)]\n",
    "\n",
    "    curated_ref_df_list.append(curated_ref_df.copy())\n",
    "    curated_comp_df_list.append(curated_comp_df.copy())\n",
    "\n",
    "curated_ref_df = pd.concat(curated_ref_df_list).reset_index(drop=True)\n",
    "curated_comp_df = pd.concat(curated_comp_df_list).reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3964bd-2600-41a4-b4b7-28669678fb4c",
   "metadata": {},
   "source": [
    "cell_kind = 'matched'\n",
    "activity_dataset = 'norm_spikes_viewed_props'\n",
    "\n",
    "ref_ds = curated_ref_df#agg_dict[f'{session_types[0]}_{cell_kind}_{activity_dataset}'].copy()\n",
    "ref_ds_ori = ref_ds.drop(ref_ds[ref_ds.osi.isna()].index).copy()\n",
    "ref_ds_dir = ref_ds.drop(ref_ds[ref_ds.dsi_abs.isna()].index).copy()\n",
    "\n",
    "comp_ds = curated_comp_df#agg_dict[f'{session_types[1]}_{cell_kind}_{activity_dataset}'].copy()\n",
    "comp_ds_ori = comp_ds.drop(comp_ds[comp_ds.osi.isna()].index).copy()\n",
    "comp_ds_dir = comp_ds.drop(comp_ds[comp_ds.dsi_abs.isna()].index).copy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac7fff",
   "metadata": {},
   "source": [
    "ori_cutoff_high = 0.5\n",
    "dir_cutoff_high = 0.5\n",
    "lower_cutoff = 0.3\n",
    "\n",
    "ori_indices = find_tuned_cell_indices(ref_ds.copy(), comp_ds.copy(), cutoff=ori_cutoff_high, stim_kind='orientation', tuning_criteria='both')\n",
    "dir_indices = find_tuned_cell_indices(ref_ds.copy(), comp_ds.copy(), cutoff=dir_cutoff_high, stim_kind='direction', tuning_criteria='both')\n",
    "\n",
    "po_shifts = tuning_shifts(ref_ds.iloc[ori_indices, :].copy(), comp_ds.iloc[ori_indices, :].copy(),\n",
    "                          ci_width_cutoff=45, stim_kind='orientation', method='resultant')\n",
    "\n",
    "pd_shifts = tuning_shifts(ref_ds.iloc[dir_indices, :].copy(), comp_ds.iloc[dir_indices, :].copy(),\n",
    "                          ci_width_cutoff=90, stim_kind='direction', method='resultant')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89da21",
   "metadata": {},
   "source": [
    "residual_ori = po_shifts['pref_2'].to_numpy() - po_shifts['pref_1'].to_numpy()\n",
    "rmse_residual_ori = np.mean(np.sqrt(residual_ori**2))\n",
    "print(po_shifts.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f783c04",
   "metadata": {},
   "source": [
    "unity_line = hv.Curve((np.arange(-90, 90, 1), np.arange(-90, 90, 1))).opts(color='black')\n",
    "scatter_ori = hv.Scatter(po_shifts[['pref_1', 'pref_2']], kdims=['pref_1'], vdims=['pref_2'], label='sig').opts(color='purple', size=8)\n",
    "scatter_PO = unity_line * scatter_ori * hv.Text(-60, 80, f'RMSE: {rmse_residual_ori:.1f}°').opts(color='black', fontsize=15)\n",
    "scatter_PO.opts(show_legend=False, width=500, height=500,\n",
    "                xlabel=f'{processing_parameters.wf_label_dictionary_wo_units[session_types[0]]} Pref. Ori. [°]', \n",
    "                ylabel=f'{processing_parameters.wf_label_dictionary_wo_units[session_types[1]]} Pref. Ori. [°]')\n",
    "scatter_PO.opts(hv.opts.Scatter(xlim=(-90, 90), ylim=(-90, 90), xticks=[-45, 0, 45, 90], yticks=[-90, -45, 0, 45, 90]))\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"delta_PO_{parsed_search['result']}_{parsed_search['rig']}.png\")\n",
    "scatter_PO = fp.save_figure(scatter_PO, save_path=save_path, fig_width=13, dpi=800, fontsize='poster', target='screen', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec05bcf",
   "metadata": {},
   "source": [
    "scatter_sig_ori = hv.Scatter(po_shifts[po_shifts.is_sig == 1][['pref_1', 'pref_2']], kdims=['pref_1'], vdims=['pref_2'], label='sig').opts(color='red', size=5)\n",
    "\n",
    "scater_insig_ori = hv.Scatter(po_shifts[po_shifts.is_sig == 0][['pref_1', 'pref_2']], kdims=['pref_1'], vdims=['pref_2'], label='inisg').opts(alpha=0.5, color='gray', size=5)\n",
    "\n",
    "unity_line = hv.Curve((np.arange(-90, 90, 1), np.arange(-90, 90, 1))).opts(color='black')\n",
    "scatter_PO = unity_line * scater_insig_ori * scatter_sig_ori\n",
    "scatter_PO.opts(show_legend=False, xlabel=f'{session_types[0].title()} Pref. Ori. [°]', ylabel=f'{session_types[1].title()} Pref. Ori. [°]', width=500, height=500)\n",
    "scatter_PO.opts(hv.opts.Scatter(xlim=(-90, 90), ylim=(-90, 90), xticks=[-45, 0, 45, 90], yticks=[-90, -45, 0, 45, 90]))\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"delta_PO_{parsed_search['result']}_{parsed_search['rig']}.png\")\n",
    "scatter_PO = fp.save_figure(scatter_PO, save_path=save_path, fig_width=14, dpi=800, fontsize='screen', target='screen', display_factor=0.1)\n",
    "\n",
    "# scatter_sig_dir = hv.Scatter(pd_shifts[pd_shifts.is_sig == 1][['pref_1', 'pref_2']], kdims=['pref_1'], vdims=['pref_2'], label='sig').opts(color='red', size=5)\n",
    "\n",
    "# scater_insig_dir = hv.Scatter(pd_shifts[pd_shifts.is_sig == 0][['pref_1', 'pref_2']], kdims=['pref_1'], vdims=['pref_2'], label='inisg').opts(alpha=0.5, color='gray', size=5)\n",
    "\n",
    "# a = np.arange(-180, 180, 1)\n",
    "# unity_line = hv.Curve((a, a)).opts(color='black')\n",
    "# scatter_PD = unity_line * scater_insig_dir * scatter_sig_dir\n",
    "# scatter_PD.opts(show_legend=False, xlabel=f'{session_types[0].title()} Pref. Dir. [°]', ylabel=f'{session_types[1].title()} Pref. Dir. [°]', width=500, height=500)\n",
    "# scatter_PD.opts(hv.opts.Scatter(xlim=(-180, 180), ylim=(-180, 180), xticks=[-135, -90, -45, 0, 45, 90, 135, 180], yticks=[-180, -135, -90, -45, 0, 45, 90, 135, 180]))\n",
    "\n",
    "# save_path = os.path.join(figure_save_path, f\"delta_PD_{parsed_search['result']}_{parsed_search['rig']}.png\")\n",
    "# scatter_PD = fp.save_figure(scatter_PD, save_path=save_path, fig_width=14, dpi=800, fontsize='screen', target='save', display_factor=0.1)\n",
    "\n",
    "# hv.Layout([scatter_PO, scatter_PD]).opts(shared_axes=False).cols(2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc27c3-8ec4-4ceb-9efd-aad2cd3839ec",
   "metadata": {},
   "source": [
    "tuning_shifts.groupby('mouse').apply(lambda x: x.is_sig_po.count())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee8a1a-ab41-47d3-80a3-b4909bd83dab",
   "metadata": {},
   "source": [
    "bins = np.arange(0, 1.01, 0.05)\n",
    "plt.hist([agg_dict[datasets[0]].responsivity_dir, agg_dict[datasets[1]].responsivity_dir], bins=bins, color=[fp.hv_blue_hex, fp.hv_red_hex], edgecolor=\"black\")\n",
    "plt.legend(['fixed', 'free'])\n",
    "plt.axvline(0.25, c='r')\n",
    "plt.title('responsivity - direction')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14eee26",
   "metadata": {},
   "source": [
    "bins = np.arange(0, 1.01, 0.05)\n",
    "plt.hist([agg_dict[datasets[0]].responsivity_ori, agg_dict[datasets[1]].responsivity_ori], bins=bins, color=[fp.hv_blue_hex, fp.hv_red_hex], edgecolor=\"black\")\n",
    "plt.legend(['fixed', 'free'])\n",
    "plt.axvline(0.25, c='r')\n",
    "plt.title('responsivity - orientation')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cbfba-93f2-4c0f-8d93-aebf8cb50cc8",
   "metadata": {},
   "source": [
    "overall_sig_po_shift_frac = tuning_shifts.is_sig_po.sum() / tuning_shifts.is_sig_po.count() \n",
    "print(overall_sig_po_shift_frac)\n",
    "tuning_shifts.groupby('mouse').apply(lambda x: x.is_sig_po.sum() / x.is_sig_po.count())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc698f-8b0d-41ad-aba1-edc180603cf2",
   "metadata": {},
   "source": [
    "frequencies, edges = np.histogram(tuning_shifts[tuning_shifts.is_sig_po == 1].delta_po.to_numpy(), 36)\n",
    "hv.Histogram((edges, frequencies)).opts(width=600)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096c76b-966e-4192-8d2d-764da3db9caf",
   "metadata": {},
   "source": [
    "x = tuning_shifts[tuning_shifts.is_sig_po == 1].groupby('mouse').apply(lambda x: np.histogram(x.delta_po.to_numpy(), 36)).to_list()\n",
    "layout = hv.Layout([hv.Histogram((edges, frequencies)).opts(width=400) for frequencies, edges in x]).opts(shared_axes=False)\n",
    "layout"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b94bba-8eff-48d1-a7fa-76aa5516c13d",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "datasets = ['VWheelWF_matched_norm_spikes_viewed_still_direction_props', 'VWheelWF_matched_norm_spikes_viewed_still_orientation_props',\n",
    "            'VTuningWF_matched_norm_spikes_viewed_still_direction_props', 'VTuningWF_matched_norm_spikes_viewed_still_orientation_props']\n",
    "\n",
    "matched_vis_fig = interactive(plot_compare_all_vis_tuning,\n",
    "                              ds_list=widgets.fixed([agg_dict[dataset] for dataset in datasets]),\n",
    "                              cell=tuning_shifts[tuning_shifts.is_sig_po == 1].index, \n",
    "                              tuning_kind = widgets.fixed(['direction', 'orientation']),\n",
    "                              exp_name = widgets.fixed(['VWheelWF', 'VTuningWF']),\n",
    "                              error = ['std', 'sem'],\n",
    "                              polar=[True, False],\n",
    "                              norm=widgets.fixed(True),\n",
    "                              axes=widgets.fixed(None))\n",
    "matched_vis_fig"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5922ef-9e52-46ec-b493-ca1680323fb7",
   "metadata": {},
   "source": [
    "tuning_shifts.loc[67]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f230a-1505-44dc-a05f-cd9e77c32bbd",
   "metadata": {},
   "source": [
    "import pycircstat as circ"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5b454027-799a-4862-9418-6900db91f78f",
   "metadata": {},
   "source": [
    "# DSI/OSI Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568b3e4-e7d3-4b17-836a-a482c562680a",
   "metadata": {},
   "source": [
    "free_matched = ['VTuningWF_matched_norm_spikes_viewed_props',\n",
    "                'VTuningWF_matched_norm_spikes_viewed_still_props']\n",
    "fixed_matched = ['VWheelWF_matched_norm_spikes_viewed_props',\n",
    "                 'VWheelWF_matched_norm_spikes_viewed_still_props']\n",
    "matched_free_dir = free_matched[0:1]\n",
    "matched_fixed_dir = fixed_matched[0:1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f078b7-1bbf-4b87-8af7-f0d991af7873",
   "metadata": {},
   "source": [
    "ds_list_matched_free = [agg_dict[d] for d in matched_free_dir]\n",
    "ds_list_matched_fixed = [agg_dict[d] for d in matched_fixed_dir]\n",
    "cols = ['osi', 'dsi_abs']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "594a1f09-2bca-4170-8b72-eb776cb58a7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Matched Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa9f51-b48f-4f00-9767-b59b2d2b6d10",
   "metadata": {},
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "for ds, exp_type in zip([agg_dict['VTuningWF_matched_norm_spikes_viewed_props'], agg_dict['VWheelWF_matched_norm_spikes_viewed_props']], ['Freely Moving', 'Head Fixed']):\n",
    "    frac_ori_tuned = []\n",
    "    frac_dir_tuned = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in ds.groupby('mouse'):\n",
    "        ori_tuned = np.abs(group.osi) > 0.5\n",
    "        dir_tuned = np.abs(group.dsi_abs) > 0.5\n",
    "\n",
    "        # ori_tuned = (np.abs(group.osi) > 0.25) & (np.abs(group.dsi_nasal_temporal) <= 0.25)\n",
    "        # dir_tuned = (np.abs(group.osi) <= 0.25) & (np.abs(group.dsi_nasal_temporal) > 0.25)\n",
    "        frac_ori_tuned.append(ori_tuned.sum() / ori_tuned.count())\n",
    "        frac_dir_tuned.append(dir_tuned.sum() / dir_tuned.count())\n",
    "\n",
    "\n",
    "    df['group'] = [exp_type] * len(frac_ori_tuned)\n",
    "    df['Ori. Tuned'] = frac_ori_tuned\n",
    "    df['Dir. Tuned'] = frac_dir_tuned\n",
    "    df_list.append(df)\n",
    "    plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "matched_dsi_osi = pd.concat(df_list, axis=0)\n",
    "matched_dsi_osi= pd.melt(matched_dsi_osi, id_vars=['group'], value_vars=['Ori. Tuned', 'Dir. Tuned'])\n",
    "\n",
    "violinplot_matched_dsi_osi = hv.Violin(matched_dsi_osi, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=600,\n",
    "                                                                  ylim=(0, 1.1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  cmap=[fp.hv_blue_hex, fp.hv_orange_hex],\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"matched_frac_ori_dir_tuned.png\")\n",
    "# violinplot\n",
    "violinplot_matched_dsi_osi = fp.save_figure(violinplot_matched_dsi_osi, save_path=save_path, fig_width=16, dpi=800, fontsize='screen', target='both', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f3b54",
   "metadata": {},
   "source": [
    "ax = sns_scatter_swarm(matched_dsi_osi, \"variable\", \"value\", \"group\")\n",
    "ax.set_ylabel('Significant Frac.')\n",
    "save_path = os.path.join(figure_save_path, \"matched_frac_ori_dir_tuned.png\")\n",
    "plt.savefig(save_path, dpi=800, format='png')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6236ba-3871-4cd6-a889-3b8204936f6d",
   "metadata": {},
   "source": [
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "comp_tuning_rank_sum = matched_dsi_osi.groupby(['variable', 'group'], group_keys=True).value.agg(list).unstack(level=1)\n",
    "comp_tuning_stats = comp_tuning_rank_sum.apply(lambda x: st.mannwhitneyu(x['Freely Moving'], x['Head Fixed'], alternative='two-sided'), axis=1)\n",
    "p_vals = [comp_tuning_stats.to_numpy()[i][1] for i in np.arange(comp_tuning_stats.shape[0])]\n",
    "print(comp_tuning_stats)\n",
    "multipletests(p_vals, alpha=0.05, method='bonferroni')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07627043-2d22-4886-97e5-7e10a3162e1a",
   "metadata": {},
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "\n",
    "for ds, exp_type in zip([agg_dict['VTuningWF_matched_norm_spikes_viewed_props'], agg_dict['VWheelWF_matched_norm_spikes_viewed_props']], ['Freely Moving', 'Head Fixed']):\n",
    "    df = pd.DataFrame()\n",
    "    df['OSI'] = ds.osi.abs().to_numpy()\n",
    "    df['DSI'] = ds.dsi_abs.abs().to_numpy()\n",
    "    df['group'] = [exp_type] * len(ds.osi)\n",
    "    df_list.append(df)\n",
    "    \n",
    "    # plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "matched_selectivity = pd.concat(df_list, axis=0)\n",
    "matched_selectivity = pd.melt(matched_selectivity, id_vars=['group'], value_vars=['OSI', 'DSI'])\n",
    "\n",
    "violinplot_selectivity_matched = hv.Violin(matched_selectivity, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Selectivity', \n",
    "                                                                  width=1000, height=600,\n",
    "                                                                  ylim=(-0.1, 1.1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  cmap=[fp.hv_blue_hex, fp.hv_orange_hex],\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"matched_selectivity.png\")\n",
    "violinplot_selectivity_matched = fp.save_figure(violinplot_selectivity_matched, save_path=save_path, fig_width=16, dpi=800, fontsize='screen', target='both', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b903483",
   "metadata": {},
   "source": [
    "ax = sns_scatter_swarm(matched_selectivity.dropna(), \"variable\", \"value\", \"group\")\n",
    "ax.set_ylabel('Significant Frac.')\n",
    "save_path = os.path.join(figure_save_path, \"matched_selectivity.png\")\n",
    "plt.savefig(save_path, dpi=800, format='png')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e73588-f43c-4770-968b-65bcba4c9676",
   "metadata": {},
   "source": [
    "def replace_inf(x):\n",
    "    x[x > np.percentile(x, 99)] = np.percentile(x, 99)\n",
    "    return x\n",
    "\n",
    "a = matched_selectivity[matched_selectivity.variable == 'OSI'].fillna(0).drop(columns='variable')\n",
    "a = a.groupby('group').agg(list).T.reset_index(drop=True)\n",
    "\n",
    "\n",
    "frequencies_free_osi, edges_free_osi = np.histogram(np.clip(a['Freely Moving'][0], 0, 1)\t, 20)\n",
    "frequencies_fixed_osi, edges_fixed_osi = np.histogram(np.clip(a['Head Fixed'][0], 0, 1), 20)\n",
    "\n",
    "cell_match_hist_osi = hv.Overlay([hv.Histogram((frequencies_free_osi, edges_free_osi), label='Freely Moving').opts(alpha=0.5, fill_color=fp.hv_blue_rgb), \n",
    "                                  hv.Histogram((frequencies_fixed_osi, edges_fixed_osi), label='Head Fixed').opts(alpha=0.5, fill_color=fp.hv_orange_rgb)])\n",
    "\n",
    "b = matched_selectivity[matched_selectivity.variable == 'DSI'].fillna(0).drop(columns='variable')\n",
    "b = b.groupby('group').agg(list).T.reset_index(drop=True)\n",
    "\n",
    "frequencies_free_dsi, edges_free_dsi = np.histogram(np.clip(b['Freely Moving'][0], 0, 1), 20)\n",
    "frequencies_fixed_dsi, edges_fixed_dsi = np.histogram(np.clip(b['Head Fixed'][0], 0, 1), 20)\n",
    "\n",
    "cell_match_hist_dsi = hv.Overlay([hv.Histogram((frequencies_free_dsi, edges_free_dsi)).opts(alpha=0.5, fill_color=fp.hv_blue_rgb), \n",
    "                                  hv.Histogram((frequencies_fixed_dsi, edges_fixed_dsi)).opts(alpha=0.5, fill_color=fp.hv_orange_rgb)])\n",
    "\n",
    "layout_matched_still = cell_match_hist_dsi.opts(height=300, width=400, xlabel='DSI') + cell_match_hist_osi.opts(height=300, width=500, xlabel='OSI', ylabel='', legend_position='right', fontsize={'legend': 10})\n",
    "layout_matched_still\n",
    "# save_path = os.path.join(figure_save_path, \"Fig4\", \"unmatched_dsi_osi_hist.png\")\n",
    "# layout_matched_still = fp.save_figure(layout_matched_still, save_path=save_path, fig_width=18, dpi=1000, fontsize='poster', target='both', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df533f9c",
   "metadata": {},
   "source": [
    "unity_line = hv.Curve(zip(np.linspace(0, 1), np.linspace(0,1))).opts(color='black')\n",
    "\n",
    "scatter_OSI = hv.Scatter(zip(np.clip(a['Head Fixed'][0], 0, 1), np.clip(a['Freely Moving'][0], 0, 1)), kdims=['OSI_fixed'], vdims=['OSI_free']).opts(xlabel='Fixed OSI', ylabel='Free OSI', size=5, width=500, height=500)\n",
    "scatter_OSI = scatter_OSI * unity_line\n",
    "\n",
    "scatter_DSI = hv.Scatter(zip(np.clip(b['Head Fixed'][0], 0, 1), np.clip(b['Freely Moving'][0], 0, 1)), kdims=['DSI_fixed'], vdims=['DSI_free']).opts(xlabel='Fixed DSI', ylabel='Free DSI', size=5, width=500, height=500)\n",
    "scatter_DSI = scatter_DSI * unity_line\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"delta_OSI_{parsed_search['result']}_{parsed_search['rig']}.png\")\n",
    "scatter_OSI = fp.save_figure(scatter_OSI, save_path=save_path, fig_width=16, dpi=800, fontsize='screen', target='save', display_factor=0.1)\n",
    "\n",
    "save_path = os.path.join(figure_save_path, f\"delta_DSI_{parsed_search['result']}_{parsed_search['rig']}.png\")\n",
    "scatter_DSI = fp.save_figure(scatter_DSI, save_path=save_path, fig_width=16, dpi=800, fontsize='screen', target='save', display_factor=0.1)\n",
    "\n",
    "scatter_OSI + scatter_DSI\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f1183a3a-1fd6-4e0f-999a-c3474401df7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unmatched Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30fe9e-fe0b-4b83-94e4-d24127c47808",
   "metadata": {},
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "for ds, exp_type in zip([agg_dict['VTuningWF_unmatched_norm_spikes_viewed_props'], agg_dict['VWheelWF_unmatched_norm_spikes_viewed_props']], \n",
    "                        ['Freely Moving', 'Head Fixed']):\n",
    "    frac_ori_tuned = []\n",
    "    frac_dir_tuned = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in ds.groupby('mouse'):\n",
    "        ori_tuned = np.abs(group.osi) > 0.75\n",
    "        dir_tuned = np.abs(group.dsi_abs) > 0.75\n",
    "        frac_ori_tuned.append(ori_tuned.sum() / ori_tuned.count())\n",
    "        frac_dir_tuned.append(dir_tuned.sum() / dir_tuned.count())\n",
    "\n",
    "\n",
    "    df['group'] = [exp_type] * len(frac_ori_tuned)\n",
    "    df['Ori. Tuned'] = frac_ori_tuned\n",
    "    df['Dir. Tuned'] = frac_dir_tuned\n",
    "    df_list.append(df)\n",
    "    plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "unmatched_dsi_osi = pd.concat(df_list, axis=0)\n",
    "unmatched_dsi_osi= pd.melt(unmatched_dsi_osi, id_vars=['group'], value_vars=['Ori. Tuned', 'Dir. Tuned'])\n",
    "\n",
    "violinplot_dsi_osi_unmatched = hv.Violin(unmatched_dsi_osi, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=400,\n",
    "                                                                  ylim=(0, 1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  cmap=[fp.hv_blue_hex, fp.hv_orange_hex],\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"unmatched_frac_ori_dir_tuned.png\")\n",
    "# violinplot\n",
    "violinplot_dsi_osi_unmatched = fp.save_figure(violinplot_dsi_osi_unmatched, save_path=save_path, fig_width=16, dpi=1000, fontsize='screen', target='both', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727ccf8-491a-40e0-aa56-efd7b0b35850",
   "metadata": {},
   "source": [
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "comp_tuning_rank_sum = unmatched_dsi_osi.groupby(['variable', 'group'], group_keys=True).value.agg(list).unstack(level=1)\n",
    "comp_tuning_stats = comp_tuning_rank_sum.apply(lambda x: st.mannwhitneyu(x['Freely Moving'], x['Head Fixed'], alternative='two-sided'), axis=1)\n",
    "p_vals = [comp_tuning_stats.to_numpy()[i][1] for i in np.arange(comp_tuning_stats.shape[0])]\n",
    "print(comp_tuning_stats)\n",
    "multipletests(p_vals, alpha=0.05, method='bonferroni')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc3d79-fed5-4096-a04a-fe0a5c76c400",
   "metadata": {},
   "source": [
    "plt_list = []\n",
    "df_list = []\n",
    "\n",
    "for ds, exp_type in zip([agg_dict['VTuningWF_unmatched_norm_spikes_viewed_props'], agg_dict['VWheelWF_unmatched_norm_spikes_viewed_props']], \n",
    "                        ['Freely Moving', 'Head Fixed']):\n",
    "    df = pd.DataFrame()\n",
    "    df['OSI'] = ds.osi.abs().to_numpy()\n",
    "    df['DSI'] = ds.dsi_abs.abs().to_numpy()\n",
    "    df['group'] = [exp_type] * len(ds.osi)\n",
    "    df_list.append(df)\n",
    "    \n",
    "    # plt_list.append(df.hvplot.box(legend=False))\n",
    "\n",
    "unmatched_selectivity = pd.concat(df_list, axis=0)\n",
    "unmatched_selectivity = pd.melt(unmatched_selectivity, id_vars=['group'], value_vars=['OSI', 'DSI'])\n",
    "\n",
    "violinplot_selectivity_unmatched = hv.Violin(unmatched_selectivity, ['variable', 'group'], 'value').opts(xlabel='', ylabel='Selectivity', \n",
    "                                                                  width=1000, height=400,\n",
    "                                                                  ylim=(-0.1, 1.1),\n",
    "                                                                  violin_color=hv.dim('group'),\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "save_path = os.path.join(figure_save_path, \"unmatched_selectivity.png\")\n",
    "violinplot_selectivity_unmatched = fp.save_figure(violinplot_selectivity_unmatched, save_path=save_path, fig_width=16, dpi=1000, fontsize='poster', target='both', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd6cb8-313d-4cf0-b03b-c4cb97d474a7",
   "metadata": {},
   "source": [
    "a = unmatched_selectivity[unmatched_selectivity.variable == 'OSI'].fillna(0).drop(columns='variable')\n",
    "a = a.groupby('group').agg(list).T.reset_index(drop=True)\n",
    "\n",
    "frequencies_free_osi, edges_free_osi = np.histogram(a['Freely Moving'][0], 20)\n",
    "frequencies_fixed_osi, edges_fixed_osi = np.histogram(a['Head Fixed'][0], 20)\n",
    "\n",
    "unmatched_hist_osi = hv.Overlay([hv.Histogram((frequencies_free_osi, edges_free_osi), label='Freely Moving').opts(alpha=0.5, fill_color=fp.hv_blue_rgb), \n",
    "                                  hv.Histogram((frequencies_fixed_osi, edges_fixed_osi), label='Head Fixed').opts(alpha=0.5, fill_color=fp.hv_orange_rgb)])\n",
    "\n",
    "b = unmatched_selectivity[unmatched_selectivity.variable == 'DSI'].fillna(0).drop(columns='variable')\n",
    "b = b.groupby('group').agg(list).T.reset_index(drop=True)\n",
    "\n",
    "frequencies_free_dsi, edges_free_dsi = np.histogram(b['Freely Moving'][0], 20)\n",
    "frequencies_fixed_dsi, edges_fixed_dsi = np.histogram(b['Head Fixed'][0], 20)\n",
    "\n",
    "unmatched_hist_dsi = hv.Overlay([hv.Histogram((frequencies_free_dsi, edges_free_dsi)).opts(alpha=0.5, fill_color=fp.hv_blue_rgb), \n",
    "                                  hv.Histogram((frequencies_fixed_dsi, edges_fixed_dsi)).opts(alpha=0.5, fill_color=fp.hv_orange_rgb)])\n",
    "\n",
    "layout_unmatched = unmatched_hist_dsi.opts(height=300, width=400, xlabel='DSI') + unmatched_hist_osi.opts(height=300, width=500, xlabel='OSI', ylabel='', legend_position='right', fontsize={'legend': 10})\n",
    "layout_unmatched"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "31179cc2-6bad-4381-ab5f-cbf3260f9be7",
   "metadata": {},
   "source": [
    "## Compare matched/unmatched strongly tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6635ad-308a-4bae-b7b4-7e860956bb70",
   "metadata": {},
   "source": [
    "matched_selectivity['super_group'] = 'matched'\n",
    "unmatched_selectivity['super_group'] = 'unmatched'\n",
    "all_selectivity = pd.concat([matched_selectivity, unmatched_selectivity]).fillna(0)\n",
    "violinplot_selectivity = hv.Violin(all_selectivity, ['variable', 'group', 'super_group'], 'value').opts(xlabel='', ylabel='Selectivity', \n",
    "                                                                  width=1000, height=200,\n",
    "                                                                  ylim=(-0.05, 1.05),\n",
    "                                                                  violin_color=hv.dim('super_group'),\n",
    "                                                                  cmap='Category10',\n",
    "                                                                  # show_legend=True, legend_position='right',\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "\n",
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "rank_sum = all_selectivity.groupby(['variable', 'group', 'super_group'], group_keys=True).value.agg(list).unstack(level=-1)\n",
    "stats = rank_sum.apply(lambda x: st.ranksums(x['matched'], x['unmatched'], alternative='two-sided'), axis=1)\n",
    "p_vals = [stats.to_numpy()[i][1] for i in np.arange(stats.shape[0])]\n",
    "print(p_vals)\n",
    "print(multipletests(p_vals, alpha=0.05, method='bonferroni'))\n",
    "\n",
    "save_path = os.path.join(figure_save_path, \"selectivity_dist_comp.png\")\n",
    "violinplot_selectivity = fp.save_figure(violinplot_selectivity, save_path=save_path, fig_width=30, dpi=1200, fontsize='screen', target='screen', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4228625-61d6-4dd8-b850-9a1284a51681",
   "metadata": {},
   "source": [
    "all_selectivity"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34466081-0ca4-44e0-89a4-245523c53c7c",
   "metadata": {},
   "source": [
    "save_paths = []\n",
    "selectivity_array = all_selectivity.groupby(['variable', 'group', 'super_group']).agg(list).values\n",
    "num_comps = a.shape[0]/2\n",
    "\n",
    "selectivity_plot_list = []\n",
    "for i, (a, b) in enumerate(zip(selectivity_array[::2], selectivity_array[1::2])):\n",
    "    save_path = os.path.join(figure_save_path, f\"selectivity_dist_comp_histogram_{i}.png\")\n",
    "    \n",
    "    frequencies_matched, edges_matched = np.histogram(np.clip(a[0], 0, 1), 20)\n",
    "    frequencies_matched = frequencies_matched.astype(float) / np.max(frequencies_matched)\n",
    "    frequencies_unmatched, edges_unmatched = np.histogram(np.clip(b[0], 0, 1), 20)\n",
    "    frequencies_unmatched = frequencies_unmatched.astype(float) / np.max(frequencies_unmatched.astype(float))\n",
    "\n",
    "    matched_hist = hv.Histogram((frequencies_matched, edges_matched), label='matched').opts(alpha=0.5, xlabel='', width=800, height=600, fill_color=fp.hv_mpi_green_rgb, ylabel=\"Probability\")\n",
    "    unmatched_hist = hv.Histogram((frequencies_unmatched, edges_unmatched), label='unmatched').opts(alpha=0.5, xlabel='', width=800, height=600, fill_color=fp.hv_mpi_yellow_rgb)\n",
    "    \n",
    "    if i > 0:\n",
    "        matched_hist.opts(yaxis=None, width=600)\n",
    "        unmatched_hist.opts(yaxis=None, width=600)\n",
    "    \n",
    "    hist_overlay = hv.Overlay([matched_hist, unmatched_hist])\n",
    "    hist_overlay.opts(show_legend=False)\n",
    "\n",
    "    if i == 0:\n",
    "        hist_overlay = fp.save_figure(hist_overlay, save_path=save_path, fig_width=8, dpi=1200, fontsize='screen', target='screen', display_factor=0.1)\n",
    "    else:\n",
    "        hist_overlay = fp.save_figure(hist_overlay, save_path=save_path, fig_width=6, dpi=1200, fontsize='screen', target='screen', display_factor=0.1)\n",
    "\n",
    "    selectivity_plot_list.append(hist_overlay)\n",
    "\n",
    "selectivity_layout = hv.Layout(selectivity_plot_list)\n",
    "selectivity_layout"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5203dd-8efa-4378-bb5b-842d3e606568",
   "metadata": {},
   "source": [
    "matched_dsi_osi['super_group'] = 'matched'\n",
    "unmatched_dsi_osi['super_group'] = 'unmatched'\n",
    "all_dsi_osi = pd.concat([matched_dsi_osi, unmatched_dsi_osi]).fillna(0)\n",
    "violinplot = hv.Violin(all_dsi_osi, ['variable', 'group', 'super_group'], 'value').opts(xlabel='', ylabel='Significant Frac.', \n",
    "                                                                  width=1000, height=200,\n",
    "                                                                  ylim=(-0.05, 1),\n",
    "                                                                  violin_color=hv.dim('super_group'),\n",
    "                                                                  cmap=[fp.hv_mpi_green_hex, fp.hv_mpi_yellow_hex],\n",
    "                                                                  fontsize={'legend': 10}\n",
    "                                                                 )\n",
    "\n",
    "# Do a Wilcoxon Rank-Sum  with Bonferroni correction\n",
    "rank_sum = all_dsi_osi.groupby(['variable', 'group', 'super_group'], group_keys=True).value.agg(list).unstack(level=-1)\n",
    "stats = rank_sum.apply(lambda x: st.ranksums(x['matched'], x['unmatched'], alternative='two-sided'), axis=1)\n",
    "p_vals = [stats.to_numpy()[i][1] for i in np.arange(stats.shape[0])]\n",
    "print(p_vals)\n",
    "print(multipletests(p_vals, alpha=0.05, method='bonferroni'))\n",
    "\n",
    "save_path = os.path.join(figure_save_path, \"sig_frac_selectivity_dsi_osi.png\")\n",
    "violinplot = fp.save_figure(violinplot, save_path=save_path, fig_width=30, dpi=1200, fontsize='poster', target='both', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbd5f4-ef00-46a3-a7cd-dd5d93c2286a",
   "metadata": {},
   "source": [
    "sig_dsi_osi_array = all_dsi_osi.groupby(['variable', 'group', 'super_group']).agg(list).values\n",
    "num_comps = a.shape[0]/2\n",
    "\n",
    "dsi_osi_plot_list = []\n",
    "for a, b in zip(sig_dsi_osi_array[::2], sig_dsi_osi_array[1::2]):\n",
    "    frequencies_matched, edges_matched = np.histogram(a[0], 20)\n",
    "    frequencies_unmatched, edges_unmatched = np.histogram(b[0], 20)\n",
    "\n",
    "    hist_overlay =  hv.Overlay([hv.Histogram((frequencies_unmatched, edges_unmatched), label='unmatched').opts(alpha=0.5, fill_color=fp.hv_orange_rgb), \n",
    "                                hv.Histogram((frequencies_matched, edges_matched), label='matched').opts(alpha=0.5, fill_color=fp.hv_blue_rgb)])\n",
    "\n",
    "    dsi_osi_plot_list.append(hist_overlay)\n",
    "\n",
    "dsi_osi_layout = hv.Layout(dsi_osi_plot_list)\n",
    "dsi_osi_layout"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fd3299d8-1b28-4753-a776-8f23faf8e119",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deef3d6-2062-415d-84a6-bef6f11d5ce3",
   "metadata": {},
   "source": [
    "from umap.umap_ import UMAP\n",
    "from rastermap import Rastermap\n",
    "import sklearn.preprocessing as preproc"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeefade2-717d-4e86-a3de-9cc87ad843b7",
   "metadata": {},
   "source": [
    "cell_kind = 'all_cells'   # options: 'all_cells', 'matched', 'unmatched'\n",
    "kinem_label_list = processing_parameters.variable_list_free + processing_parameters.variable_list_fixed\n",
    "labels = kinem_label_list + ['norm_spikes_viewed_props']\n",
    "labels = ['_'.join((cell_kind, label)) for label in labels]\n",
    "\n",
    "umap_dict = {}\n",
    "for label in labels:\n",
    "    agg_keys = [key for key in agg_dict.keys() if label in key]\n",
    "\n",
    "    for key in agg_keys:\n",
    "        ds = agg_dict[key]\n",
    "        base_label = '_'.join(label.split('_')[len(cell_kind.split('_')):])\n",
    "        if base_label in kinem_label_list: \n",
    "            tuning = ds['Qual_index']\n",
    "            umap_dict[base_label] = tuning\n",
    "        else:\n",
    "            tuning_dsi = ds['dsi_abs']\n",
    "            tuning_osi = ds['osi']\n",
    "            umap_dict['dsi'] = np.clip(tuning_dsi, 0, 1)\n",
    "            umap_dict['osi'] = np.clip(tuning_osi, 0, 1)\n",
    "\n",
    "\n",
    "raw_tunings = pd.DataFrame.from_dict(umap_dict)\n",
    "raw_tunings = raw_tunings.fillna(0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd026d7d",
   "metadata": {},
   "source": [
    "# TEST - Run UMAP on matched cells\n",
    "cell_kind = 'matched'   # options: 'all_cells', 'matched', 'unmatched'\n",
    "\n",
    "if (parsed_search['result'] == 'repeat') and (parsed_search['rig'] == 'VWheelWF'):\n",
    "    kinem_label_list = processing_parameters.variable_list_fixed\n",
    "elif (parsed_search['result'] == 'repeat') and (parsed_search['rig'] == 'VTuningWF'):\n",
    "    kinem_label_list = processing_parameters.variable_list_free\n",
    "else:\n",
    "    kinem_label_list = processing_parameters.variable_list_free + processing_parameters.variable_list_fixed\n",
    "\n",
    "label_list = kinem_label_list + [activity_dataset]\n",
    "labels = [f\"_{cell_kind}_{label}\" for label in label_list]\n",
    "\n",
    "umap_dict = {}\n",
    "for label in labels:\n",
    "    data_keys = [key for key in agg_dict.keys() if label in key]\n",
    "\n",
    "    for key in data_keys:\n",
    "        ds = agg_dict[key]\n",
    "        base_label = '_'.join(label.split('_')[1 + len(cell_kind.split('_')):])\n",
    "\n",
    "        if base_label in kinem_label_list:\n",
    "            tuning = ds['Qual_index']\n",
    "            umap_dict[base_label] = tuning\n",
    "        else:\n",
    "            this_rig = key.split('_')[0]\n",
    "            tuning_dsi = ds['dsi_abs'].abs().to_numpy()\n",
    "            tuning_osi = ds['osi'].to_numpy()\n",
    "            umap_dict[f'dsi_{this_rig}'] = np.clip(tuning_dsi, 0, 1)\n",
    "            umap_dict[f'osi_{this_rig}'] = np.clip(tuning_osi, 0, 1)\n",
    "\n",
    "max_col_length = max([len(col) for key, col in umap_dict.items()])\n",
    "for key, value in umap_dict.items():\n",
    "    if len(key) < max_col_length:\n",
    "        new_val = np.empty(max_col_length)\n",
    "        new_val.fill(np.nan)\n",
    "        new_val[:len(value)] = value\n",
    "        umap_dict[key] = new_val\n",
    "\n",
    "raw_tunings = pd.DataFrame.from_dict(umap_dict)\n",
    "raw_tunings = raw_tunings.fillna(0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f99a56-a840-412b-8631-8cb7ac50bc1e",
   "metadata": {},
   "source": [
    "tunings = preproc.StandardScaler().fit_transform(raw_tunings.to_numpy())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047ba5a-06f5-4fd0-8490-cdab8b3148c8",
   "metadata": {},
   "source": [
    "tuning_subset = tunings[np.random.choice(tunings.shape[0], tunings.shape[0], replace=False)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9b0a7-d6e9-4eac-8453-8e44f261bad2",
   "metadata": {},
   "source": [
    "# perform umap on the fit cell tuning\n",
    "reducer1 = UMAP(min_dist=0.1, n_neighbors=50)\n",
    "embedded_data1 = reducer1.fit_transform(tuning_subset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e85fe4-31db-4cc2-ab6b-062077e1b513",
   "metadata": {},
   "source": [
    "perc = 99\n",
    "predictor_columns = umap_dict.keys()    #['dsi', 'osi', 'responsivity']\n",
    "plot_list = []\n",
    "\n",
    "for i, predictor_column in enumerate(predictor_columns):\n",
    "    label_idx = [idx for idx, el in enumerate(predictor_columns) if predictor_column == el]\n",
    "    raw_labels = tuning_subset[:, label_idx]\n",
    "    \n",
    "    raw_labels = np.abs(raw_labels)\n",
    "    \n",
    "    raw_labels[raw_labels>np.percentile(raw_labels, perc)] = np.percentile(raw_labels, perc)\n",
    "    raw_labels[raw_labels<np.percentile(raw_labels, 100-perc)] = np.percentile(raw_labels, 100-perc)\n",
    "    \n",
    "    plot_data = np.concatenate([embedded_data1, raw_labels.reshape((-1, 1))], axis=1)\n",
    "\n",
    "    umap_plot = hv.Scatter(plot_data, vdims=['Dim 2', 'Parameter'], kdims=['Dim 1'])\n",
    "    # umap_plot = hv.HexTiles(umap_data, kdims=['Dim 1', 'Dim 2'])\n",
    "    if i == len(predictor_columns)-1:\n",
    "        umap_plot.opts(colorbar=False, color='Parameter', cmap='Spectral_r', alpha=1, xaxis=None, yaxis=None, tools=['hover'])\n",
    "    else:\n",
    "        umap_plot.opts(colorbar=False, color='Parameter', cmap='Spectral_r', alpha=1, xaxis=None, yaxis=None, tools=['hover'])\n",
    "    \n",
    "    if any([predictor_column.startswith('dsi'), predictor_column.startswith('osi')]):\n",
    "        umap_plot.opts(title=f\"{predictor_column[:3].upper()} {processing_parameters.wf_label_dictionary[predictor_column.split('_')[-1]]}\")\n",
    "    else:\n",
    "        umap_plot.opts(title=processing_parameters.wf_label_dictionary[predictor_column])\n",
    "\n",
    "        umap_plot.opts(width=300, height=300, size=2)\n",
    "\n",
    "    save_name = os.path.join(figure_save_path, f\"UMAP_{predictor_column}_{cell_kind}.png\")   \n",
    "    umap_plot = fp.save_figure(umap_plot, save_path=save_name, fig_width=6, dpi=1000, fontsize='screen', target='screen', display_factor=0.1)\n",
    "    plot_list.append(umap_plot)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930e7a6-30eb-49e2-b4ff-ff7ffbafeb02",
   "metadata": {},
   "source": [
    "layout = hv.Layout(plot_list).cols(5)\n",
    "layout"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0695f-e106-4334-8f49-13837f112825",
   "metadata": {},
   "source": [
    "# umap plot of the fit cell tunings\n",
    "umap_plot = hv.Scatter(plot_data, vdims=['Dim 2', 'Parameter'], kdims=['Dim 1'])\n",
    "# umap_plot = hv.HexTiles(plot_data, vdims=['Dim 2', 'Parameter'], kdims=['Dim 1'])\n",
    "umap_plot.opts(colorbar=True, color='Parameter', cmap='Spectral_r', tools=['hover'], alpha=1)\n",
    "umap_plot.opts(width=500, height=500, size=5)\n",
    "\n",
    "# assemble the file name\n",
    "# save_name = os.path.join(save_path, '_'.join(('poster', 'UMAP')) + '.png')\n",
    "# # save the figure\n",
    "# fig = fp.save_figure(umap_plot, save_name, fig_width=15, dpi=1200, fontsize='poster', target='screen')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebb446-2fd7-41e4-969c-7108364b5d90",
   "metadata": {},
   "source": [
    "# plot the tunings from MINE\n",
    "ticks = [(idx+0.5, processing_parameters.wf_label_dictionary[el]) for idx, el in enumerate(predictor_columns)]\n",
    "plot_matrix = raw_tunings.dropna().to_numpy().copy().T\n",
    "plot_matrix[plot_matrix<0.05] = 0\n",
    "model = Rastermap(n_clusters=2, n_PCs=200)\n",
    "model.fit(plot_matrix)\n",
    "plot_matrix = plot_matrix[model.isort, :]\n",
    "plot = hv.Raster(plot_matrix)\n",
    "plot.opts(width=1000, height=600, cmap='RdBu_r', tools=['hover'], clim=(-1, 1), xticks=ticks, xrotation=45, xlabel='', ylabel='Cells', colorbar=True)\n",
    "\n",
    "# assemble the file name\n",
    "save_name = os.path.join(save_path, '_'.join(('Fig5', 'MINE_tunings')) + '.png')\n",
    "# save the figure\n",
    "fig = fp.save_figure(plot, save_name, fig_width=7, dpi=1200, fontsize='poster', target='screen')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802817f2-f8ad-4806-9502-d41059ef66a7",
   "metadata": {},
   "source": [
    "cell_kinds = ['all_cells', 'matched', 'unmatched']  # options: 'all_cells', 'matched', 'unmatched'\n",
    "reducer = UMAP(min_dist=0.1, n_neighbors=50)\n",
    "for cell_kind in cell_kinds:\n",
    "    labels = [f\"_{cell_kind}_{label}\" for label in label_list]\n",
    "\n",
    "    # If the cells are matched, we always have the same number of cells\n",
    "    if cell_kind == \"matched\":\n",
    "        umap_dict = {}\n",
    "        for label in labels:\n",
    "            data_keys = [key for key in agg_dict.keys() if label in key]\n",
    "\n",
    "            for key in data_keys:\n",
    "                ds = agg_dict[key]\n",
    "                base_label = '_'.join(label.split('_')[1 + len(cell_kind.split('_')):])\n",
    "\n",
    "                if base_label in kinem_label_list:\n",
    "                    tuning = ds['Qual_index']\n",
    "                    umap_dict[base_label] = tuning\n",
    "                else:\n",
    "                    this_rig = key.split('_')[0]\n",
    "                    tuning_dsi = ds['dsi_abs'].abs().to_numpy()\n",
    "                    tuning_osi = ds['osi'].to_numpy()\n",
    "                    umap_dict[f'dsi_{this_rig}'] = np.clip(tuning_dsi, 0, 1)\n",
    "                    umap_dict[f'osi_{this_rig}'] = np.clip(tuning_osi, 0, 1)\n",
    "\n",
    "        raw_tunings = pd.DataFrame.from_dict(umap_dict)\n",
    "        raw_tunings = raw_tunings.fillna(0)\n",
    "\n",
    "        tunings = preproc.StandardScaler().fit_transform(raw_tunings.to_numpy())\n",
    "\n",
    "        # perform umap on the fit cell tuning\n",
    "        embedded_data = reducer.fit_transform(tunings)\n",
    "\n",
    "        perc = 99\n",
    "        predictor_columns = umap_dict.keys()\n",
    "        plot_list = []\n",
    "\n",
    "        for i, predictor_column in enumerate(predictor_columns):\n",
    "            label_idx = [idx for idx, el in enumerate(predictor_columns) if predictor_column == el]\n",
    "            raw_labels = tunings[:, label_idx]\n",
    "\n",
    "            raw_labels = np.abs(raw_labels)\n",
    "\n",
    "            raw_labels[raw_labels > np.percentile(raw_labels, perc)] = np.percentile(raw_labels, perc)\n",
    "            raw_labels[raw_labels < np.percentile(raw_labels, 100 - perc)] = np.percentile(raw_labels, 100 - perc)\n",
    "\n",
    "            plot_data = np.concatenate([embedded_data, raw_labels.reshape((-1, 1))], axis=1)\n",
    "\n",
    "            umap_plot = hv.Scatter(plot_data, vdims=['Dim 2', 'Parameter'], kdims=['Dim 1'])\n",
    "            # umap_plot = hv.HexTiles(umap_data, kdims=['Dim 1', 'Dim 2'])\n",
    "            if i == len(predictor_columns) - 1:\n",
    "                umap_plot.opts(colorbar=False, color='Parameter', cmap='Spectral_r', alpha=1, xaxis=None,\n",
    "                                yaxis=None,\n",
    "                                tools=['hover'])\n",
    "            else:\n",
    "                umap_plot.opts(colorbar=False, color='Parameter', cmap='Spectral_r', alpha=1, xaxis=None,\n",
    "                                yaxis=None,\n",
    "                                tools=['hover'])\n",
    "\n",
    "            if any([predictor_column.startswith('dsi'), predictor_column.startswith('osi')]):\n",
    "                umap_plot.opts(title=f\"{predictor_column[:3].upper()} \"\n",
    "                                        f\"{processing_parameters.wf_label_dictionary[predictor_column.split('_')[-1]]}\")\n",
    "            else:\n",
    "                umap_plot.opts(title=processing_parameters.wf_label_dictionary[predictor_column])\n",
    "\n",
    "            umap_plot.opts(width=300, height=300, size=2)\n",
    "\n",
    "            save_name = os.path.join(figure_save_path, f\"{cell_kind}_UMAP_{predictor_column}.png\")\n",
    "            umap_plot = fp.save_figure(umap_plot, save_path=save_name, fig_width=6, dpi=800, fontsize='paper',\n",
    "                                        target='screen', display_factor=0.1)\n",
    "\n",
    "    else:\n",
    "        # Here there may be uneven numbers of cells between sessions\n",
    "        umap_dict_1 = {}\n",
    "        umap_dict_2 = {}\n",
    "\n",
    "        for label in labels:\n",
    "            data_keys = [key for key in agg_dict.keys() if label in key]\n",
    "\n",
    "            for key in data_keys:\n",
    "                ds = agg_dict[key]\n",
    "                base_label = '_'.join(label.split('_')[1 + len(cell_kind.split('_')):])\n",
    "\n",
    "                if base_label in kinem_label_list:\n",
    "                    tuning = ds['Qual_index']\n",
    "\n",
    "                    if base_label in processing_parameters.variable_list_free:\n",
    "                        umap_dict_1[base_label] = tuning\n",
    "                    else:\n",
    "                        umap_dict_2[base_label] = tuning\n",
    "                else:\n",
    "                    this_rig = key.split('_')[0]\n",
    "                    tuning_dsi = ds['dsi_abs'].abs().to_numpy()\n",
    "                    tuning_osi = ds['osi'].to_numpy()\n",
    "\n",
    "                    if this_rig == 'VTuningWF':\n",
    "                        umap_dict_1[f'dsi_{this_rig}'] = np.clip(tuning_dsi, 0, 1)\n",
    "                        umap_dict_1[f'osi_{this_rig}'] = np.clip(tuning_osi, 0, 1)\n",
    "                    else:\n",
    "                        umap_dict_2[f'dsi_{this_rig}'] = np.clip(tuning_dsi, 0, 1)\n",
    "                        umap_dict_2[f'osi_{this_rig}'] = np.clip(tuning_osi, 0, 1)\n",
    "\n",
    "        raw_tunings_1 = pd.DataFrame.from_dict(umap_dict_1)\n",
    "        raw_tunings_1 = raw_tunings_1.fillna(0)\n",
    "        raw_tunings_2 = pd.DataFrame.from_dict(umap_dict_2)\n",
    "        raw_tunings_2 = raw_tunings_2.fillna(0)\n",
    "\n",
    "        tunings_1 = preproc.StandardScaler().fit_transform(raw_tunings_1.to_numpy())\n",
    "        tunings_2 = preproc.StandardScaler().fit_transform(raw_tunings_2.to_numpy())\n",
    "\n",
    "        # perform umap on the fit cell tuning\n",
    "        embedded_data_1 = reducer.fit_transform(tunings_1)\n",
    "        embedded_data_2 = reducer.fit_transform(tunings_2)\n",
    "\n",
    "        perc = 99\n",
    "        plot_list = []\n",
    "        \n",
    "        for umap_dict, embedded_data, tunings in zip([umap_dict_1, umap_dict_2], \n",
    "                                            [embedded_data_1, embedded_data_2], \n",
    "                                            [tunings_1, tunings_2]):\n",
    "            \n",
    "            predictor_columns = umap_dict.keys()\n",
    "\n",
    "            for i, predictor_column in enumerate(predictor_columns):\n",
    "                label_idx = [idx for idx, el in enumerate(predictor_columns) if predictor_column == el]\n",
    "                raw_labels = tunings[:, label_idx]\n",
    "\n",
    "                raw_labels = np.abs(raw_labels)\n",
    "\n",
    "                raw_labels[raw_labels > np.percentile(raw_labels, perc)] = np.percentile(raw_labels, perc)\n",
    "                raw_labels[raw_labels < np.percentile(raw_labels, 100 - perc)] = np.percentile(raw_labels, 100 - perc)\n",
    "\n",
    "                plot_data = np.concatenate([embedded_data, raw_labels.reshape((-1, 1))], axis=1)\n",
    "\n",
    "                umap_plot = hv.Scatter(plot_data, vdims=['Dim 2', 'Parameter'], kdims=['Dim 1'])\n",
    "                # umap_plot = hv.HexTiles(umap_data, kdims=['Dim 1', 'Dim 2'])\n",
    "                if i == len(predictor_columns) - 1:\n",
    "                    umap_plot.opts(colorbar=False, color='Parameter', cmap='Spectral_r', alpha=1, xaxis=None,\n",
    "                                    yaxis=None,\n",
    "                                    tools=['hover'])\n",
    "                else:\n",
    "                    umap_plot.opts(colorbar=False, color='Parameter', cmap='Spectral_r', alpha=1, xaxis=None,\n",
    "                                    yaxis=None,\n",
    "                                    tools=['hover'])\n",
    "\n",
    "                if any([predictor_column.startswith('dsi'), predictor_column.startswith('osi')]):\n",
    "                    umap_plot.opts(title=f\"{predictor_column[:3].upper()} \"\n",
    "                                            f\"{processing_parameters.wf_label_dictionary[predictor_column.split('_')[-1]]}\")\n",
    "                else:\n",
    "                    umap_plot.opts(title=processing_parameters.wf_label_dictionary[predictor_column])\n",
    "\n",
    "                umap_plot.opts(width=300, height=300, size=2)\n",
    "\n",
    "                save_name = os.path.join(figure_save_path, f\"{cell_kind}_UMAP_{predictor_column}.png\")\n",
    "                umap_plot = fp.save_figure(umap_plot, save_path=save_name, fig_width=6, dpi=800, fontsize='paper',\n",
    "                                            target='screen', display_factor=0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03314c99",
   "metadata": {},
   "source": [
    "layout = hv.Layout(plot_list).cols(5)\n",
    "layout"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab496d",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
