{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "import h5py\n",
    "import cv2\n",
    "from skimage import color\n",
    "from hmmlearn import hmm\n",
    "from scipy.stats import mannwhitneyu\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import paths\n",
    "import processing_parameters\n",
    "import functions_bondjango as bd\n",
    "import functions_misc as fmisc\n",
    "import functions_matching as fm\n",
    "import functions_data_handling as fdh\n",
    "import functions_tuning as tuning\n",
    "import functions_plotting as fp\n",
    "import functions_kinematic as fk\n",
    "from wirefree_experiment import WirefreeExperiment, DataContainer\n",
    "from functions_wirefree_trigger_fix import get_trial_duration_stats\n",
    "\n",
    "# fig_path = paths.wf_figures_path\n",
    "fig_path = r\"H:\\thesis\\figures\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def drop_partial_or_long_trials(df, min_trial_length=4.5, max_trial_length=5.5):\n",
    "    \"\"\"\n",
    "    This function drops trials that are shorter than min_trial_length (partial trials) and\n",
    "    trials that are longer than max_trial_length (errors in trial number indexing) from the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The dataframe containing the trials.\n",
    "    min_trial_length (float): The minimum length for a trial. Defaults to 4.5.\n",
    "    max_trial_length (float): The maximum length for a trial. Defaults to 5.5.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The dataframe after dropping the partial and long trials.\n",
    "    \"\"\"\n",
    "\n",
    "    trial_lengths = df[df.trial_num > 0].groupby('trial_num').apply(lambda x: x.shape[0] / processing_parameters.wf_frame_rate)\n",
    "\n",
    "    # Drop trials that are shorter than min_trial_length (partial trials)\n",
    "    short_trials = trial_lengths[trial_lengths < min_trial_length].index\n",
    "    df = df.drop(df[df.trial_num.isin(short_trials)].index)\n",
    "\n",
    "    # Drop trials that are longer than max_trial_length (errors in trial number indexing)\n",
    "    long_trials = trial_lengths[trial_lengths > max_trial_length].index\n",
    "    df = df.drop(df[df.trial_num.isin(long_trials)].index).reset_index(drop=True)\n",
    "\n",
    "    return df   \n",
    "\n",
    "\n",
    "def filter_viewed_trials(kinematics, activity_df):\n",
    "\n",
    "    # Filter trials by head pitch if freely moving\n",
    "    pitch_lower_cutoff = processing_parameters.head_pitch_cutoff[0]\n",
    "    pitch_upper_cutoff = processing_parameters.head_pitch_cutoff[1]\n",
    "    view_fraction = processing_parameters.view_fraction\n",
    "    kinematics['viewed'] = np.logical_and(kinematics['head_pitch'].to_numpy() >= pitch_lower_cutoff,\n",
    "                                          kinematics['head_pitch'].to_numpy() <= pitch_upper_cutoff)\n",
    "    viewed_trials = kinematics.groupby('trial_num').filter(\n",
    "        lambda x: (x['viewed'].sum() / len(x['viewed'])) > view_fraction).trial_num.unique()\n",
    "\n",
    "    viewed_activity_df = activity_df.loc[activity_df.trial_num.isin(viewed_trials)].copy()\n",
    "    return viewed_activity_df\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "source": [
    "importlib.reload(processing_parameters)\n",
    "\n",
    "# get the search string\n",
    "# for thesis: 'mouse:MM_221109_a, slug:01_11_2023,'\n",
    "# for control light 'mouse:MM_221109_a, slug:,'\n",
    "# for control dark 'mouse:MM_221109_a, slug:01_27_2023,'\n",
    "\n",
    "search_string = 'mouse:MM_221109_a, slug:01_27_2023' \n",
    "parsed_search = fdh.parse_search_string(search_string)\n",
    "\n",
    "# get the paths from the database\n",
    "\n",
    "# get the raw experiment\n",
    "exp_query = bd.query_database('vr_experiment', search_string)\n",
    "exp_query.sort(key=lambda x: x['rig'])\n",
    "\n",
    "# Get the preprocessing file\n",
    "preproc_query = bd.query_database('analyzed_data', search_string + r', analysis_type:preprocessing')\n",
    "preproc_query = [q for q in preproc_query if parsed_search['mouse'].lower() in q['slug']]\n",
    "preproc_query.sort(key=lambda x: x['rig'])\n",
    "preproc_paths = np.sort(np.array([el['analysis_path'] for el in preproc_query if (el['analysis_type'] == 'preprocessing') and\n",
    "                        (parsed_search['mouse'].lower() in el['slug'])]))\n",
    "\n",
    "# Get the tuning curve file\n",
    "tc_query = bd.query_database('analyzed_data', search_string + r', analysis_type:tc_analysis')\n",
    "tc_query = [q for q in tc_query if parsed_search['mouse'].lower() in q['slug']]\n",
    "tc_query.sort(key=lambda x: x['rig'])\n",
    "tc_paths = np.sort(np.array([el['analysis_path'] for el in tc_query if (el['analysis_type'] == 'tc_analysis') and\n",
    "                    (parsed_search['mouse'].lower() in el['slug'])]))\n",
    "\n",
    "# Get the cell matching file\n",
    "cell_match_query = bd.query_database('analyzed_data', search_string + r', analysis_type:cellmatching')\n",
    "cell_match_query = [q for q in cell_match_query if parsed_search['mouse'].lower() in q['slug']]\n",
    "cell_match_query.sort(key=lambda x: x['rig'])\n",
    "cell_matching_path = np.array([el['analysis_path'] for el in cell_match_query if (el['analysis_type'] == 'cellmatching') and\n",
    "                                (parsed_search['mouse'].lower() in el['slug']) and ('daycellmatch' in el['slug'])])\n",
    "\n",
    "# Get the calcium file names\n",
    "calcium_paths = np.array([p.replace('preproc', 'calciumraw') for p in preproc_paths])\n",
    "\n",
    "# Parse the rigs\n",
    "rigs = np.array([os.path.basename(file).split('_')[6] for file in calcium_paths])\n",
    "sort_array = np.argsort(rigs)\n",
    "\n",
    "rigs = rigs[sort_array]\n",
    "calcium_paths = calcium_paths[sort_array]\n",
    "preproc_paths = preproc_paths[sort_array]\n",
    "tc_paths = tc_paths[sort_array]\n",
    "\n",
    "print(cell_matching_path)\n",
    "print(calcium_paths)\n",
    "print(preproc_paths)\n",
    "print(tc_paths)\n",
    "print(rigs)\n",
    "\n",
    "# For thesis\n",
    "parsed_search['lighting'] = 'dark'\n",
    "parsed_search['result'] = 'control'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "source": [
    "# Load the matching assignments and find the column that corresponds to each file\n",
    "assignments =  fm.match_cells(cell_matching_path[0])\n",
    "new_cols = [col.split('_')[-2] for col in assignments.columns]\n",
    "assignments.columns = new_cols\n",
    "col_sort_idx = np.argsort(assignments.columns)\n",
    "assignments = assignments[assignments.columns[col_sort_idx]]\n",
    "\n",
    "# Use number of non-NaNs in each row to filter out components that were not registered in enough sessions\n",
    "assignments_filtered = assignments.dropna().astype(int).to_numpy()\n",
    "unassigned = np.array(assignments[np.sum(~np.isnan(assignments), axis=1) < 2])\n",
    "unassigned = [unassigned[~np.isnan(unassigned[:, 0]), 0].astype(int), unassigned[~np.isnan(unassigned[:, 1]), 1].astype(int)]\n",
    "unassigned = [np.sort(np.unique(unassigned[0])), np.sort(np.unique(unassigned[1]))]\n",
    "\n",
    "# Specify the path to the curated cell matches file\n",
    "curated_cell_matches_path = os.path.join(r\"C:\\Users\\mmccann\\Desktop\", \n",
    "                                f\"curated_cell_matches_{parsed_search['result']}_{parsed_search['lighting']}_{parsed_search['rig']}.xlsx\")\n",
    "\n",
    "try:\n",
    "    # Read all sheets into a list of dataframes\n",
    "    curated_matches_dict = pd.read_excel(curated_cell_matches_path, sheet_name=None)\n",
    "\n",
    "    # Concatenate the dataframes into a single dataframe\n",
    "    curated_matches = pd.concat(curated_matches_dict.values(), ignore_index=True)\n",
    "\n",
    "    # Get the hand-picked matches for the current experiment\n",
    "    day_mouse_curated_idxs = curated_matches[(curated_matches['mouse'] == parsed_search['mouse']) & \n",
    "                                            (curated_matches['day'] == parsed_search['slug'])]['index'].values\n",
    "    \n",
    "    if len(day_mouse_curated_idxs) == 0:\n",
    "        raise Exception(\"No curated matches found for the current experiment. Continuing with CaImAn matches...\")\n",
    "    else:\n",
    "        day_mouse_curated_matches = assignments_filtered[day_mouse_curated_idxs, :]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not find the file {curated_cell_matches_path}. Continuing with CaImAn matches...\")\n",
    "    day_mouse_curated_matches = assignments_filtered"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "source": [
    "# Load freely moving data\n",
    "exp_free = WirefreeExperiment(exp_info=exp_query[0], preproc_info=preproc_query[0], tc_info=tc_query[0])\n",
    "exp_free._load_preprocessing()\n",
    "exp_free._load_tc()\n",
    "\n",
    "exp_free.deconv_fluor = drop_partial_or_long_trials(exp_free.deconv_fluor.copy())\n",
    "exp_free.norm_deconv_fluor = tuning.normalize_responses(exp_free.deconv_fluor.copy())\n",
    "exp_free.deconv_fluor_viewed = filter_viewed_trials(exp_free.kinematics, exp_free.deconv_fluor.copy())\n",
    "exp_free.norm_deconv_fluor_viewed = filter_viewed_trials(exp_free.kinematics, exp_free.norm_deconv_fluor.copy())\n",
    "\n",
    "# load head fixed data\n",
    "exp_fixed = WirefreeExperiment(exp_info=exp_query[1], preproc_info=preproc_query[1], tc_info=tc_query[1])\n",
    "exp_fixed._load_preprocessing()\n",
    "exp_fixed._load_tc()\n",
    "\n",
    "exp_fixed.deconv_fluor = drop_partial_or_long_trials(exp_fixed.deconv_fluor.copy())\n",
    "exp_fixed.norm_deconv_fluor = tuning.normalize_responses(exp_fixed.deconv_fluor.copy())\n",
    "exp_fixed.deconv_fluor_viewed = filter_viewed_trials(exp_fixed.kinematics, exp_fixed.deconv_fluor.copy())\n",
    "exp_fixed.norm_deconv_fluor_viewed = exp_fixed.norm_deconv_fluor.copy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the thresholds for MannWhitneyU test based responsivity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "source": [
    "use_exp = 'fixed'\n",
    "this_std = 8\n",
    "\n",
    "# load the used dataset from processing params\n",
    "used_activity_ds = processing_parameters.activity_datasets[0]\n",
    "print(used_activity_ds)\n",
    "\n",
    "if use_exp == 'free':\n",
    "    this_exp = exp_free\n",
    "else:\n",
    "    this_exp = exp_fixed\n",
    "\n",
    "this_tc = getattr(this_exp.visual_tcs, f'{used_activity_ds}_props')\n",
    "activity_df = this_exp.norm_deconv_fluor_viewed\n",
    "cells = [col for col in activity_df.columns if 'cell' in col]\n",
    "activity_df.reset_index(drop=True, inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "source": [
    "# --- 1. Calculate Responsivity --- #\n",
    "\n",
    "# -- 1.0 Get std of each cell across whole experiment\n",
    "std_activity = activity_df.loc[:, cells].apply(np.std)\n",
    "\n",
    "# -- 1.1 Get the std or cell response, and mean, max and AUC of response during trials\n",
    "trial_max_activity = (activity_df.loc[activity_df.trial_num > 0, :]\n",
    "                        .groupby(['trial_num', 'direction_wrapped', 'orientation'])[cells]\n",
    "                        .agg(np.max).copy().reset_index())\n",
    "trial_mean_activity = (activity_df.loc[activity_df.trial_num > 0, :]\n",
    "                        .groupby(['trial_num', 'direction_wrapped', 'orientation'])[cells]\n",
    "                        .agg(np.mean).copy().reset_index())\n",
    "trial_auc_activity = (activity_df.loc[activity_df.trial_num > 0, :]\n",
    "                        .groupby(['trial_num', 'direction_wrapped', 'orientation'])[cells]\n",
    "                        .agg(np.trapz).copy().reset_index())\n",
    "\n",
    "# -- 1.2 Get the std or cell response, and mean, max and AUC of response during ITI\n",
    "#    Parse the dataframe into trial frames, which are the trial + 1.5 sec of the preceding inter-trial interval\n",
    "#    This will be used for evaluating per-trial responsivity\n",
    "trial_frames_short_iti, _ = tuning.parse_trial_frames(activity_df, pre_trial=1.5)\n",
    "\n",
    "iti_std_activity = (trial_frames_short_iti.groupby('frame_num')\n",
    "                    .apply(lambda x: x.loc[x.trial_num == 0, cells].std())\n",
    "                    .reset_index(names='trial_num'))\n",
    "iti_std_activity.insert(1, 'direction_wrapped', trial_max_activity['direction_wrapped'])\n",
    "iti_std_activity.insert(2, 'orientation', trial_max_activity['orientation'])\n",
    "\n",
    "iti_mean_activity = (trial_frames_short_iti.groupby('frame_num')\n",
    "                        .apply(lambda x: x.loc[x.trial_num == 0, cells].mean())\n",
    "                        .reset_index(names='trial_num'))\n",
    "iti_mean_activity.insert(1, 'direction_wrapped', trial_max_activity['direction_wrapped'])\n",
    "iti_mean_activity.insert(2, 'orientation', trial_max_activity['orientation'])\n",
    "\n",
    "iti_max_activity = (trial_frames_short_iti.groupby('frame_num')\n",
    "                    .apply(lambda x: x.loc[x.trial_num == 0, cells].max())\n",
    "                    .reset_index(names='trial_num'))\n",
    "iti_max_activity.insert(1, 'direction_wrapped', trial_max_activity['direction_wrapped'])\n",
    "iti_max_activity.insert(2, 'orientation', trial_max_activity['orientation'])\n",
    "\n",
    "iti_auc_activity = (trial_frames_short_iti.groupby('frame_num')\n",
    "                    .apply(lambda x: x.loc[x.trial_num == 0, cells].apply(np.trapz))\n",
    "                    .reset_index(names='trial_num'))\n",
    "iti_auc_activity.insert(1, 'direction_wrapped', trial_max_activity['direction_wrapped'])\n",
    "iti_auc_activity.insert(2, 'orientation', trial_max_activity['orientation'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "source": [
    "vis_drive_test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "source": [
    "# -- 1.3 Responsivity Evaluations\n",
    "\n",
    "# 1.3.1 Determine if the cell is visually responsive.\n",
    "#    This is done by comparing the AUC activity during each 5 sec ITI to the AUC activity during the trial. If a\n",
    "#    cell passes a Mann-Whitney U test where the test checks if activity during the trials is greater than that\n",
    "#    during the ITI (i.e. alternative='greater'), then the cell is considered visually driven.\n",
    "trial_frames_long_iti, _ = tuning.parse_trial_frames(activity_df, pre_trial=5.0)\n",
    "long_iti_auc_activity = (trial_frames_long_iti.groupby('frame_num')\n",
    "                            .apply(lambda x: x.loc[x.trial_num == 0, cells]\n",
    "                            .apply(np.trapz))\n",
    "                            .reset_index(names='trial_num'))\n",
    "long_iti_auc_activity.insert(1, 'direction_wrapped', trial_max_activity['direction_wrapped'])\n",
    "long_iti_auc_activity.insert(2, 'orientation', trial_max_activity['orientation'])\n",
    "\n",
    "stats, pvals = mannwhitneyu(trial_auc_activity[cells], long_iti_auc_activity[cells],\n",
    "                            alternative='greater', axis=0)\n",
    "vis_drive_test = pd.DataFrame(index=cells, data={'statistic': stats, 'pvalue': pvals})\n",
    "\n",
    "p_cutoff = 0.25\n",
    "vis_drive_test['vis_resp'] = vis_drive_test.pvalue < p_cutoff\n",
    "vis_drive_test['not_vis_resp'] = vis_drive_test.pvalue > 1-p_cutoff\n",
    "vis_drive_test['mod_vis_resp'] = np.logical_and(vis_drive_test.pvalue >= p_cutoff, vis_drive_test.pvalue <= 1-p_cutoff)\n",
    "\n",
    "dir_sel = this_tc.fit_osi >= processing_parameters.selectivity_idx_cutoff\n",
    "ori_sel = this_tc.fit_dsi >= processing_parameters.selectivity_idx_cutoff\n",
    "\n",
    "vis_drive_test['vis_resp_dir_sel'] = np.logical_and(vis_drive_test.vis_resp, dir_sel)\n",
    "vis_drive_test['not_vis_resp_dir_sel'] = np.logical_and(vis_drive_test.not_vis_resp, dir_sel)\n",
    "vis_drive_test['mod_vis_resp_dir_sel'] = np.logical_and(vis_drive_test.mod_vis_resp, dir_sel)\n",
    "\n",
    "vis_drive_test['vis_resp_ori_sel'] = np.logical_and(vis_drive_test.vis_resp, ori_sel)\n",
    "vis_drive_test['not_vis_resp_ori_sel'] = np.logical_and(vis_drive_test.not_vis_resp, ori_sel)\n",
    "vis_drive_test['mod_vis_resp_ori_sel'] = np.logical_and(vis_drive_test.mod_vis_resp, ori_sel)\n",
    "\n",
    "vis_resp_cells = vis_drive_test.loc[vis_drive_test.vis_resp].index.to_list()\n",
    "not_vis_resp_cells = vis_drive_test.loc[vis_drive_test.not_vis_resp].index.to_list()\n",
    "mod_resp_cells = vis_drive_test.loc[vis_drive_test.mod_vis_resp].index.to_list()\n",
    "\n",
    "vis_resp_dir_sel_cells = vis_drive_test.loc[vis_drive_test.vis_resp_dir_sel].index.to_list()\n",
    "not_vis_resp_dir_sel_cells = vis_drive_test.loc[vis_drive_test.not_vis_resp_dir_sel].index.to_list()\n",
    "mod_resp_dir_sel_cells = vis_drive_test.loc[vis_drive_test.mod_vis_resp_dir_sel].index.to_list()\n",
    "\n",
    "vis_resp_ori_sel_cells = vis_drive_test.loc[vis_drive_test.vis_resp_ori_sel].index.to_list()\n",
    "not_vis_resp_ori_sel_cells = vis_drive_test.loc[vis_drive_test.not_vis_resp_ori_sel].index.to_list()\n",
    "mod_resp_ori_sel_cells = vis_drive_test.loc[vis_drive_test.mod_vis_resp_ori_sel].index.to_list()\n",
    "\n",
    "print(vis_drive_test.iloc[:, 2:].sum())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "source": [
    "fp.plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                          plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                          fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(vis_resp_dir_sel_cells, min(len(vis_resp_dir_sel_cells), 10), replace=False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "source": [
    "for i, cell in enumerate(vis_resp_dir_sel_cells):\n",
    "    fig = plt.figure(layout='constrained', figsize=(3/fp.constant_in2cm, 3/fp.constant_in2cm))\n",
    "\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(this_tc, cell, subfig=fig, tuning_kind='direction', \n",
    "                                              plot_selectivity=False, font_size='paper', plot_trials=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "source": [
    "fp.plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                          plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                          fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(not_vis_resp_dir_sel_cells, min(len(not_vis_resp_dir_sel_cells), 10), replace=False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "source": [
    "for i, cell in enumerate(not_vis_resp_dir_sel_cells):\n",
    "    fig = plt.figure(layout='constrained', figsize=(3/fp.constant_in2cm, 3/fp.constant_in2cm))\n",
    "\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(this_tc, cell, subfig=fig, tuning_kind='direction', \n",
    "                                              plot_selectivity=False, font_size='paper', plot_trials=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "source": [
    "fp.plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                          plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                          fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(mod_resp_dir_sel_cells, min(len(mod_resp_dir_sel_cells), 8), replace=False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "source": [
    "for i, cell in enumerate(mod_resp_dir_sel_cells):\n",
    "    fig = plt.figure(layout='constrained', figsize=(3/fp.constant_in2cm, 3/fp.constant_in2cm))\n",
    "\n",
    "    this_fig_axes = fp.plot_tuning_with_stats(this_tc, cell, subfig=fig, tuning_kind='direction', \n",
    "                                              plot_selectivity=False, font_size='paper', plot_trials=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fp.plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                          plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                          fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(vis_resp_cells, min(len(vis_resp_cells), 8), replace=False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fp.plot_dff_spikes_trials(this_exp, os.path.join(fig_path, '2_head_fixed_cells_traces_ethogram'), save=False,\n",
    "                          plot_spikes=False, plot_trials=True, plot_running=False, \n",
    "                          fig_width=15, fontsize='paper', cells_to_plot=np.random.choice(dir_resp_cells, min(len(dir_resp_cells), 8), replace=False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select cells with particular visual response properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def get_vis_tuned_cells(ds, vis_stim='dir', sel_thresh=0.3, drop_na=True):\n",
    "    data = ds.copy()\n",
    "\n",
    "    if (vis_stim == 'dir'):\n",
    "        # Cells cannot be both responsive to all visual stimuli and to directions\n",
    "        cells = data[(data['is_dir_responsive'] == 1) & (data['fit_dsi'] >= sel_thresh)]\n",
    "                    #   & (data['fit_osi'] < sel_thresh)] & (data['is_vis_responsive'] == 0)\n",
    "        return cells\n",
    "    \n",
    "    elif (vis_stim == 'ori'):\n",
    "        # Cells cannot be both responsive to all visual stimuli and to orientations\n",
    "        cells = data[(data['is_ori_responsive'] == 1) & (data['fit_osi'] >= sel_thresh)]\n",
    "            #   & (data['fit_dsi'] < sel_thresh)] & (data['is_vis_responsive'] == 0)\n",
    "        return cells\n",
    "\n",
    "    elif (vis_stim == 'vis'):\n",
    "        cells = data[(data['is_vis_responsive'] == 1) & (data['is_gen_responsive'] == 0)]\n",
    "        return cells\n",
    "    \n",
    "    elif (vis_stim == 'gen') :\n",
    "        cells = data[data['is_gen_responsive'] == 1]\n",
    "        return cells\n",
    "\n",
    "    else:\n",
    "        return Exception('Invalid vis_stim')\n",
    "\n",
    "\n",
    "def filter_vis_selectivity(fixed_exp_tcs, free_exp_tcs, matches, vis_stim, sel_thresh=0.3):\n",
    "\n",
    "    # Get the right columns\n",
    "    if vis_stim == 'dir':\n",
    "        sel_var = 'fit_dsi'\n",
    "        resp_test = 'is_dir_responsive'\n",
    "    elif vis_stim == 'ori':\n",
    "        sel_var = 'fit_osi'\n",
    "        resp_test = 'is_ori_responsive'\n",
    "    else:\n",
    "        raise ValueError('Invalid vis_stim')\n",
    "\n",
    "    # Find matched_cells\n",
    "    free_matched = free_exp_tcs.iloc[matches[:, 0], :]\n",
    "    fixed_matched = fixed_exp_tcs.iloc[matches[:, 1], :]\n",
    "\n",
    "    # Get the selectivity values from the matched cells\n",
    "    free = free_matched[sel_var].abs()\n",
    "    fixed = fixed_matched[sel_var].abs()\n",
    "    diff = free.values - fixed.values\n",
    "    sel_matched = pd.DataFrame({'fixed': fixed.values, 'free': free.values, 'diff': diff})\n",
    "\n",
    "    # Find matches where both are responsive\n",
    "    free_responsive = free_matched[resp_test].values\n",
    "    fixed_responsive = fixed_matched[resp_test].values\n",
    "    diff_resp = free_responsive - fixed_responsive\n",
    "    both_resp_idxs = np.argwhere(diff_resp == 0).flatten()\n",
    "    gained_resp_idx = np.argwhere(diff_resp == 1).flatten()\n",
    "    lost_resp_idx = np.argwhere(diff_resp == -1).flatten()\n",
    "\n",
    "    # find cells that maintained, gained, or lost selectivity\n",
    "    kept_sel = sel_matched[(sel_matched['fixed'] >= sel_thresh) & (sel_matched['free'] >= sel_thresh)]\n",
    "    strengthened_sel = sel_matched[(sel_matched['fixed'] >= sel_thresh) & (sel_matched['free'] >= sel_thresh) & (sel_matched['diff'] > 0.15)]\n",
    "    weakened_sel = sel_matched[(sel_matched['fixed'] >= sel_thresh) & (sel_matched['free'] >= sel_thresh) & (sel_matched['diff'] < -0.15)]\n",
    "    gained_sel = sel_matched[(sel_matched['fixed'] < sel_thresh) & (sel_matched['free'] >= sel_thresh)]\n",
    "    lost_sel = sel_matched[(sel_matched['fixed'] >= sel_thresh) & (sel_matched['free'] < sel_thresh)]\n",
    "\n",
    "    sel_matched['kept'] = sel_matched.index.isin(kept_sel.index)\n",
    "    sel_matched['lost'] = sel_matched.index.isin(lost_sel.index)\n",
    "    sel_matched['gained'] = sel_matched.index.isin(gained_sel.index)\n",
    "    sel_matched['strengthened'] = sel_matched.index.isin(strengthened_sel.index)\n",
    "    sel_matched['weakened'] = sel_matched.index.isin(weakened_sel.index)\n",
    "    \n",
    "    return sel_matched"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "free_tcs = getattr(exp_free.visual_tcs, f'{used_activity_ds}_props')\n",
    "fixed_tcs = getattr(exp_fixed.visual_tcs, f'{used_activity_ds}_props')\n",
    "\n",
    "# Cells that are generally responsive (but not specific for visual stimuli)\n",
    "free_gen_resp = get_vis_tuned_cells(free_tcs, vis_stim='gen', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "fixed_gen_resp = get_vis_tuned_cells(fixed_tcs, vis_stim='gen', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "# Cells that meet visual responsivity criteria\n",
    "free_vis_resp = get_vis_tuned_cells(free_tcs, vis_stim='vis', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "fixed_vis_resp = get_vis_tuned_cells(fixed_tcs, vis_stim='vis', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "# Cells that meet direction selectivity criteria\n",
    "free_dir_tuned = get_vis_tuned_cells(free_tcs, vis_stim='dir', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "fixed_dir_tuned = get_vis_tuned_cells(fixed_tcs, vis_stim='dir', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "# Cells that meet orientation selectivity criteria\n",
    "free_ori_tuned = get_vis_tuned_cells(free_tcs, vis_stim='ori', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "fixed_ori_tuned = get_vis_tuned_cells(fixed_tcs, vis_stim='ori', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "\n",
    "# Find cells that are both direction and orientation tuned, and figure out what to do with them.\n",
    "intersect, comm1, comm2 = np.intersect1d(free_dir_tuned.index, free_ori_tuned.index, return_indices=True)\n",
    "free_both_tuned = free_dir_tuned.iloc[comm1].copy()\n",
    "\n",
    "# Remove cells tuned to both from each category\n",
    "free_dir_tuned = free_dir_tuned.drop(free_dir_tuned.index[comm1])\n",
    "free_ori_tuned = free_ori_tuned.drop(free_ori_tuned.index[comm2])\n",
    "\n",
    "intersect, comm1, comm2 = np.intersect1d(fixed_dir_tuned.index, fixed_ori_tuned.index, return_indices=True)\n",
    "fixed_both_tuned = fixed_dir_tuned.iloc[comm1].copy()\n",
    "fixed_dir_tuned = fixed_dir_tuned.drop(fixed_dir_tuned.index[comm1])\n",
    "fixed_ori_tuned = fixed_ori_tuned.drop(fixed_ori_tuned.index[comm2])\n",
    "\n",
    "# Double check cells that are visually reposnsive, make sure that all are contained in the vis_resp\n",
    "free_resp_cells = np.unique(np.concatenate([free_dir_tuned.index, free_ori_tuned.index, free_both_tuned.index]))\n",
    "not_in_free_resp_cells = np.setdiff1d(free_vis_resp.index, free_resp_cells, assume_unique=True)\n",
    "free_vis_resp = pd.concat([free_vis_resp, free_tcs.loc[not_in_free_resp_cells, :]])\n",
    "free_vis_resp = free_vis_resp.reset_index().drop_duplicates(subset=['index'])\n",
    "\n",
    "fixed_resp_cells = np.unique(np.concatenate([fixed_dir_tuned.index, fixed_ori_tuned.index, fixed_both_tuned.index]))\n",
    "not_in_fixed_resp_cells = np.setdiff1d(fixed_vis_resp.index, fixed_resp_cells, assume_unique=True)\n",
    "fixed_vis_resp = pd.concat([fixed_vis_resp, fixed_tcs.loc[not_in_fixed_resp_cells, :]])\n",
    "fixed_vis_resp = fixed_vis_resp.reset_index().drop_duplicates(subset=['index'])\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(free_dir_tuned.index.to_list(), free_ori_tuned.index.to_list())\n",
    "print(fixed_dir_tuned.index.to_list(), fixed_ori_tuned.index.to_list())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# For thesis\n",
    "# final_idxs = [4, 11, 12, 21, 27, 36, 39, 19]\n",
    "# free ['cell_0013', 'cell_0026', 'cell_0027', 'cell_0049', 'cell_0075', 'cell_0119', 'cell_0133', 'cell_0045']\n",
    "# fixed ['cell_0014', 'cell_0036', 'cell_0039', 'cell_0054', 'cell_0092', 'cell_0128', 'cell_0141', 'cell_0061']\n",
    "\n",
    "num_matches = min(day_mouse_curated_matches.shape[0], 8)\n",
    "\n",
    "ori_matched = filter_vis_selectivity(fixed_tcs, free_tcs, day_mouse_curated_matches, 'ori', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "dir_matched = filter_vis_selectivity(fixed_tcs, free_tcs, day_mouse_curated_matches, 'dir', sel_thresh=processing_parameters.selectivity_idx_cutoff)\n",
    "\n",
    "ori_kept = ori_matched[ori_matched['kept']].index.values\n",
    "ori_gained = ori_matched[ori_matched['gained']].index.values\n",
    "ori_lost = ori_matched[ori_matched['lost']].index.values\n",
    "ori_strong = ori_matched[ori_matched['strengthened']].index.values\n",
    "ori_weak = ori_matched[ori_matched['weakened']].index.values\n",
    "\n",
    "dir_kept = dir_matched[dir_matched['kept']].index.values\n",
    "dir_gained = dir_matched[dir_matched['gained']].index.values\n",
    "dir_lost = dir_matched[dir_matched['lost']].index.values\n",
    "dir_strong = dir_matched[dir_matched['strengthened']].index.values\n",
    "dir_weak = dir_matched[dir_matched['weakened']].index.values\n",
    "\n",
    "# Choose cells somewhat at random for the thesis: want 8 in total, one from each category + 2 random\n",
    "chosen_idxs = []\n",
    "for arr in [ori_kept, ori_lost, ori_gained, ori_strong, ori_weak, dir_kept, dir_lost, dir_gained, dir_strong, dir_weak]:\n",
    "    if arr.size > 0:\n",
    "        chosen_idxs.append(np.random.choice(arr, 1)[0])\n",
    "\n",
    "# Enforce no repeats\n",
    "chosen_idxs = np.unique(chosen_idxs)\n",
    "\n",
    "# randomly choose 2 more cells from those remaining\n",
    "remaining_idxs = np.setdiff1d(np.arange(len(day_mouse_curated_matches)), chosen_idxs)\n",
    "random_idxs = np.random.choice(remaining_idxs, num_matches - len(chosen_idxs), replace=False)\n",
    "final_idxs = np.concatenate([chosen_idxs, random_idxs]).astype(int)\n",
    "\n",
    "# enforce no repeats\n",
    "# final_idxs = np.unique(final_idxs)\n",
    "\n",
    "# final_idxs = [4, 11, 12, 21, 27, 36, 39, 19]\n",
    "final_cells = day_mouse_curated_matches[final_idxs, :]\n",
    "\n",
    "exp_free.cells_to_match = [f'cell_{id:04d}' for id in final_cells[:, 0]]\n",
    "exp_fixed.cells_to_match = [f'cell_{id:04d}' for id in final_cells[:, 1]]\n",
    "print(final_idxs)\n",
    "print(exp_free.cells_to_match)\n",
    "print(exp_fixed.cells_to_match)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prey_capture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
