{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b9a88a",
   "metadata": {},
   "source": [
    "# TO DO \n",
    "- [x] Responsivity - bootstrap for metric\n",
    "- [ ] Mean spike rate per trial\n",
    "- [x] Tuning Width\n",
    "- [x] Tuning Peak\n",
    "- [x] Smooth tuning curves\n",
    "- [ ] Running vs not\n",
    "\n",
    "Notes:\n",
    "- [x] Distribution-based metrics of responsivity (bootstrapping, etc) over arbitrary values (Baden 2016 style)\n",
    "- [ ] Population measures\n",
    "    - [ ] distribution of widths/prefs\n",
    "    - [ ] pop. vector decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82e766",
   "metadata": {
    "editable": true,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "import datashader as dshade\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import importlib\n",
    "import datetime\n",
    "import warnings\n",
    "import math\n",
    "import cmath\n",
    "import pycircstat as circ\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pprint import pprint\n",
    "from itertools import zip_longest\n",
    "from scipy.stats import sem, norm, binned_statistic, percentileofscore, ttest_1samp, ttest_ind\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.io import export_svgs, export_png\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation import histogram\n",
    "from holoviews.operation.datashader import datashade, shade\n",
    "hv.extension('bokeh')\n",
    "# hv.extension('matplotlib')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "%aimport paths\n",
    "import processing_parameters\n",
    "import functions_bondjango as bd\n",
    "import functions_plotting as fp\n",
    "import functions_data_handling as fdh\n",
    "import functions_kinematic as fk\n",
    "\n",
    "importlib.reload(fp)\n",
    "# set up the figure theme\n",
    "fp.set_theme()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f43a3f4d-01cf-43f5-9717-14c132a5adf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912b9bf-214e-4673-a438-4bd47e4c92f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ee3b2",
   "metadata": {
    "code_folding": [
     0,
     22,
     28
    ],
    "init_cell": true
   },
   "source": [
    "def normalize_rows(data_in):\n",
    "    \n",
    "    for idx, el in enumerate(data_in):\n",
    "        data_in[idx, :] = (el-np.nanmin(el))/(np.nanmax(el)-np.nanmin(el))\n",
    "    return data_in\n",
    "\n",
    "def normalize(data_in):\n",
    "    return (data_in - np.nanmin(data_in)) / (np.nanmax(data_in) - np.nanmin(data_in))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9b515d29-d5bb-4ace-b788-a10b0feb3fcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gaussian Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7cb91-4d30-4b79-a32f-9e2ac9353a95",
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     13,
     17,
     20,
     23
    ],
    "init_cell": true,
    "tags": []
   },
   "source": [
    "import functions_tuning as tuning"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d9bc8ca7-fe16-436e-886d-8ee08bcbb987",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a01217-8fdb-43a1-8392-556b7cc26e75",
   "metadata": {
    "code_folding": [
     0,
     9
    ],
    "init_cell": true
   },
   "source": [
    "def spike_raster(data, cells=None):\n",
    "        if cells is None:\n",
    "            cells = [el for el in data.columns if 'cell' in el]\n",
    "    \n",
    "        spikes = data.loc[:, cells]\n",
    "    \n",
    "        im = hv.Image((data.time_vector, np.arange(len(cells)), spikes.values.T), \n",
    "                        kdims=['Time (s)', 'Cells'], vdims=['Activity (a.u.)'])\n",
    "        im.opts(width=600) #, cmap='Purples')\n",
    "        return im\n",
    "    \n",
    "def trace_raster(data, cells=None, ds_factor=1):\n",
    "    if cells is None:\n",
    "        cells = [el for el in data.columns if 'cell' in el]\n",
    "\n",
    "    trace = data.loc[:, cells]\n",
    "    max_std = trace.std().max()\n",
    "\n",
    "    lines = {i: hv.Curve((data.time_vector, trace.iloc[:, i].values.T + i*max_std)) for i in np.arange(len(cells))}\n",
    "    lineoverlay = hv.NdOverlay(lines, kdims=['Time (s)']).opts(height=500, width=800)\n",
    "    return lineoverlay\n",
    "\n",
    "\n",
    "def plot_tuning_curve(tuning_curve, **kwargs):\n",
    "    plt.plot(*tuning_curve)\n",
    "    \n",
    "    if \"fit\" in kwargs:\n",
    "        plt.plot(*kwargs['fit'])\n",
    "        \n",
    "    if \"pref_angle\" in kwargs:\n",
    "        plt.axvline(kwargs['pref_angle'], color='k', linewidth=1)\n",
    "        \n",
    "def plot_tuning_curve_hv(tuning_curve, fit=None, sem=None, trials=None, pref_angle=None, **kwargs):\n",
    "    overlay = []\n",
    "    \n",
    "    tuning = hv.Curve(tuning_curve).opts(width=600, height=300, **kwargs)\n",
    "    overlay.append(tuning)\n",
    "    \n",
    "    if fit is not None:\n",
    "        fit_plot = hv.Curve(fit)\n",
    "        overlay.append(fit_plot)\n",
    "        \n",
    "    if sem is not None:\n",
    "        sem_plot = hv.Spread((*tuning_curve, sem)).opts(fill_alpha=0.25)\n",
    "        overlay.append(sem_plot)\n",
    "        \n",
    "    if trials is not None:\n",
    "        trials_plot = hv.Scatter(trials).opts(color='r', size=3)\n",
    "        overlay.append(trials_plot)\n",
    "        \n",
    "    if pref_angle is not None:\n",
    "        pref_plot = hv.VLine(pref_angle).opts(color='k', line_width=1)\n",
    "        overlay.append(pref_plot)\n",
    "                  \n",
    "    return hv.Overlay(overlay)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0c27b5a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf77fe8",
   "metadata": {
    "init_cell": true,
    "tags": []
   },
   "source": [
    "importlib.reload(processing_parameters)\n",
    "\n",
    "# get the search string\n",
    "search_string = processing_parameters.search_string + r\", analysis_type:preprocessing\"\n",
    "\n",
    "# get the paths from the database\n",
    "file_path, paths_all, parsed_query, date_list, animal_list = fdh.fetch_preprocessing(search_string)\n",
    "\n",
    "animal_idxs = [i for i,d in enumerate(animal_list) if d==parsed_query['mouse'].lower()]\n",
    "good_entries = [file_path[index] for index in animal_idxs]\n",
    "input_path = [paths_all[index] for index in animal_idxs]\n",
    "\n",
    "# # assemble the output path\n",
    "print(input_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab690e3-6fff-4f20-9440-e32bfe0d7dc6",
   "metadata": {},
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "class Cell():\n",
    "    def __init__(self, name):\n",
    "        self.id = name\n",
    "\n",
    "class WirefreeExperiment():\n",
    "    def __init__(self, filepath, use_xarray=False):\n",
    "        # Experiment attributes\n",
    "        self.animal = None\n",
    "        self.rig = None\n",
    "        self.exp_type = None\n",
    "        self.exp_date = None\n",
    "        self.exp_params = None\n",
    "\n",
    "        # Experimental metadata\n",
    "        self.cell_matches = None\n",
    "        self.arena_corners = None\n",
    "        \n",
    "        self.roi_info = None\n",
    "        self.trial_set = None\n",
    "        self.full_kinematics = None\n",
    "\n",
    "        # Neural and kinematic data structures\n",
    "        self.kinematics = None\n",
    "        self.raw_spikes = None\n",
    "        self.raw_fluor = None\n",
    "\n",
    "        # Load the data\n",
    "        self._load_hdf(filepath, use_xarray)\n",
    "        self.cells = [el for el in self.raw_spikes.columns if \"cell\" in el]\n",
    "        self._create_cell_class()\n",
    "\n",
    "\n",
    "    def _load_hdf(self, file, use_xarray):\n",
    "        with pd.HDFStore(file) as h:\n",
    "\n",
    "                self._parse_params(h['params'])\n",
    "                self._add_orientation_to_params()\n",
    "            \n",
    "                self._parse_kinematic_data(h['matched_calcium'], use_xarray)\n",
    "\n",
    "                if use_xarray:\n",
    "                    self.full_kinematics = h['full_traces'].to_xarray()\n",
    "                else:\n",
    "                    self.full_kinematics = h['full_traces']\n",
    "\n",
    "                self.roi_info = h['roi_info']\n",
    "                self.trial_set = h['trial_set']\n",
    "                self.cell_matches = h['cell_matches']\n",
    "                self.arena_corners = h['arena_corners']\n",
    "\n",
    "    def _parse_kinematic_data(self, matched_calcium, use_xarray):\n",
    "\n",
    "        # Calculate orientation expicitly\n",
    "        if 'orientation' not in matched_calcium.columns:\n",
    "            matched_calcium['orientation'] = matched_calcium['direction']\n",
    "            matched_calcium['orientation'][(matched_calcium['orientation'] > -180) & (matched_calcium['orientation'] < 0)] += 180\n",
    "           \n",
    "        # For all data\n",
    "        self.rig = matched_calcium['mouse'].values[0].split('_', 1)[0]\n",
    "        if self.rig in ['VWheel', 'VWheelWF']:\n",
    "            self.exp_type = 'fixed'\n",
    "        else:\n",
    "            self.exp_type = 'free'\n",
    "        \n",
    "        self.animal = matched_calcium['mouse'].values[0].split('_', 1)[1:]\n",
    "        self.exp_date = matched_calcium['datetime'][0]\n",
    "        spikes_cols = [key for key in matched_calcium.keys() if 'spikes' in key]\n",
    "        fluor_cols = [key for key in matched_calcium.keys() if 'fluor' in key]\n",
    "        motive_tracking_cols = ['mouse_y_m','mouse_z_m','mouse_x_m','mouse_yrot_m','mouse_zrot_m','mouse_xrot_m']\n",
    "\n",
    "\n",
    "        # If there is more than one spatial or temporal frequency, include it, othewise don't\n",
    "        stimulus_cols = ['trial_num', 'time_vector', 'direction', 'orientation', 'grating_phase',]\n",
    "        if len(self.exp_params['temporal_freq']) > 1:\n",
    "            stimulus_cols.append('temporal_freq')\n",
    "        if len(self.exp_params['spatial_freq']) > 1:\n",
    "            stimulus_cols.append('spatial_freq')\n",
    "        \n",
    "        # For headfixed data\n",
    "        eye_cols = ['eye_horizontal_vector_x', 'eye_horizontal_vector_y', 'eye_midpoint_x', 'eye_midpoint_y', 'pupil_center_ref_x', 'pupil_center_ref_y', 'fit_pupil_center_x', 'fit_pupil_center_y',\n",
    "                       'pupil_diameter', 'minor_axis', 'pupil_rotation', 'eyelid_angle']\n",
    "        eye_dlc_cols = ['pupil_center_x','pupil_center_y','pupil_top_left_x','pupil_top_left_y','pupil_top_x','pupil_top_y','pupil_top_right_x','pupil_top_right_y' 'pupil_right_x' 'pupil_right_y', \n",
    "                           'pupil_bottom_right_x','pupil_bottom_right_y','pupil_bottom_x','pupil_bottom_y','pupil_bottom_left_x','pupil_bottom_left_y','pupil_left_x','pupil_left_y','eye_corner_nasal_x',\n",
    "                           'eye_corner_nasal_y','eye_corner_temporal_x','eye_corner_temporal_y','eyelid_top_x','eyelid_top_y','eyelid_bottom_x','eyelid_bottom_y','led_x','led_y']\n",
    "        wheel_cols = ['wheel_speed', 'wheel_acceleration']\n",
    "        \n",
    "        # For free data\n",
    "        mouse_kinem_cols = ['mouse_heading', 'mouse_angular_speed', 'mouse_speed', 'mouse_acceleration', 'head_direction', 'head_height']\n",
    "        mouse_dlc_cols = ['mouse_snout_x', 'mouse_snout_y', 'mouse_barl_x', 'mouse_barl_y', 'mouse_barr_x', 'mouse_barr_y', 'mouse_x', 'mouse_y', 'mouse_body2_x', 'mouse_body2_y', \n",
    "                          'mouse_body3_x', 'mouse_body3_y', 'mouse_base_x', 'mouse_base_y', 'mouse_head_x', 'mouse_head_y', 'miniscope_top_x', 'miniscope_top_y']\n",
    "\n",
    "        if self.exp_type == 'fixed':\n",
    "            self.kinematics = matched_calcium.loc[:, stimulus_cols + motive_tracking_cols + eye_cols + wheel_cols]\n",
    "        else:\n",
    "            self.kinematics = matched_calcium.loc[:, stimulus_cols + motive_tracking_cols + mouse_kinem_cols]\n",
    "            \n",
    "        self.raw_spikes = matched_calcium.loc[:, stimulus_cols + spikes_cols]\n",
    "        self.raw_spikes.columns = [key.rsplit('_', 1)[0] if 'spikes' in key else key for key in self.raw_spikes.columns]\n",
    "        self.raw_fluor = matched_calcium.loc[:, stimulus_cols + fluor_cols]\n",
    "        self.raw_fluor.columns = [key.rsplit('_', 1)[0] if 'fluor' in key else key for key in self.raw_fluor.columns]\n",
    "\n",
    "        if use_xarray:\n",
    "            self.kinematics = self.kinematics.to_xarray()\n",
    "            self.raw_spikes = self.raw_spikes.to_xarray()\n",
    "            self.raw_fluor = self.raw_fluor.to_xarray()\n",
    "\n",
    "    def _parse_params(self, df):\n",
    "        params = df.to_dict('list')\n",
    "        for key in params.keys():\n",
    "            try:\n",
    "                params[key] = np.array(literal_eval(params[key][0]))\n",
    "            except:\n",
    "                params[key] = params[key][0]\n",
    "        \n",
    "        self.exp_params = params\n",
    "\n",
    "    def _add_orientation_to_params(self):\n",
    "        self.exp_params['direction'].sort()\n",
    "        self.exp_params['orientation'] = self.exp_params['direction'].copy()\n",
    "        self.exp_params['orientation'][self.exp_params['orientation'] < 0] += 180\n",
    "        self.exp_params['orientation'].sort()\n",
    "\n",
    "        # Add wrapped directions, useful for plotting\n",
    "        directions_wrapped = np.sort(fk.wrap(self.exp_params['direction']))\n",
    "        directions_wrapped = np.concatenate((directions_wrapped, [360.]))\n",
    "        self.exp_params['directions_wrapped'] = directions_wrapped\n",
    "\n",
    "    def _create_cell_class(self):\n",
    "        self.cell_props_spikes = {}\n",
    "    \n",
    "        for cell in self.cells:\n",
    "            self.cell_props_spikes[cell] = Cell(cell)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8276e6",
   "metadata": {
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "fixed = WirefreeExperiment(input_path[0], use_xarray=False)\n",
    "free = WirefreeExperiment(input_path[1], use_xarray=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cde5cf1a-eb3d-4529-94a3-a46a5998070a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remove baselines from the data for later processing\n",
    "Also normalize inferred spike responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03539b",
   "metadata": {},
   "source": [
    "def normalize_spike_responses(ds, quantile=0.07):\n",
    "    ds_norm = ds.fillna(0)\n",
    "    \n",
    "    # get the number of cells\n",
    "    if type(ds) is pd.DataFrame:\n",
    "        cells = [el for el in ds.columns if \"cell\" in el]\n",
    "        # Normalize cell responses across all sessions\n",
    "        ds_norm[cells].apply(normalize)\n",
    "    \n",
    "        # Get the 7th percentile of activity per cell for each stimulus\n",
    "        # Try 7th/8th percentile\n",
    "        percentiles = ds_norm.groupby(['direction'])[cells].quantile(quantile)\n",
    "    \n",
    "        # get the baselines - The first row is the inter-trial interval\n",
    "        baselines = percentiles.iloc[0, :]\n",
    "    \n",
    "        # Subtract baseline from everything\n",
    "        ds_norm[cells].subtract(baselines, axis=1)\n",
    "\n",
    "    elif type(ds) == xr.Dataset:\n",
    "        cells = [el for el in ds.data_vars if \"cell\" in el]\n",
    "    \n",
    "\n",
    "    return ds_norm"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533535d5-12c4-4de8-a99e-063160b3bef0",
   "metadata": {},
   "source": [
    "free.norm_spikes = normalize_spike_responses(free.raw_spikes)\n",
    "fixed.norm_spikes = normalize_spike_responses(fixed.raw_spikes)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "57719c37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Extract matched cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c1d3f",
   "metadata": {},
   "source": [
    "matched_data = []\n",
    "unmatched_data = []\n",
    "remap_dict = []\n",
    "for i, ds in enumerate(data):\n",
    "    cells = np.array([el for el in ds.columns if \"cell\" in el])\n",
    "    cell_nums = np.unique([int(cell.split(\"_\")[1])  for cell in cells])\n",
    "    \n",
    "    keep = np.in1d(cell_nums, cell_matches.iloc[:, i])\n",
    "    match_cells = cells[np.argwhere(keep)].flatten()\n",
    "    unmatch_cells = cells[np.argwhere(~keep)].flatten()\n",
    "    \n",
    "    matched_ds = ds.drop(unmatch_cells, axis=\"columns\")\n",
    "    matched_data.append(matched_ds)\n",
    "    \n",
    "    unmatched_ds = ds.drop(match_cells, axis=\"columns\")\n",
    "    unmatched_data.append(unmatched_ds)\n",
    "\n",
    "old_name_0 = []\n",
    "old_name_1 = []\n",
    "rename_0 = []\n",
    "rename_1 = []\n",
    "for i, match_pair in enumerate(cell_matches.values):\n",
    "    new_number = f'{i:04}'\n",
    "    cells_0 = [el for el in matched_data[0].columns if f\"cell_{match_pair[0]:04}\" in el]\n",
    "    old_name_0.extend(cells_0)\n",
    "    cells_1 = [el for el in matched_data[1].columns if f\"cell_{match_pair[1]:04}\" in el]\n",
    "    old_name_1.extend(cells_1)\n",
    "    \n",
    "    new_cells_0 = [el.replace(f\"{match_pair[0]:04}\", new_number) for el in cells_0]\n",
    "    rename_0.extend(new_cells_0)\n",
    "    new_cells_1 = [el.replace(f\"{match_pair[1]:04}\", new_number) for el in cells_1]\n",
    "    rename_1.extend(new_cells_1)\n",
    "    \n",
    "rename_dict_0 = dict(zip(old_name_0, rename_0)) \n",
    "rename_dict_1 = dict(zip(old_name_1, rename_1)) \n",
    "\n",
    "matched_data[0].rename(columns=rename_dict_0, inplace=True)\n",
    "matched_data[1].rename(columns=rename_dict_1, inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f7b2ffa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Determine responsivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69be7be",
   "metadata": {},
   "source": [
    "ds = matched_data[0]\n",
    "# get the number of cells\n",
    "cell_spikes = [el for el in ds.columns if 'spikes' in el]\n",
    "\n",
    "# Get response per trial for each cell\n",
    "for cell in cell_spikes:\n",
    "    trial_responses = ds[ds.trial_num >= 1].groupby(['trial_num'])[cell].mean().to_numpy()\n",
    "    isi_responses = ds[ds.trial_num == 0][cell].mean()\n",
    "#     isi_responses = np.ones(trial_responses.shape) * isi_responses\n",
    "    \n",
    "    ttest = ttest_ind(isi_responses, trial_responses)\n",
    "\n",
    "# trial_start = ds[ds.trial_num >= 1].groupby(['trial_num']).time_vector.nth(0)\n",
    "# trial_end = ds[ds.trial_num >= 1].groupby(['trial_num']).time_vector.nth(-2)\n",
    "# trial_times = np.array((trial_start, trial_end)).T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40aa12a",
   "metadata": {},
   "source": [
    "isi_responses"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "63181c7a-85cd-4ef8-8d61-f6638f4f0314",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Some simple exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f067a",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "## Plot activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f4c58",
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Inferred spikes\n",
    "spike_plots = [trace_raster(free.norm_spikes), trace_raster(fixed.norm_spikes)]\n",
    "hv.Layout(spike_plots).cols(2).opts(shared_axes=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25892929-5790-4205-bc15-5b3f9162b405",
   "metadata": {},
   "source": [
    "# allocate memory for the plots\n",
    "fluor_plots = [trace_raster(free.raw_fluor), trace_raster(fixed.raw_fluor)]\n",
    "hv.Layout(fluor_plots).cols(2).opts(shared_axes=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054772f4",
   "metadata": {},
   "source": [
    "# average across repeats and time\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "328ccd7d",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "## Visualize the activity for all units during the inter-trial interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274d528",
   "metadata": {
    "hidden": true
   },
   "source": [
    "free_iti = free.norm_spikes.loc[free.norm_spikes['trial_num'] == 0, ['time_vector'] + free.cells].reset_index(drop=True)\n",
    "trace_raster(free_iti).opts(ylabel=\"Cells\", width=900, height=500)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a000f5-86a9-40a1-9f2f-fa552991cd04",
   "metadata": {},
   "source": [
    "fixed_iti = fixed.norm_spikes.loc[fixed.norm_spikes['trial_num'] == 0, ['time_vector'] + fixed.cells].reset_index(drop=True)\n",
    "trace_raster(fixed_iti).opts(ylabel=\"Cells\", width=900, height=500)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7cbfa3e5-14d4-4c67-a2a1-1c18dcd708b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot the activity of each cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050fc45-abb0-40b4-b08d-cc7262518900",
   "metadata": {},
   "source": [
    "direction_plots = []\n",
    "for cell in free.cells[:2]:\n",
    "    for direction in free.exp_params['direction']:\n",
    "        individual_responses = free.norm_spikes.groupby(['trial_num'])[cell].agg(list)\n",
    "        resp_array = np.array(list(zip_longest(*individual_responses, fillvalue=np.NaN))).T\n",
    "        current_direction = np.nanmean(resp_array, axis=0)\n",
    "        current_sem = sem(resp_array, axis=0, nan_policy='omit')\n",
    "\n",
    "        x = np.arange(resp_array.shape[-1])\n",
    "        plot = hv.Curve(current_direction).opts(ylabel=str(direction), xlabel=\"time\")\n",
    "        plot2 = hv.Spread((x, current_direction, current_sem))\n",
    "        plot.opts(xrotation=45)\n",
    "        direction_plots.append(plot*plot2)\n",
    "\n",
    "hv.Layout(direction_plots).opts(shared_axes=False).cols(len(free.exp_params['direction']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b8f0d1c8",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot direction selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7199406",
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "source": [
    "def plot_trial_responses(ds, key, cells=None):\n",
    "    # allocate memory for the cell plots\n",
    "    cell_plots = []\n",
    "\n",
    "    if cells is None:\n",
    "        cells = [el for el in data.columns if 'cell' in el]\n",
    "    num_cells = len(cells)\n",
    "    \n",
    "    tuning = ds.groupby([key])[cells].mean()\n",
    "    tuning_sem = ds.groupby([key])[cells].sem()\n",
    "    percentiles = ds.groupby([key])[cells].quantile(0.07)\n",
    "\n",
    "    # get the baselines - The first column is the inter-trial interval\n",
    "    baselines = percentiles.iloc[0, percentiles.columns.get_loc(cells[0]):percentiles.columns.get_loc(cells[-1])+1]\n",
    "\n",
    "    # Subtract baseline from everything\n",
    "    ds[cells].subtract(baselines, axis=1)\n",
    "    \n",
    "    # Get the mean reponse on each trial\n",
    "    trial_responses = ds.groupby([key, 'trial_num'])[cells].agg(np.nanmean)\n",
    "    # Drop the trial number level and regroup by orientation\n",
    "    trial_responses = trial_responses.droplevel(['trial_num']).groupby([key]).agg(list)\n",
    "    \n",
    "    for cell in cells:\n",
    "        \n",
    "        # get the current cell dActivity and sem\n",
    "        current_cell = tuning.iloc[1:, tuning.columns.get_loc(cell)]\n",
    "        current_sem = tuning_sem.iloc[1:, tuning_sem.columns.get_loc(cell)]\n",
    "        \n",
    "        # get the current cell dActivity\n",
    "        current_cell_trials = trial_responses.iloc[1:, trial_responses.columns.get_loc(cell)].to_list()\n",
    "        current_cell_trials = list_lists_to_array(current_cell_trials)\n",
    "\n",
    "        # get the orientation or direction\n",
    "        label = current_cell.index.to_numpy()\n",
    "        label_by_observation = np.multiply(np.ones(current_cell_trials.shape), label[:, np.newaxis])\n",
    "        \n",
    "        # Create a 2D array of positions and values for scatter plot\n",
    "        X = np.vstack((np.ravel(label_by_observation), np.ravel(current_cell_trials))).T\n",
    "\n",
    "        # plot\n",
    "        if key == 'direction':\n",
    "            x_lim = (-180, 180)\n",
    "        else:\n",
    "            x_lim= (0, 180)\n",
    "            \n",
    "        plot_scatter = hv.Scatter(X).opts(color='r', size=3, xlabel=key, xlim=x_lim, xrotation=45)\n",
    "        plot_mean = hv.Curve((label, current_cell))\n",
    "        plot_sem = hv.Spread((label, current_cell.values, current_sem))\n",
    "        cell_plots.append(plot_scatter*plot_mean*plot_sem)\n",
    "        \n",
    "    return cell_plots"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4506e",
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# allocate memory for the cell plots\n",
    "cell_plots = []\n",
    "\n",
    "# for all the files\n",
    "for ds in matched_data:\n",
    "    ds_plots = plot_trial_responses(ds, 'direction')\n",
    "    cell_plots.append(ds_plots)\n",
    "        \n",
    "num_cells = len(cell_plots[0])\n",
    "cell_plots = sum(cell_plots, [])\n",
    "hv.Layout(cell_plots).opts(shared_axes=False).cols(num_cells)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5d096013",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot orientation selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6b09b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# allocate memory for the cell plots\n",
    "cell_plots = []\n",
    "\n",
    "# for all the files\n",
    "for ds in matched_data:\n",
    "    ds_plots = plot_trial_responses(ds, 'orientation')\n",
    "    cell_plots.append(ds_plots)\n",
    "        \n",
    "num_cells = len(cell_plots[0])\n",
    "cell_plots = sum(cell_plots, [])\n",
    "hv.Layout(cell_plots).opts(shared_axes=False).cols(num_cells)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dc87c55d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SVD tuning analysis (Baden et al 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aad7bf-ff24-45e7-b55b-906f900e6b9a",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "## SVD Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849d05c-c8cd-4684-a0ea-49cee7355ef0",
   "metadata": {
    "code_folding": [
     0,
     6,
     14,
     47,
     78
    ],
    "hidden": true
   },
   "source": [
    "def map_binned_statistic(x, statistic=np.nanmean):\n",
    "    vals_to_be_binned = np.array(x)\n",
    "    x_array = np.arange(0, len(vals_to_be_binned))\n",
    "    bin_means, bin_edges, bin_numbers = binned_statistic(x_array, vals_to_be_binned, statistic=statistic, bins=25)\n",
    "    return bin_means\n",
    "\n",
    "def mean_histogram(x):\n",
    "    hists = np.array(x)\n",
    "    hist_mean = np.mean(hists, axis=0)\n",
    "    \n",
    "    # Normalize mean\n",
    "    hist_mean = hist_mean / np.nanmax(hist_mean)\n",
    "    return hist_mean\n",
    "\n",
    "\n",
    "def generate_mean_response_matrix(cell_responses, tuning_kind):\n",
    "    agg_current_cell = cell_responses.groupby([tuning_kind]).agg(lambda x: [h for h in x])\n",
    "\n",
    "    # Take the mean across binned trials\n",
    "    current_cell_mean_resp = agg_current_cell.apply(mean_histogram)\n",
    "    \n",
    "    # Get the sem across binned trials\n",
    "    agg_current_cell.apply(mean_histogram)\n",
    "\n",
    "    # Get a list of directions/orientations\n",
    "    angles = current_cell_mean_resp.index.to_numpy()\n",
    "\n",
    "    # Wrap angles from [-180, 180] to [0, 360] for direction tuning, and sort angles\n",
    "    # Needed for pycircstat toolbox\n",
    "    angles_wrapped = fk.wrap(angles)\n",
    "    sort_idx = np.argsort(angles_wrapped)\n",
    "    angles_sorted = angles_wrapped[sort_idx]\n",
    "\n",
    "    # Create the response matrix (direction x time response)\n",
    "    response_mat = np.vstack(current_cell_mean_resp.values)\n",
    "\n",
    "    # Sorted to match sorted angles\n",
    "    sorted_response_mat = response_mat[sort_idx, :]\n",
    "\n",
    "    # Make sure to explicitly represent 360 degrees in the data if looking at direction tuning. \n",
    "    # This is done by duplicating the 0 degrees trace\n",
    "    if tuning_kind == 'direction':\n",
    "        idx_0 = np.argwhere(angles_sorted == 0)[0][0]\n",
    "        trace_360 = sorted_response_mat[idx_0, :]\n",
    "        angles_sorted = np.append(angles_sorted, 360.)\n",
    "        sorted_response_mat = np.append(sorted_response_mat, [trace_360], axis=0)\n",
    "\n",
    "    # Get into time, direction format\n",
    "    response_mat = sorted_response_mat.T\n",
    "    \n",
    "    return response_mat, angles_sorted\n",
    "\n",
    "def svd_selectivity_idx(response_mat, angles, tuning_kind, verbose=False):\n",
    "    # Note the @ is matrix multiplication in Python 3.x\n",
    "    \n",
    "    # Zero out nans so that the SVD converges\n",
    "    response_mat = np.nan_to_num(response_mat, nan=0.0)\n",
    "    \n",
    "    # Do SVD. Note that in numpy's implementation, V is already transposed, \n",
    "    # so M ~ U @ np.diag(S) @ V \n",
    "    U, S, V = np.linalg.svd(response_mat, full_matrices=False)\n",
    "\n",
    "    # Some sanity checks\n",
    "    if verbose:\n",
    "        print(f'Dimensions of U: {U.shape}, S: {S.shape}, V: {V.shape}')\n",
    "        print(f'Is the SVD approximation close? {np.allclose(response_mat, U @ np.diag(S) @ V)}')\n",
    "\n",
    "    # Compute direction/orientation selectivity and DSi/OSi\n",
    "    tuning_curve = V.T[:, 1] # Transpose V because of numpy svd convention\n",
    "    temporal_component = U[:, 1]\n",
    "\n",
    "    if tuning_kind == 'direction':\n",
    "        im_exp = 1j\n",
    "    else:\n",
    "        im_exp = 2j\n",
    "\n",
    "    phi = np.exp(im_exp * np.deg2rad(angles))\n",
    "    phi = np.expand_dims(phi, axis=-1)\n",
    "    K = phi.T @ tuning_curve\n",
    "    selectivity_idx = np.absolute(K)\n",
    "    \n",
    "    return selectivity_idx, tuning_curve, temporal_component\n",
    "\n",
    "def bootstrap_svd_selectivity(trial_responses, tuning_kind, num_shuffles=1000):\n",
    "    \n",
    "    trial_idxs = trial_responses.index.to_numpy()\n",
    "    shuffled_selectivity_idxs = []\n",
    "\n",
    "    for i in range(0, num_shuffles):\n",
    "        # Shuffle stimulus labels and reassign\n",
    "        np.random.shuffle(trial_idxs)\n",
    "        shuffled_responses = trial_responses.copy().reindex(trial_idxs)\n",
    "\n",
    "        # Generate normalized mean response matrix\n",
    "        response_mat, angles_sorted = generate_mean_response_matrix(shuffled_responses, tuning_kind)\n",
    "\n",
    "        # Do SVD\n",
    "        selectivity_idx, _, _ = svd_selectivity_idx(response_mat, angles_sorted, tuning_kind)\n",
    "\n",
    "        shuffled_selectivity_idxs.append(selectivity_idx)\n",
    "\n",
    "    shuffled_selectivity_idxs = np.concatenate(shuffled_selectivity_idxs)\n",
    "    \n",
    "    return shuffled_selectivity_idxs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ea1fb218-a2d9-4603-b955-665ecb359548",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935b9e9",
   "metadata": {},
   "source": [
    "keys = ['direction', 'orientation']\n",
    "\n",
    "# Allocate memory for cell property dataframes\n",
    "df_list = []\n",
    "\n",
    "for i, (ds, exp) in enumerate(zip(matched_data, exp_type)):\n",
    "\n",
    "    # get the number of cells\n",
    "    cells = [el for el in ds.columns if 'spike' in el]\n",
    "    \n",
    "    # allocate memory for the experiment\n",
    "    exp_list = []\n",
    "\n",
    "    for key in keys:\n",
    "        key_abbr = key[:3]\n",
    "\n",
    "        # Get the mean reponse during each time bin on each trial\n",
    "        trial_responses = ds.groupby([key, 'trial_num'])[cells].agg(list)\n",
    "        trial_responses = trial_responses.applymap(map_binned_statistic)\n",
    "\n",
    "        # Drop the trial number level, remove inter-trial interval from df\n",
    "        trial_responses = trial_responses.droplevel(['trial_num'])\n",
    "        trial_responses = trial_responses.drop(trial_responses[trial_responses.index < -500].index)\n",
    "\n",
    "        df_data_list = []\n",
    "\n",
    "        for cell in cells:\n",
    "            \n",
    "            # Aggregate trials for each stimulus\n",
    "            current_cell_responses = trial_responses.iloc[:, trial_responses.columns.get_loc(cell)]\n",
    "\n",
    "            # Generate normalized mean response matrix\n",
    "            response_mat, angles_sorted = generate_mean_response_matrix(current_cell_responses, key)\n",
    "\n",
    "            # Do SVD to get DSi/OSi\n",
    "            selectivity_idx, tuning_curve, temporal_component = svd_selectivity_idx(response_mat, angles_sorted, key)\n",
    "\n",
    "            # Normalize tuning curve to its range\n",
    "            tuning_curve = normalize(tuning_curve)\n",
    "            \n",
    "            #-- Get response quality index of the cell --#\n",
    "            response_mat = np.nan_to_num(response_mat, nan=0.0)\n",
    "            QI = np.var(np.mean(response_mat, axis=1)) / np.mean(np.var(response_mat, axis=0))\n",
    "            \n",
    "            #-- Run permutation test --#\n",
    "            # Here we shuffle the trial IDs and compare the real selectivity index to the bootstrapped distribution\n",
    "            shuffled_selectivity_idxs = bootstrap_svd_selectivity(current_cell_responses, key, num_shuffles=300)\n",
    "            p = percentileofscore(shuffled_selectivity_idxs, selectivity_idx, kind='mean') / 100.\n",
    "            \n",
    "            #-- Fit Gaussian tuning curves to get preference and tuning width --#\n",
    "            if key == \"direction\":\n",
    "                fit, fit_curve, pref_angle, real_pref_angle = calculate_pref_direction(angles_sorted, tuning_curve)\n",
    "            else:\n",
    "                fit, fit_curve, pref_angle, real_pref_angle = calculate_pref_orientation(angles_sorted, tuning_curve)\n",
    "\n",
    "            # Get tuning width.\n",
    "            tuning_width = get_FWHM(fit.x[2])\n",
    "            \n",
    "            # Append all the data for saving\n",
    "            df_data_list.append([cell, float(selectivity_idx), p, QI, pref_angle, tuning_width, (angles_sorted, tuning_curve), fit_curve])\n",
    "\n",
    "        # Make data frame for the experiment\n",
    "        cell_props = pd.DataFrame(data=df_data_list, \n",
    "                                  columns=['cell', f'{key_abbr}_sel_idx', f'{key_abbr}_sel_p', f'{key_abbr}_qi', f'{key_abbr}_pref', f'{key_abbr}_width', f'{key_abbr}_tuning_curve', f'{key_abbr}_fit_curve'],\n",
    "                                      )\n",
    "        cell_props.insert(0, 'exp_type', ''.join([exp, str(i)]))\n",
    "        exp_list.append(cell_props)\n",
    "        \n",
    "    df_list.append(exp_list[0].merge(exp_list[1], on=['cell', 'exp_type']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdc67b",
   "metadata": {},
   "source": [
    "cell_properties_svd = df_list[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313991a",
   "metadata": {},
   "source": [
    "bins = np.linspace(0, max(selectivity_idx[0], np.max(shuffled_selectivity_idxs)), retstep=0.2)[0]\n",
    "values, bins, _ = plt.hist(shuffled_selectivity_idxs, bins=bins, edgecolor='k', linewidth=1)\n",
    "plt.axvline(selectivity_idx, color='r', linewidth=3)\n",
    "plt.xlabel('Selectivity Index (K)')\n",
    "plt.ylabel('# of runs')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c782f233-0c0b-410e-8089-09b83c4faf4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tuning with circular variance\n",
    "As seen in Carandini, Rose, Schumacher papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71682f7a-bbc1-47b8-afec-173eea191000",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Circular Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e59dff-6672-4d42-ae0f-057deb5b2d5c",
   "metadata": {
    "code_folding": [
     0,
     8,
     17,
     22,
     37,
     47,
     75,
     101
    ]
   },
   "source": [
    "def wrap_negative(angles, bound=180):\n",
    "    \"\"\"Wrap angles to the range [-180, 180]\"\"\"\n",
    "    bound_excess_idx = np.argwhere(angles > bound)\n",
    "    out_angles = angles.copy()\n",
    "    out_angles[bound_excess_idx] = (angles[bound_excess_idx] % bound) - bound\n",
    " \n",
    "    return out_angles\n",
    "\n",
    "def wrap_sort_negative(angles, values, bound=180):\n",
    "    \"\"\"Wrap angles to  the range [-180, 180]\"\"\"\n",
    "    wrapped_angles = wrap_negative(angles)\n",
    "    sorted_index = np.argsort(wrapped_angles)\n",
    "    sorted_values = values[sorted_index]\n",
    "    sorted_wrapped_angles = wrapped_angles[sorted_index]\n",
    "\n",
    "    return sorted_wrapped_angles, sorted_values\n",
    "\n",
    "def wrap_sort(angles, bound=360):\n",
    "    angles_wrapped = fk.wrap(angles)\n",
    "    sort_idx = np.argsort(angles_wrapped)\n",
    "    angles_sorted = angles_wrapped[sort_idx]\n",
    "    return angles_sorted, sort_idx\n",
    "\n",
    "def map_statistic(x, func=np.nanmean):\n",
    "    x_array = np.array(x)\n",
    "    output = func(x_array, axis=1)\n",
    "    return output\n",
    "\n",
    "def get_resultant_vector(angles, tuning_weights, tuning_kind):\n",
    "    \n",
    "    # When calculating mean resultant, need to make orientation (bound from [0, pi]) bound from [0, 2pi]\n",
    "    # See comment here: https://www.mathworks.com/matlabcentral/fileexchange/10676-circular-statistics-toolbox-directional-statistics\n",
    "    if tuning_kind == 'orientation':\n",
    "        multiplier = 2\n",
    "    else:\n",
    "        multiplier = 1\n",
    "        \n",
    "    mean_resultant = circ.moment(multiplier*angles,  w=tuning_weights, d=multiplier*np.mean(np.diff(angles)))\n",
    "    angle = np.angle(mean_resultant) / multiplier\n",
    "    length = np.absolute(mean_resultant)\n",
    "    \n",
    "    return length, angle\n",
    "\n",
    "def get_circ_var(angles, tuning_weights, tuning_kind):\n",
    "    \n",
    "    # When calculating mean resultant, need to make orientation (bound from [0, pi]) bound from [0, 2pi]\n",
    "    if tuning_kind == 'orientation':\n",
    "        multiplier = 2\n",
    "    else:\n",
    "        multiplier = 1\n",
    "        \n",
    "    return circ.var(multiplier*angles, w=tuning_weights, d=multiplier*np.mean(np.diff(angles))) / multiplier\n",
    "\n",
    "def generate_mean_response_vector(cell_responses, tuning_kind):\n",
    "    # Get mean response across trials\n",
    "    current_cell_mean_resp = cell_responses.groupby([tuning_kind]).apply(np.nanmean)\n",
    "\n",
    "    # Normalize responses and fill any NaNs with zeros\n",
    "    current_cell_mean_resp = current_cell_mean_resp.fillna(0)\n",
    "    \n",
    "\n",
    "    # Get a list of directions/orientations\n",
    "    angles = current_cell_mean_resp.index.to_numpy()\n",
    "\n",
    "    # Wrap angles from [-180, 180] to [0, 360] for direction tuning, and sort angles and cell responses\n",
    "    # Needed for pycircstat toolbox\n",
    "    angles_sorted, sort_idx = wrap_sort(angles)\n",
    "    current_cell_mean_resp = current_cell_mean_resp.to_numpy()\n",
    "    sorted_mean_resp = current_cell_mean_resp[sort_idx]\n",
    "\n",
    "    # Make sure to explicitly represent 360 degrees in the data if looking at direction tuning. This is done by duplicating the 0 degresstrace\n",
    "    if tuning_kind == 'direction':\n",
    "        idx_0 = np.argwhere(angles_sorted == 0)[0][0]\n",
    "        trace_360 = sorted_mean_resp[idx_0]\n",
    "        angles_sorted = np.append(angles_sorted, 360.)\n",
    "        sorted_mean_resp = np.append(sorted_mean_resp, [trace_360], axis=0)\n",
    "    \n",
    "    return sorted_mean_resp, angles_sorted\n",
    "\n",
    "\n",
    "def generate_sem_vector(cell_responses, tuning_kind):\n",
    "    # Get mean response across trials\n",
    "    current_cell_resp_sem = cell_responses.groupby([tuning_kind]).apply(sem, nan_policy='omit')\n",
    "\n",
    "    # Normalize responses and fill any NaNs with zeros\n",
    "    current_cell_resp_sem = current_cell_resp_sem.fillna(0)\n",
    "    \n",
    "    # Get a list of directions/orientations\n",
    "    angles = current_cell_resp_sem.index.to_numpy()\n",
    "\n",
    "    # Wrap angles from [-180, 180] to [0, 360] for direction tuning, and sort angles and cell responses\n",
    "    # Needed for pycircstat toolbox\n",
    "    angles_sorted, sort_idx = wrap_sort(angles)\n",
    "    current_cell_resp_sem = current_cell_resp_sem.to_numpy()\n",
    "    sorted_sem_resp = current_cell_resp_sem[sort_idx]\n",
    "\n",
    "    # Make sure to explicitly represent 360 degrees in the data if looking at direction tuning. This is done by duplicating the 0 degresstrace\n",
    "    if tuning_kind == 'direction':\n",
    "        idx_0 = np.argwhere(angles_sorted == 0)[0][0]\n",
    "        trace_360 = sorted_sem_resp[idx_0]\n",
    "        angles_sorted = np.append(angles_sorted, 360.)\n",
    "        sorted_sem_resp = np.append(sorted_sem_resp, [trace_360], axis=0)\n",
    "    \n",
    "    return sorted_sem_resp, angles_sorted\n",
    "\n",
    "\n",
    "\n",
    "def bootstrap_responsivity(trial_responses, tuning_kind, num_shuffles=1000):\n",
    "    \n",
    "    shuffled_responsivity = []\n",
    "    \n",
    "    # Get a list of directions/orientations\n",
    "    angles = trial_responses.index.unique().to_numpy()\n",
    "    \n",
    "    trial_idxs = trial_responses.index.to_numpy()\n",
    "\n",
    "    for i in range(0, num_shuffles):\n",
    "        # Shuffle stimulus labels and reassign\n",
    "        np.random.shuffle(trial_idxs)\n",
    "        shuffled_responses = trial_responses.copy().reindex(trial_idxs)\n",
    "\n",
    "        # Generate mean response vector from shuffled data\n",
    "        shuffled_response_vector, angles = generate_mean_response_vector(shuffled_responses, tuning_kind)\n",
    "        \n",
    "         #-- Get response circular variance --#\n",
    "        circ_var = get_circ_var(np.deg2rad(angles), shuffled_response_vector, tuning_kind)\n",
    "        responsivity = 1 - circ_var\n",
    "        shuffled_responsivity.append(responsivity)\n",
    "\n",
    "    shuffled_responsivity = np.array(shuffled_responsivity)\n",
    "    \n",
    "    return shuffled_responsivity\n",
    "\n",
    "def polar_vector_sum(magnitudes, directions):\n",
    "    directions = np.deg2rad(directions)\n",
    "    x = np.sum(magnitudes * np.cos(directions))\n",
    "    y = np.sum(magnitudes * np.sin(directions))\n",
    "    \n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    theta = np.rad2deg(np.arctan2(y, x))\n",
    "    \n",
    "    return r, theta"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb1443a-06b0-4511-9f23-6e2d17864e33",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee8e60d-d6fb-4b94-9098-b54381eb01c9",
   "metadata": {},
   "source": [
    "keys = ['direction', 'orientation']\n",
    "\n",
    "# Allocate memory for cell property dataframes\n",
    "df_list_circvar = []\n",
    "\n",
    "for i, (ds, exp) in enumerate(zip(matched_data, exp_type)):\n",
    "\n",
    "    # get the number of cells\n",
    "    cells = [el for el in ds.columns if 'spikes' in el]\n",
    "    \n",
    "    # allocate memory for the experiment\n",
    "    exp_list = []\n",
    "\n",
    "    for key in keys:\n",
    "        key_abbr = key[:3]\n",
    "\n",
    "        # Get the mean reponse per trial\n",
    "        trial_responses = ds.groupby([key, 'trial_num'])[cells].agg(np.nanmean)\n",
    "\n",
    "        # Drop the inter-trial interval from df\n",
    "        trial_responses = trial_responses.droplevel(['trial_num'])\n",
    "        trial_responses = trial_responses.drop(trial_responses[trial_responses.index < -500].index)\n",
    "\n",
    "        df_data_list = []\n",
    "\n",
    "        for cell in cells:\n",
    "            \n",
    "            #-- Create the response vector --#\n",
    "            current_cell_responses = trial_responses.iloc[:, trial_responses.columns.get_loc(cell)]\n",
    "            mean_resp, angles = generate_mean_response_vector(current_cell_responses, key)\n",
    "            sem_resp, _ = generate_sem_vector(current_cell_responses, key)\n",
    "            \n",
    "            # Normalize to maximum\n",
    "            if np.max(mean_resp) > 0:\n",
    "                norm_mean_resp = mean_resp / np.max(mean_resp)\n",
    "                norm_sem_resp = sem_resp / mean_resp\n",
    "            else:\n",
    "                norm_mean_resp = mean_resp\n",
    "                norm_sem_resp = sem_resp\n",
    "\n",
    "            #-- Get preferred tuning --#\n",
    "            resultant_length, resultant_angle = get_resultant_vector(np.deg2rad(angles), norm_mean_resp, key)\n",
    "            resultant_angle = fk.wrap(np.rad2deg(resultant_angle))\n",
    "\n",
    "            #-- Get response circular variance --#\n",
    "            circ_var = get_circ_var(np.deg2rad(angles), norm_mean_resp, key)\n",
    "            responsivity = 1 - circ_var\n",
    "            \n",
    "            # -- Run permutation test --#\n",
    "            # Here we shuffle the trial IDs and compare the real selectivity index to the bootstrapped distribution\n",
    "            shuffled_responsivity = bootstrap_responsivity(current_cell_responses, key, num_shuffles=300)\n",
    "            p = percentileofscore(shuffled_responsivity, responsivity, kind='mean') / 100.\n",
    "            \n",
    "            #-- Fit Gaussian tuning curves to get preference and tuning width --#\n",
    "            if key == \"direction\":\n",
    "                fit, fit_curve, pref_angle, real_pref_angle = calculate_pref_direction(angles, norm_mean_resp)\n",
    "            else:\n",
    "                fit, fit_curve, pref_angle, real_pref_angle = calculate_pref_orientation(angles, norm_mean_resp)\n",
    "\n",
    "            # Get tuning width\n",
    "            tuning_width = get_FWHM(fit.x[2])\n",
    "            \n",
    "            # Append all the data for saving\n",
    "            df_data_list.append([cell, responsivity, p, resultant_angle, pref_angle, tuning_width, (angles, norm_mean_resp), norm_sem_resp, fit_curve])\n",
    "\n",
    "        # Make data frame for the experiment\n",
    "        cell_props = pd.DataFrame(data=df_data_list, \n",
    "                                  columns=['cell', f'{key_abbr}_resp', f'{key_abbr}_resp_p', f'{key_abbr}_res_angle', f'{key_abbr}_pref', f'{key_abbr}_width', f'{key_abbr}_tuning_curve', f'{key_abbr}_sem', f'{key_abbr}_fit_curve'],\n",
    "                                      )\n",
    "        cell_props.insert(0, 'exp_type', ''.join([exp, str(i)]))\n",
    "        exp_list.append(cell_props)\n",
    "        \n",
    "    df_list_circvar.append(exp_list[0].merge(exp_list[1], on=['cell', 'exp_type']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bee96-33da-43eb-aea2-69b659ae1d1b",
   "metadata": {},
   "source": [
    "bins = np.linspace(0, max(responsivity, np.max(shuffled_responsivity)), retstep=0.2)[0]\n",
    "values, bins, _ = plt.hist(shuffled_responsivity, bins=bins, edgecolor='k', linewidth=1)\n",
    "plt.axvline(responsivity, color='r', linewidth=3)\n",
    "plt.xlabel('1 - circ_var')\n",
    "plt.ylabel('# of runs')\n",
    "plt.text(0, 200, str(p)) \n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514cd9c-f83c-4d0c-9494-ae34c2823b50",
   "metadata": {},
   "source": [
    "idx =  3\n",
    "cell_properties_cv = df_list_circvar[0]\n",
    "tuning_curve = cell_properties_cv.iloc[idx].dir_tuning_curve\n",
    "fit_curve = cell_properties_cv.iloc[idx].dir_fit_curve\n",
    "pref = cell_properties_cv.iloc[idx].dir_pref\n",
    "tuning_width = cell_properties_cv.iloc[idx].dir_width\n",
    "\n",
    "plot_tuning_curve(tuning_curve, fit=fit_curve, pref_angle=pref)\n",
    "\n",
    "print(tuning_curve)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb04dff",
   "metadata": {},
   "source": [
    "# allocate memory for the cell plots\n",
    "cell_plots = []\n",
    "\n",
    "# for all the files\n",
    "for ds in df_list_circvar:\n",
    "    for i, cell in ds.iterrows():\n",
    "        \n",
    "        cell_plot = plot_tuning_curve_hv(cell.ori_tuning_curve,\n",
    "                                         sem=cell.ori_sem,\n",
    "                                         fit=cell.ori_fit_curve, \n",
    "                                         pref_angle=cell.ori_pref)\n",
    "        \n",
    "        cell_plots.append(cell_plot.opts(xlim=(0,180), xlabel=\"angle [deg]\", title=str(cell.cell)))\n",
    "        \n",
    "num_cells = np.max([len(ds.cell.unique()) for ds in df_list_circvar])\n",
    "hv.Layout(cell_plots).opts(shared_axes=False).cols(num_cells)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a325af8",
   "metadata": {},
   "source": [
    "# allocate memory for the cell plots\n",
    "cell_plots = []\n",
    "\n",
    "# for all the files\n",
    "for ds in df_list_circvar:\n",
    "    for i, cell in ds.iterrows():\n",
    "        \n",
    "        cell_plot = plot_tuning_curve_hv(cell.dir_tuning_curve, \n",
    "                                         sem=cell.dir_sem,\n",
    "                                         fit=cell.dir_fit_curve, \n",
    "                                         pref_angle=cell.dir_pref)\n",
    "        cell_plots.append(cell_plot.opts(xlim=(0, 360), xlabel=\"angle [deg]\", title=str(cell.cell)))\n",
    "        \n",
    "num_cells = np.max([len(ds.cell.unique()) for ds in df_list_circvar])\n",
    "hv.Layout(cell_plots).opts(shared_axes=False).cols(num_cells)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5d016-1b4b-4750-9783-87258f40cf8a",
   "metadata": {},
   "source": [
    "df_idx = 0\n",
    "this_ds = df_list_circvar[df_idx]\n",
    "this_ds = this_ds.sort_values(['dir_resp'], ascending=False, inplace=False).reset_index(drop=True)\n",
    "\n",
    "# cell_idx =  int(this_ds[this_ds.cell == 'cell_19'].index.values)\n",
    "cell_idx = 13\n",
    "cell_num = this_ds.iloc[cell_idx].cell\n",
    "tuning_curve = this_ds.iloc[cell_idx].dir_tuning_curve\n",
    "fit_curve = this_ds.iloc[cell_idx].dir_fit_curve\n",
    "pref = this_ds.iloc[cell_idx].dir_pref\n",
    "tuning_width = this_ds.iloc[cell_idx].dir_width\n",
    "resp = this_ds.iloc[cell_idx].dir_resp\n",
    "resp_p = this_ds.iloc[cell_idx].dir_resp_p\n",
    "\n",
    "# angles, sorted_tuning = wrap_sort_negative(directions_wrapped, tuning_curve)\n",
    "# sorted_fit_curve = wrap_sort_negative(*fit_curve)\n",
    "# if pref > 180:\n",
    "#     pref = pref % 180 - 180\n",
    "# plot_tuning_curve_hv(angles, sorted_tuning, fit=sorted_fit_curve, pref_angle=pref)\n",
    "\n",
    "fig = plot_tuning_curve_hv(tuning_curve, fit=fit_curve, pref_angle=pref)\n",
    "\n",
    "print(cell_num, pref, tuning_width, resp, resp_p)\n",
    "fig"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d39fb-f880-497a-a344-c2fd082a3378",
   "metadata": {},
   "source": [
    "df_idx = 1\n",
    "this_ds = df_list_circvar[df_idx]\n",
    "this_ds = this_ds.sort_values(['ori_resp'], ascending=False, inplace=False).reset_index(drop=True)\n",
    "\n",
    "# cell_idx =  int(this_ds[this_ds.cell == 'cell_19'].index.values)\n",
    "cell_idx = 4\n",
    "\n",
    "\n",
    "cell_num = this_ds.iloc[cell_idx].cell\n",
    "tuning_curve = this_ds.iloc[cell_idx].ori_tuning_curve\n",
    "fit_curve = this_ds.iloc[cell_idx].ori_fit_curve\n",
    "pref = this_ds.iloc[cell_idx].ori_pref\n",
    "tuning_width = this_ds.iloc[cell_idx].ori_width\n",
    "resp = this_ds.iloc[cell_idx].ori_resp\n",
    "resp_p = this_ds.iloc[cell_idx].ori_resp_p\n",
    "\n",
    "fig = plot_tuning_curve_hv(tuning_curve, fit=fit_curve, pref_angle=pref)\n",
    "\n",
    "print(cell_num, pref, tuning_width, resp, resp_p)\n",
    "fig"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61736d16-5d11-40c7-aa6a-cb7406df344c",
   "metadata": {},
   "source": [
    "df_idx = 0\n",
    "this_ds = df_list_circvar[df_idx]\n",
    "this_ds = this_ds.sort_values(['ori_resp_p', 'dir_resp_p'], ascending=True, inplace=False).reset_index(drop=True)\n",
    "\n",
    "# cell_idx =  int(this_ds[this_ds.cell == 'cell_0'].index.values)\n",
    "cell_idx = 15\n",
    "cell_num = this_ds.iloc[cell_idx].cell\n",
    "dir_tuning_curve = this_ds.iloc[cell_idx].dir_tuning_curve\n",
    "dir_fit_curve = this_ds.iloc[cell_idx].dir_fit_curve\n",
    "dir_pref = this_ds.iloc[cell_idx].dir_pref\n",
    "dir_tuning_width = this_ds.iloc[cell_idx].dir_width\n",
    "dir_resp = this_ds.iloc[cell_idx].dir_resp\n",
    "dir_resp_p = this_ds.iloc[cell_idx].dir_resp_p\n",
    "\n",
    "angles, sorted_dir_tuning = wrap_sort_negative(directions_wrapped, dir_tuning_curve)\n",
    "sorted_dir_fit_curve = wrap_sort_negative(*dir_fit_curve)\n",
    "if dir_pref > 180:\n",
    "    dir_pref = dir_pref % 180 - 180\n",
    "\n",
    "print(cell_num, dir_pref, dir_tuning_width, dir_resp, dir_resp_p)\n",
    "dir_fig = plot_tuning_curve_hv(angles, sorted_dir_tuning, fit=sorted_dir_fit_curve, pref_angle=dir_pref, xlabel='Direction [deg]', ylabel='Mean Response [inf. spikes]')\n",
    "\n",
    "ori_tuning_curve = this_ds.iloc[cell_idx].ori_tuning_curve\n",
    "ori_fit_curve = this_ds.iloc[cell_idx].ori_fit_curve\n",
    "ori_pref = this_ds.iloc[cell_idx].ori_pref\n",
    "ori_tuning_width = this_ds.iloc[cell_idx].ori_width\n",
    "ori_resp = this_ds.iloc[cell_idx].ori_resp\n",
    "ori_resp_p = this_ds.iloc[cell_idx].ori_resp_p\n",
    "\n",
    "print(cell_num, ori_pref, ori_tuning_width, ori_resp, ori_resp_p)\n",
    "ori_fig = plot_tuning_curve_hv(orientations, ori_tuning_curve, fit=ori_fit_curve, pref_angle=ori_pref, xlabel='Orientation [deg]', ylabel='Mean Response [inf. spikes]')\n",
    "\n",
    "hv.Layout(dir_fig + ori_fig).opts(shared_axes=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "96a40c4c-1c2a-4129-b25b-8fe2653793db",
   "metadata": {},
   "source": [
    "# Compare SVD and Circ Var based metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3e473-9045-4b4f-adb3-d470367dce0f",
   "metadata": {},
   "source": [
    "cell_properties_svd = df_list[-1]\n",
    "# The cutoff of QI here is from the Baden paper\n",
    "sig_dir_sel_svd = cell_properties_svd[(cell_properties_svd.dir_sel_p <= 0.15)].sort_values('dir_sel_p')\n",
    "sig_ori_sel_svd = cell_properties_svd[(cell_properties_svd.ori_sel_p <= 0.15)].sort_values('ori_sel_p')\n",
    "\n",
    "cell_properties_cv = df_list_circvar[-1]\n",
    "sig_dir_sel_cv = cell_properties_cv[(cell_properties_cv.dir_resp > 0.25)].sort_values('dir_resp')\n",
    "sig_ori_sel_cv = cell_properties_cv[(cell_properties_cv.ori_resp > 0.25)].sort_values('ori_resp')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2e675-106f-44d7-9dcd-5b38dd3d5041",
   "metadata": {},
   "source": [
    "print(cell_properties_svd.columns)\n",
    "print(cell_properties_cv.columns)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b6cdf-a54e-4150-bf58-7d12e28689ea",
   "metadata": {},
   "source": [
    "shared_dir_sel = sig_dir_sel_svd.merge(sig_dir_sel_cv, on='cell', how='left', suffixes=['_svd', '_cv'])\n",
    "shared_ori_sel = sig_ori_sel_svd.merge(sig_ori_sel_cv, on='cell', how='left', suffixes=['_svd', '_cv'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96ed5d-18b8-46c1-8d3b-009f31a59f3c",
   "metadata": {},
   "source": [
    "shared_dir_sel[['cell', 'dir_sel_p', 'dir_pref_svd', 'dir_pref_cv', 'dir_resp']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68dbb5-28ec-4d6f-be4d-398d33fafd6f",
   "metadata": {},
   "source": [
    "shared_dir_sel[['cell', 'ori_sel_p', 'ori_pref_svd', 'ori_pref_cv', 'ori_resp']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a9a10f39-8448-4079-b180-a7b2a7981d53",
   "metadata": {},
   "source": [
    "# Population Vector Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72c272-d923-485a-a2ca-0b7391651db8",
   "metadata": {},
   "source": [
    "Use SVD chosen, direction selective cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fe7ee-480b-4197-b402-f380126504d5",
   "metadata": {},
   "source": [
    "cell_properties_svd = df_list[-1]\n",
    "# The cutoff of QI here is from the Baden paper\n",
    "sig_dir_sel_svd = cell_properties_svd[(cell_properties_svd.dir_sel_p <= 0.15)].sort_values('dir_sel_p')\n",
    "cell_tuning = sig_dir_sel_svd[['cell', 'dir_pref']].sort_index()\n",
    "tuned_cells = cell_tuning.cell.to_list()\n",
    "dir_prefs = cell_tuning.dir_pref.to_list()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c349c8-822b-4bde-83fe-bb5c1b6f9313",
   "metadata": {},
   "source": [
    "print(tuned_cells)\n",
    "print(dir_prefs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c8dc7-30e0-4f14-9f13-055c779d6e0b",
   "metadata": {},
   "source": [
    "# Get the mean reponse per trial\n",
    "trial_responses = data[-1].groupby(['trial_num'])[['direction'] + tuned_cells].agg(np.nanmean)\n",
    "\n",
    "# Drop the inter-trial interval from df\n",
    "trial_responses = trial_responses.drop(trial_responses[trial_responses.index == 0].index)\n",
    "\n",
    "real_direction = trial_responses.direction.to_numpy()\n",
    "\n",
    "decoded_angles = []\n",
    "for i, row in trial_responses.iterrows():\n",
    "    direction = row.direction\n",
    "    cell_resps = row[tuned_cells]\n",
    "    \n",
    "    #-- Get preferred tuning --#\n",
    "    decoded_length, decoded_angle = get_resultant_vector(np.deg2rad(dir_prefs), cell_resps, 'direction')\n",
    "    decoded_angle = np.rad2deg(decoded_angle)\n",
    "    if decoded_angle > 180:\n",
    "        decoded_angle = decoded_angle % 180 - 180\n",
    "    decoded_angles.append(decoded_angle)\n",
    "    \n",
    "decoded_angles = np.array(decoded_angles)\n",
    "\n",
    "# for cell in cells:\n",
    "\n",
    "#     current_cell_responses = trial_responses.iloc[:, trial_responses.columns.get_loc(cell)]\n",
    "\n",
    "#     # Get mean response across trials\n",
    "#     current_cell_mean_resp = current_cell_responses.groupby([key]).apply(np.nanmean)\n",
    "\n",
    "#     # Normalize responses and fill any NaNs with zeros\n",
    "#     current_cell_mean_resp = current_cell_mean_resp.fillna(0)\n",
    "\n",
    "#     # Get a list of directions/orientations\n",
    "#     angles = current_cell_mean_resp.index.to_numpy()\n",
    "\n",
    "#     # Wrap angles from [-180, 180] to [0, 360] for direction tuning, and sort angles and cell responses\n",
    "#     # Needed for pycircstat toolbox\n",
    "#     angles_wrapped = fk.wrap(angles)\n",
    "#     sort_idx = np.argsort(angles_wrapped)\n",
    "#     angles_sorted = angles_wrapped[sort_idx]\n",
    "\n",
    "#     current_cell_mean_resp = current_cell_mean_resp.to_numpy()\n",
    "#     sorted_mean_resp = current_cell_mean_resp[sort_idx]\n",
    "\n",
    "#     #-- Get preferred tuning --#\n",
    "#     resultant_length, resultant_angle = get_resultant_vector(np.deg2rad(angles_sorted), sorted_mean_resp, key)\n",
    "#     resultant_angle = fk.wrap(np.rad2deg(resultant_angle))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3194fc5-3586-42bc-92cd-e5467756810a",
   "metadata": {},
   "source": [
    "print(real_direction)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2598c2-b5da-480f-82ee-13c715ff80cc",
   "metadata": {},
   "source": [
    "print(decoded_angles)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93f4ee-7ec1-4bad-aca7-795a71388282",
   "metadata": {},
   "source": [
    "real_direction - decoded_angles"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811e443-c8e5-423b-aed3-ebba226df41e",
   "metadata": {},
   "source": [
    "plt.imshow(np.cov(real_direction, decoded_angles))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8a00dc96",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Polar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137c1d2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Test polar vector sum for direction\n",
    "fig, axes = plt.subplots(nrows=len(data), ncols=len(cells), subplot_kw={'projection': 'polar'}, figsize=(20,40))\n",
    "\n",
    "for j, ds in enumerate(data):\n",
    "    cells = [el for el in ds.columns if 'cell' in el]\n",
    "    tuning = ds.groupby(['direction'])[cells].mean()\n",
    "    tuning_sem = ds.groupby(['direction'])[cells].sem()\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "\n",
    "        baseline = tuning.iloc[0, tuning.columns.get_loc(cell)]\n",
    "        current_cell = tuning.iloc[1:, tuning.columns.get_loc(cell)] - baseline\n",
    "        current_cell -= current_cell.min()\n",
    "        current_cell_norm = current_cell / current_cell.max()\n",
    "        current_sem = (tuning_sem.iloc[1:, tuning_sem.columns.get_loc(cell)])\n",
    "        directions = current_cell.index.to_numpy()\n",
    "        r, theta = polar_vector_sum(current_cell.to_numpy(), directions)\n",
    "\n",
    "        axes[j,i].plot(np.deg2rad(directions), current_cell.to_numpy())\n",
    "        axes[j,i].fill_between(np.deg2rad(directions), current_cell.to_numpy()+current_sem.to_numpy(), current_cell.to_numpy()-current_sem.to_numpy(), alpha=0.2)\n",
    "        axes[j,i].plot([0, np.deg2rad(theta)], [0, current_cell.max()], color='r')\n",
    "        axes[j,i].set_rmin(0)\n",
    "        axes[j,i].set_theta_zero_location(\"W\")\n",
    "        axes[j,i].set_theta_direction(-1)\n",
    "        axes[j,i].set_xticklabels(['0', '45', '90', '135', '+/-180', '-135', '-90', '-45'])\n",
    "        axes[j,i].set_title(cell)\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187f7bc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Test polar vector sum for orientation\n",
    "fig, axes = plt.subplots(nrows=len(data), ncols=len(cells), subplot_kw={'projection': 'polar'}, figsize=(20,40))\n",
    "\n",
    "for j, ds in enumerate(data):\n",
    "    cells = [el for el in ds.columns if 'cell' in el]\n",
    "    tuning = ds.groupby(['orientation'])[cells].mean()\n",
    "    tuning_sem = ds.groupby(['orientation'])[cells].sem()\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "\n",
    "        baseline = tuning.iloc[0, tuning.columns.get_loc(cell)]\n",
    "        current_cell = tuning.iloc[1:, tuning.columns.get_loc(cell)] - baseline\n",
    "        current_cell -= current_cell.min()\n",
    "        current_cell_norm = current_cell / current_cell.max()\n",
    "        current_sem = (tuning_sem.iloc[1:, tuning_sem.columns.get_loc(cell)])\n",
    "        directions = current_cell.index.to_numpy()\n",
    "        r, theta = polar_vector_sum(current_cell.to_numpy(), directions)\n",
    "\n",
    "        axes[j,i].plot(np.deg2rad(directions), current_cell.to_numpy())\n",
    "        axes[j,i].fill_between(np.deg2rad(directions), current_cell.to_numpy()+current_sem.to_numpy(), current_cell.to_numpy()-current_sem.to_numpy(), alpha=0.2)\n",
    "        axes[j,i].plot([0, np.deg2rad(theta)], [0, current_cell.max()], color='r')\n",
    "        axes[j,i].set_rmin(0)\n",
    "        axes[j,i].set_theta_zero_location(\"W\")\n",
    "        axes[j,i].set_theta_direction(-1)\n",
    "        axes[j,i].set_thetamax(180)\n",
    "        axes[j,i].set_title(cell)\n"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "383.85px",
    "left": "1265px",
    "right": "20px",
    "top": "157px",
    "width": "558px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
