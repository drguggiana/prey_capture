{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib widget\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import cv2\n",
    "import importlib\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(r'C:/Users/mmccann/repos/bonhoeffer/prey_capture/'))\n",
    "import processing_parameters\n",
    "import functions_bondjango as bd\n",
    "import functions_misc as fmisc\n",
    "import functions_matching as fm\n",
    "import functions_data_handling as fdh\n",
    "import functions_tuning as tuning\n",
    "import functions_plotting as fp\n",
    "from wirefree_experiment import WirefreeExperiment, DataContainer\n",
    "from functions_wirefree_trigger_fix import get_trial_duration_stats\n",
    "\n",
    "fig_path = r\"C:\\Users\\mmccann\\Dropbox\\bonhoeffer lab\\conferences\\senses_in_motion_24\\figure_media\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "def get_footprint_centroids(calcium_data):\n",
    "    cents = []\n",
    "    for cell in calcium_data:\n",
    "        new_cell = cell.copy()\n",
    "        new_cell[new_cell > 0] == 1 \n",
    "        M = cv2.moments(new_cell)\n",
    "        \n",
    "        # centroid calciulation\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cents.append([cX, cY])\n",
    "    return cents\n",
    "\n",
    "def get_footprint_contours(calcium_data):\n",
    "    contour_list = []\n",
    "    contour_stats = []\n",
    "    for frame in calcium_data:\n",
    "        frame = frame * 255.\n",
    "        frame = frame.astype(np.uint8)\n",
    "        thresh = cv2.threshold(frame, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # # get contours and filter out small defects\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        # Only take the largest contour\n",
    "        cntr = max(contours, key=cv2.contourArea)\n",
    "        area = cv2.contourArea(cntr)\n",
    "        perimeter = cv2.arcLength(cntr, True)\n",
    "        compactness = 4*np.pi*area / (perimeter + 1e-16)**2\n",
    "        \n",
    "        contour_list.append(cntr)\n",
    "        contour_stats.append((area, perimeter, compactness))\n",
    "\n",
    "    return contour_list, np.array(contour_stats)\n",
    "\n",
    "def make_contour_projection(contour_list, shape, threshold=0.1):\n",
    "    contour_img = np.zeros(shape)\n",
    "    for i, cntr in enumerate(contour_list):\n",
    "        cv2.drawContours(contour_img[i, :], [cntr], 0, 1, 1)\n",
    "\n",
    "    contour_img = np.sum(contour_img, axis=0)\n",
    "    contour_img[contour_img > threshold] = 1.0\n",
    "    return contour_img\n",
    "\n",
    "def get_binary_footprints(footprint_pic, threshold=0.1):\n",
    "    bin_pic = np.zeros_like(footprint_pic)\n",
    "    bin_pic[footprint_pic > threshold] = 1\n",
    "    return bin_pic\n",
    "\n",
    "def make_rgb_overlay(max_proj, footprints, contour_img, channel='r'):\n",
    "    max_proj -= max_proj.min()\n",
    "    max_proj /= max_proj.max()\n",
    "\n",
    "    # Make RGB max projection\n",
    "    max_proj_rgb = np.dstack((max_proj, max_proj, max_proj))\n",
    "\n",
    "    # mak RGB footprint image\n",
    "    footprint_rgb = np.zeros((*max_proj.shape, 3))\n",
    "\n",
    "    footprints /= footprints.max()\n",
    "    if channel == 'r':\n",
    "        footprint_rgb[:, :, 0] = footprints\n",
    "    elif channel == 'g':\n",
    "        footprint_rgb[:, :, 1] = footprints\n",
    "    elif channel == 'b':\n",
    "        footprint_rgb[:, :, 2] = footprints\n",
    "    else:\n",
    "        raise ValueError('channel must be r, g, or b')\n",
    "    \n",
    "    # Convert RGB max proj and RGB footprints to HSV colorspace\n",
    "    max_proj_hsv = color.rgb2hsv(max_proj_rgb)\n",
    "    footprint_mask_hsv = color.rgb2hsv(footprint_rgb)\n",
    "\n",
    "    # Overlay the footprint mask on the max projection\n",
    "    max_proj_hsv[..., 0] = footprint_mask_hsv[..., 0]\n",
    "    max_proj_hsv[..., 1] = footprint_mask_hsv[..., 1]\n",
    "\n",
    "    # Return to RGB colorspace\n",
    "    overlay = color.hsv2rgb(max_proj_hsv)\n",
    "    overlay[:] += np.expand_dims(contour_img, -1).astype(float)\n",
    "\n",
    "    return overlay\n",
    "\n",
    "def hv_plot_FOVs(rigs, binary_footprints, contour_images, alpha=0, labels=None, overlay=True):\n",
    "    binary_images = []\n",
    "\n",
    "    for i, (rig, bin_pic) in enumerate(zip(rigs, binary_footprints)):\n",
    "        # Plot all binarized ROIS with contours\n",
    "        alpha_mask = np.ones_like(bin_pic) * alpha\n",
    "        bin_pic = np.dstack((bin_pic, alpha_mask))\n",
    "        binary_image = hv.RGB(bin_pic.astype(float), bounds=(0, 0, 320, 320)).opts(title=rig)\n",
    "        \n",
    "        if labels is not None:\n",
    "            cents = labels[i][:, :2].copy()\n",
    "            cents[:,1] = 320 - cents[:,1]\n",
    "            label = labels[i][:, -1]\n",
    "            label_plot = hv.Labels({('x', 'y'): cents, 'text': label}, ['x', 'y'], 'text').opts(text_color='white', xoffset=0.0, yoffset=0.0, text_font_size='8pt')\n",
    "            binary_image = binary_image * label_plot\n",
    "\n",
    "        binary_images.append(binary_image)\n",
    "\n",
    "    if overlay:\n",
    "        binary_overlay = hv.RGB(np.dstack((contour_images[1], np.zeros_like(contour_images[0]), contour_images[0])), bounds=(0, 0, 320, 320)).opts(title='Overlay')\n",
    "        binary_images.append(binary_overlay)\n",
    "        \n",
    "    layout = hv.Layout(binary_images).cols(len(binary_images))\n",
    "\n",
    "    return layout"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "importlib.reload(processing_parameters)\n",
    "\n",
    "# get the search string\n",
    "search_string = processing_parameters.search_string\n",
    "parsed_search = fdh.parse_search_string(search_string)\n",
    "\n",
    "# get the paths from the database\n",
    "file_infos = bd.query_database('analyzed_data', search_string)\n",
    "preproc_paths = np.sort(np.array([el['analysis_path'] for el in file_infos if (el['analysis_type'] == 'preprocessing') and\n",
    "                         (parsed_search['mouse'].lower() in el['slug'])]))\n",
    "calcium_paths = np.sort(np.array([el['analysis_path'].replace('preproc', 'calciumraw') for el in file_infos if (el['analysis_type'] == 'preprocessing') and\n",
    "                         (parsed_search['mouse'].lower() in el['slug'])]))\n",
    "tc_paths = np.sort(np.array([el['analysis_path'] for el in file_infos if (el['analysis_type'] == 'tc_analysis') and\n",
    "                         (parsed_search['mouse'].lower() in el['slug'])]))\n",
    "cell_matching_path = [el['analysis_path'] for el in file_infos if ('daycellmatch' in el['slug']) and\n",
    "                            (parsed_search['mouse'].lower() in el['slug'])]\n",
    "rigs = np.array([os.path.basename(file).split('_')[6] for file in calcium_paths])\n",
    "print(cell_matching_path)\n",
    "print(calcium_paths)\n",
    "print(preproc_paths)\n",
    "print(tc_paths)\n",
    "print(rigs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "# Load the assignments and find the column that corresponds to each file\n",
    "assignments =  fm.match_cells(cell_matching_path[0])\n",
    "new_cols = [col.split('_')[-2] for col in assignments.columns]\n",
    "assignments.columns = new_cols\n",
    "match_cols = [i for i, (rig, col) in enumerate(zip(rigs, assignments.columns)) if str(col) in rig]\n",
    "\n",
    "# Use number of non-NaNs in each row to filter out components that were not registered in enough sessions\n",
    "assignments_filtered = assignments.dropna().astype(int).to_numpy()\n",
    "unassigned = np.array(assignments[np.sum(~np.isnan(assignments), axis=1) < 2])\n",
    "unassigned = [unassigned[~np.isnan(unassigned[:, 0]), 0].astype(int), unassigned[~np.isnan(unassigned[:, 1]), 1].astype(int)]\n",
    "unassigned = [np.sort(np.unique(unassigned[0])), np.sort(np.unique(unassigned[1]))]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "# load the data for the matching\n",
    "calcium_list = []\n",
    "max_proj_list = []\n",
    "footprint_list = []\n",
    "contour_list = []\n",
    "size_list = []\n",
    "template_list = []\n",
    "footprint_pics = []\n",
    "countour_pics = []\n",
    "centroids_list = []\n",
    "binary_footprints = []\n",
    "overlay_footprints = []\n",
    "overlay_binary_footprints = []\n",
    "\n",
    "\n",
    "# load the calcium data\n",
    "for files, channel in zip(calcium_paths, ['b', 'r']):\n",
    "\n",
    "    with h5py.File(files, mode='r') as f:\n",
    "\n",
    "        try:\n",
    "            calcium_data = np.array(f['A'])\n",
    "            max_proj = np.array(f['max_proj'])     \n",
    "\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    # if there are no ROIs, skip\n",
    "    if (type(calcium_data) == np.ndarray) and np.any(calcium_data.astype(str) == 'no_ROIs'):\n",
    "        continue\n",
    "        \n",
    "    # clear the rois that don't pass the size or compactness criteria\n",
    "    roi_stats = fmisc.get_roi_stats(calcium_data)\n",
    "    contours, contour_stats = get_footprint_contours(calcium_data)\n",
    "\n",
    "    if len(roi_stats.shape) == 1:\n",
    "        roi_stats = roi_stats.reshape(1, -1)\n",
    "        contour_stats = contour_stats.reshape(1, -1)\n",
    "\n",
    "    areas = roi_stats[:, -1]\n",
    "    compactness = contour_stats[:, -1]\n",
    "\n",
    "    keep_vector = (areas > processing_parameters.roi_parameters['area_min']) & \\\n",
    "                  (areas < processing_parameters.roi_parameters['area_max']) & \\\n",
    "                  (compactness > 0.5)\n",
    "\n",
    "    if np.all(keep_vector == False):\n",
    "        continue\n",
    "\n",
    "    calcium_data = calcium_data[keep_vector, :, :]\n",
    "    contours = [contours[i] for i, keep in enumerate(keep_vector) if keep]\n",
    "\n",
    "    centroids = get_footprint_centroids(calcium_data)\n",
    "    footprint_proj = np.sum(calcium_data, axis=0)\n",
    "    binary_footprint_proj = get_binary_footprints(footprint_proj)\n",
    "    contour_proj = make_contour_projection(contours, calcium_data.shape, threshold=0.5)\n",
    "    \n",
    "    # format and masks and store for matching\n",
    "    calcium_list.append(calcium_data)\n",
    "    footprint_list.append(np.moveaxis(calcium_data, 0, -1).reshape((-1, calcium_data.shape[0])))\n",
    "    contour_list.append(contours)\n",
    "    countour_pics.append(contour_proj)\n",
    "\n",
    "    size_list.append(calcium_data.shape[1:])\n",
    "    template_list.append(max_proj)\n",
    "    max_proj_list.append((max_proj - max_proj.min())/ max_proj.max())\n",
    "    footprint_pics.append(footprint_proj)\n",
    "    binary_footprints.append(binary_footprint_proj)\n",
    "    centroids_list.append(np.array(centroids))\n",
    "\n",
    "    overlay_footprints.append(make_rgb_overlay(max_proj, footprint_proj, contour_proj, channel=channel))\n",
    "    overlay_binary_footprints.append(make_rgb_overlay(max_proj, binary_footprint_proj, contour_proj, channel=channel))\n",
    "\n",
    "# Filter footprints and contours based on the matching\n",
    "match_ca1 = calcium_list[0][assignments_filtered[:, match_cols[0]], :]\n",
    "match_ca2 = calcium_list[1][assignments_filtered[:, match_cols[1]], :]\n",
    "\n",
    "match_footprint_projs = [np.sum(match_ca1, axis=0),  np.sum(match_ca2, axis=0)]\n",
    "match_binary_footprint_projs = [get_binary_footprints(fp_proj) for fp_proj in match_footprint_projs]\n",
    "match_centroids = [np.array(get_footprint_centroids(match_ca1)), np.array(get_footprint_centroids(match_ca2))]\n",
    "\n",
    "match_contours1, _ = get_footprint_contours(match_ca1)\n",
    "match_contours2, _ = get_footprint_contours(match_ca2)\n",
    "match_contour_proj1 = make_contour_projection(match_contours1, match_ca1.shape)\n",
    "match_contour_proj2 = make_contour_projection(match_contours2, match_ca2.shape)\n",
    "match_binary_contour_projs = [match_contour_proj1, match_contour_proj2]\n",
    "match_contours = [match_contours1, match_contours2]\n",
    "\n",
    "match_overlay_binary_footprints = []\n",
    "for i, channel in enumerate(['b', 'r']):\n",
    "    match_overlay_binary_footprints.append(make_rgb_overlay(max_proj_list[i], match_binary_footprint_projs[i], match_binary_contour_projs[i], channel=channel))\n",
    "\n",
    "# Filter unmatched footprints and contours based on the matching\n",
    "unmatch_ca1 = calcium_list[0][unassigned[match_cols[0]], :]\n",
    "unmatch_ca2 = calcium_list[1][unassigned[match_cols[1]], :]\n",
    "\n",
    "unmatch_footprint_projs = [np.sum(unmatch_ca1, axis=0),  np.sum(unmatch_ca2, axis=0)]\n",
    "unmatch_binary_footprint_projs = [get_binary_footprints(fp_proj) for fp_proj in unmatch_footprint_projs]\n",
    "unmatch_centroids = [np.array(get_footprint_centroids(unmatch_ca1)), np.array(get_footprint_centroids(unmatch_ca2))]\n",
    "\n",
    "unmatch_contours1, _ = get_footprint_contours(unmatch_ca1)\n",
    "unmatch_contours2, _ = get_footprint_contours(unmatch_ca2)\n",
    "unmatch_contour_proj1 = make_contour_projection(unmatch_contours1, unmatch_ca1.shape)\n",
    "unmatch_contour_proj2 = make_contour_projection(unmatch_contours2, unmatch_ca2.shape)\n",
    "unmatch_binary_contour_projs = [unmatch_contour_proj1, unmatch_contour_proj2]\n",
    "unmatch_contours = [unmatch_contours1, unmatch_contours2]\n",
    "\n",
    "unmatch_overlay_binary_footprints = []\n",
    "for i, channel in enumerate(['b', 'r']):\n",
    "    unmatch_overlay_binary_footprints.append(make_rgb_overlay(max_proj_list[i], unmatch_binary_footprint_projs[i], unmatch_binary_contour_projs[i], channel=channel))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "all_cell_labels = [np.concatenate((centroids, np.arange(centroids.shape[0]).reshape(-1,1)), axis=1) for centroids in centroids_list]\n",
    "all_cells = hv_plot_FOVs(rigs, overlay_binary_footprints, countour_pics, overlay=True, labels=all_cell_labels)\n",
    "\n",
    "matched_cell_labels = [np.concatenate((match_centroids[i], assignments_filtered[:, i].reshape(-1,1)), axis=1) for i in np.arange(len(match_centroids))]\n",
    "match_cells = hv_plot_FOVs(rigs, match_overlay_binary_footprints, match_binary_contour_projs, \n",
    "                           overlay=True, labels=matched_cell_labels).opts(hv.opts.RGB(title=''))\n",
    "\n",
    "unmatched_cell_labels = [np.concatenate((unmatch_centroids[i], unassigned[i].reshape(-1,1)), axis=1) for i in np.arange(len(unmatch_centroids))]\n",
    "unmatch_cells = hv_plot_FOVs(rigs, unmatch_overlay_binary_footprints, unmatch_binary_contour_projs, \n",
    "                             overlay=True, labels=unmatched_cell_labels).opts(hv.opts.RGB(title=''))\n",
    "\n",
    "match_plot = hv.Layout(all_cells + match_cells + unmatch_cells).cols(3).opts(hv.opts.RGB(xlabel=None, ylabel=None, xaxis=None, yaxis=None, width=350, height=350), hv.opts.Labels(text_font_size='15pt'))\n",
    "\n",
    "match_plot\n",
    "# match_cells.opts(hv.opts.RGB(xlabel=None, ylabel=None, xaxis=None, yaxis=None), hv.opts.Labels(text_font_size='15pt'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prey_capture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
