{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-vitamin",
   "metadata": {},
   "source": [
    "# imports\n",
    "# suppress holoviews warning. Using warnings module didn't work\n",
    "import logging\n",
    "logging.getLogger(\"param.Dimension\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"param.ParameterizedMetaclass\").setLevel(logging.CRITICAL)\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(r'D:\\Code Repos\\prey_capture'))\n",
    "\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')\n",
    "from bokeh.resources import INLINE\n",
    "\n",
    "import paths\n",
    "import functions_bondjango as bd\n",
    "import functions_misc as fm\n",
    "import functions_plotting as fp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.mixture as mix\n",
    "import sklearn.decomposition as decomp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import svm, datasets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import random\n",
    "import functions_data_handling as fd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-career",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "# define the search string\n",
    "search_string = 'result:succ, lighting:normal, rig:miniscope, analysis_type:preprocessing, imaging:doric'\n",
    "# query the database for data to plot\n",
    "data_all = bd.query_database('analyzed_data', search_string)\n",
    "# data_path = data_all[0]['analysis_path']\n",
    "\n",
    "# load the data\n",
    "# allocate memory\n",
    "ca_data = []\n",
    "\n",
    "# for all the entries\n",
    "for entry in data_all:\n",
    "    ca_data.append(pd.read_hdf(entry['analysis_path'], 'matched_calcium'))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-confirmation",
   "metadata": {},
   "source": [
    "# define the number of bins\n",
    "bin_number = 5;\n",
    "\n",
    "images = []\n",
    "scores = []\n",
    "\n",
    "prediction = []\n",
    "\n",
    "# # get the mice for this dataset\n",
    "# mice = data.keys()\n",
    "\n",
    "# # # for all the mice\n",
    "# for mouse in mice:\n",
    "# # for mouse in ['dg_200701_a']:\n",
    "#     # get the dates for this mouse\n",
    "#     dates = data[mouse].keys()\n",
    "# #     # for all the dates\n",
    "#     for day in dates:\n",
    "# #     for day in ['2020_09_02']:\n",
    "#         print(str(mouse)+str(day))\n",
    "#         # get the table\n",
    "#         sub_data = data[mouse][day]\n",
    "\n",
    "# allocate a confusion matrix to average\n",
    "confusion_overall = np.zeros((bin_number, bin_number))\n",
    "\n",
    "# for all the files\n",
    "for idx, sub_data in enumerate(ca_data):\n",
    "    \n",
    "    # get the available columns\n",
    "    labels = list(sub_data.columns)\n",
    "    cells = [el for el in labels if 'cell' in el]\n",
    "    not_cells = [el for el in labels if 'cell' not in el]\n",
    "    # get the cell data\n",
    "    calcium_data = np.array(sub_data[cells].copy())\n",
    "#     # get rid of the super small values\n",
    "    calcium_data[np.isnan(calcium_data)] = 0\n",
    "    calcium_data[calcium_data<0] = 0\n",
    "    calcium_data[calcium_data==0] = 1\n",
    "    calcium_data = np.log(calcium_data)\n",
    "    print(calcium_data.shape)\n",
    "#         selection_vector = np.sum(np.isnan(calcium_data), axis=1)==0\n",
    "#         selection_vector = np.sum(calcium_data>np.std(calcium_data, axis=None)*3, axis=1)==0\n",
    "#         calcium_data = calcium_data[selection_vector, :]\n",
    "\n",
    "    if calcium_data.shape[0] == 0 or calcium_data.shape[1] == 0:\n",
    "        prediction.append([])\n",
    "        continue\n",
    "    # scale (convert to float to avoid warning, potentially from using too small a dtype)\n",
    "#         calcium_data = preprocessing.scale(calcium_data.astype(float), axis=0)\n",
    "    calcium_data = preprocessing.StandardScaler().fit_transform(calcium_data)\n",
    "\n",
    "#     print(calcium_data.shape)\n",
    "    # get the distance to cricket\n",
    "    distance = sub_data.cricket_0_mouse_distance\n",
    "#         print(sub_data.keys())\n",
    "#         distance = sub_data.cricket_0_delta_heading\n",
    "    # determine the speed bin edges\n",
    "#         bins = np.linspace(np.min(distance),np.max(distance),num=bin_number)\n",
    "    bins = np.percentile(distance,np.linspace(0, 100, bin_number+1))   \n",
    "    bins[-1] = np.ceil(bins[-1])\n",
    "    \n",
    "#     bins = [0, 300, 600, 800, 1000, 1200]\n",
    "    # bin the distance to cricket\n",
    "    label_vector = np.digitize(distance,bins)-1\n",
    "    \n",
    "    print(np.unique(label_vector))\n",
    "#         label_vector = label_vector[selection_vector]\n",
    "#     print([np.min(calcium_data.flatten()), np.max(calcium_data.flatten())])\n",
    "#         frequencies, edges = np.histogram(calcium_data.flatten(), 20)\n",
    "#         hv.Histogram((edges, frequencies))  \n",
    "#         print(label_vector.shape)\n",
    "    # shufle the label vector\n",
    "    random.shuffle(label_vector)\n",
    "\n",
    "    # train the classifier\n",
    "#         linear_pred = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo', random_state=0).fit(calcium_data,label_vector).predict(calcium_data)\n",
    "    linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovr', random_state=0, probability=False)\n",
    "#         linear.fit(calcium_data, label_vector)\n",
    "#         linear_pred_save = linear.predict_proba(calcium_data)\n",
    "#         linear_pred = linear.predict(calcium_data)\n",
    "\n",
    "    linear_pred_save = cross_val_predict(linear, calcium_data, label_vector, cv=5, verbose=3, \n",
    "                                    n_jobs=None, method='decision_function')\n",
    "#     print(linear_pred_save.shape)\n",
    "    \n",
    "#     if len(linear_pred.shape)==1:\n",
    "#         continue\n",
    "\n",
    "    linear_pred = np.argmax(linear_pred_save, axis=1)\n",
    "    confusion_linear = confusion_matrix(label_vector, linear_pred)\n",
    "    \n",
    "    if confusion_linear.shape[0] != bin_number:\n",
    "        prediction.append([])\n",
    "        continue\n",
    "    # calculate the accumulated one\n",
    "    confusion_overall += confusion_linear/len(ca_data)\n",
    "\n",
    "    # plot\n",
    "    delta_image = hv.Image(confusion_linear, bounds=[0, 0, confusion_linear.shape[1], confusion_linear.shape[0]])\n",
    "#         delta_image.opts(width=600, invert_axes=False, invert_yaxis=False, \n",
    "#                        invert_xaxis=False, cmap='Viridis', xticks=variable_names, yticks=mouse_data_names, \n",
    "#               xrotation=45, tools=['hover'], colorbar=True, shared_axes=False)\n",
    "    images.append(delta_image)\n",
    "    scores.append(np.sum(np.diag(confusion_linear))/np.sum(confusion_linear.flatten()))\n",
    "    prediction.append(linear_pred_save)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-temperature",
   "metadata": {},
   "source": [
    "# Plot scores\n",
    "frequencies, edges = np.histogram(scores, 20)\n",
    "hv.Histogram((edges, frequencies))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-surfing",
   "metadata": {},
   "source": [
    "# Plot the overall confusion matrix\n",
    "delta_image = hv.Image(confusion_overall, bounds=[0, 0, confusion_linear.shape[1], confusion_linear.shape[0]])\n",
    "delta_image"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-humanitarian",
   "metadata": {},
   "source": [
    "# Plot the classification over time\n",
    "\n",
    "# Plot classification over time with other variables\n",
    "print(len(ca_data))\n",
    "# allocate a dict for the holomap\n",
    "holo_dict = {}\n",
    "# select the behavioral variables to show\n",
    "target_behavior = ['cricket_0_mouse_distance', 'cricket_0_delta_heading', 'prediction']\n",
    "# define the plot offset\n",
    "offset = 0\n",
    "# # define the target mouse, date and trial\n",
    "# mouse = 'DG_200701_a'\n",
    "# day = '2020_08_06'\n",
    "# trial = 1\n",
    "\n",
    "# define the target trial\n",
    "target_trial = 503\n",
    "\n",
    "# # get the table\n",
    "# if isinstance(data, dict):\n",
    "#     sub_data = data[mouse][day]\n",
    "# else:\n",
    "#     sub_data = data\n",
    "sub_data = ca_data[target_trial]\n",
    "\n",
    "# get the available columns\n",
    "labels = list(sub_data.columns)\n",
    "cells = [el for el in labels if 'cell' in el]\n",
    "# calculate the average neuronal response\n",
    "# get a vector with the trial id\n",
    "\n",
    "sub_data = sub_data.loc[:, target_behavior + cells]\n",
    "# sub_data = sub_data.loc[5:, :]\n",
    "\n",
    "# separate the cells and non-cells\n",
    "behavior_data = sub_data[target_behavior]\n",
    "temp_prediction = prediction[target_trial]\n",
    "# behavior_data['prediction'] = temp_prediction\n",
    "temp_prediction = np.sort(temp_prediction, axis=1)\n",
    "behavior_data['prediction'] = temp_prediction[:, -1]/np.sum(temp_prediction[:, :-1], axis=1)\n",
    "# behavior_data['prediction'] = np.sum(temp_prediction, axis=1)\n",
    "\n",
    "sub_data = sub_data[cells]\n",
    "# get the column labels\n",
    "labels = sub_data.columns\n",
    "# get the number of rows\n",
    "x_axis = sub_data.shape[0]\n",
    "# get the array\n",
    "sub_array = sub_data.to_numpy().T\n",
    "sub_array = fm.normalize_matrix(sub_array, axis=1)\n",
    "\n",
    "# plot the behavioral variables\n",
    "traces = []\n",
    "# get the x axis values\n",
    "x = np.array(np.arange(x_axis))\n",
    "# get the labels of the behavioral variables\n",
    "behavior_labels = behavior_data.columns\n",
    "\n",
    "# # replace the delta head name for heading\n",
    "# behavior_labels = ['heading' if el=='cricket_0_delta_head' else el for el in behavior_labels]\n",
    "# behavior_labels = [el.replace('cricket_0_', 'cricket_') if 'cricket_0_' in el else el for el in behavior_labels]\n",
    "\n",
    "# define the ticks\n",
    "y_tick = [(idx-0.5, el.replace('_',' ')) for idx, el in enumerate(behavior_labels)]\n",
    "# for all the behavioral variables\n",
    "for idx, variable in enumerate(target_behavior):\n",
    "    \n",
    "#         # if it's the heading\n",
    "#     if variable == 'cricket_0_delta_head':\n",
    "#         # draw a line through the middle of the heading parameter\n",
    "#         trace2 = hv.Curve((x, 0.5+offset*(idx-1)), 'Time',variable)\n",
    "#         trace2.opts(width=fp.pix(15), height=fp.pix(6*0.2), xticks=0, xlabel='', yticks=0, ylabel='', \n",
    "#                toolbar=None, color='red', line_dash='dotted', line_width=7)\n",
    "        \n",
    "#         traces.append(trace2)\n",
    "    \n",
    "    y = behavior_data[variable].to_numpy()\n",
    "    if variable != 'cricket_0_delta_heading':\n",
    "        y = np.log(y)\n",
    "        y[np.isnan(y)] = 0\n",
    "        y[np.isinf(y)] = 0\n",
    "#     else:\n",
    "#         np.set_printoptions(precision=1, suppress=True)\n",
    "#         print(y)\n",
    "\n",
    "    y[np.isnan(y)] = 0\n",
    "    y = fm.normalize_matrix(y, axis=0)+offset*(idx-1)\n",
    "    \n",
    "    trace = hv.Curve((x, y), 'Time',variable)\n",
    "#     trace = hv.Curve((x, behavior_data[variable].to_numpy()+offset*(idx-1)), 'Time',variable)\n",
    "#     trace.opts(width=fp.pix(15), height=fp.pix(8*0.3), xticks=0, xlabel='', yticks=y_tick, ylabel='', \n",
    "#                toolbar=None, color='black', line_width=7)\n",
    "    trace.opts(width=800)\n",
    "#     if variable == 'mouse_speed':\n",
    "#         print(fm.normalize_matrix(np.log(behavior_data[variable].to_numpy()), axis=0))\n",
    "\n",
    "    # append\n",
    "    traces.append(trace)\n",
    "        \n",
    "# plot the cells\n",
    "raw_image = hv.Image(sub_array, ['Time (s)','Cells'], bounds=[0,-0.5,x_axis,0.5], fontstyle='regular')\n",
    "raw_image.opts(width=800)\n",
    "# raw_image.opts(width=fp.pix(15), height=fp.pix(8*0.7), colorbar=True, colorbar_opts={'major_label_text_align': 'left'},\n",
    "#                cmap='Viridis', yticks=[(-0.5, 1), (0.5, sub_array.shape[0])], toolbar=None,fontsize=fp.font_sizes['small'], \n",
    "#                hooks=[fp.margin])\n",
    "\n",
    "# create the overlay with the behavioral traces\n",
    "overlay = hv.Overlay(traces)\n",
    "# overlay.opts(text_font='Arial',fontsize=fp.font_sizes['small'])\n",
    "\n",
    "# create the final layout\n",
    "layout = hv.Layout(raw_image+overlay).cols(1)\n",
    "layout.opts(fontsize=fp.font_sizes['small'])\n",
    "\n",
    "# # assemble the save path\n",
    "# save_path = os.path.join(paths.figures_path,'_'.join((save_name,mouse,day,str(trial),'ethogram.png')))\n",
    "# hv.save(layout,save_path)\n",
    "\n",
    "layout\n",
    "# print(sub_array)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prey_capture] *",
   "language": "python",
   "name": "conda-env-.conda-prey_capture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
