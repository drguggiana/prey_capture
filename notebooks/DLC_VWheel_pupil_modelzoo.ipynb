{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677b6a3d",
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3rc3...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut as dlc\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# From paths.py\n",
    "import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3345f7c5",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Find all videos in the data directory with VTuning in the name\n",
    "all_videos = glob.glob(paths.vrexperiment_path + os.sep + \"*VWheel*.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af98c80",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "working_dir = r\"D:\\DLC_projects\"\n",
    "project_name = \"vwheel_pupil_modelzoo\"\n",
    "experimenter = \"matt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb58578",
   "metadata": {},
   "source": [
    "# If Project already created, run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b1da4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_path = glob.glob(os.path.join(working_dir, project_name) + \"*/config.yaml\")[0]\n",
    "cfg = dlc.auxiliaryfunctions.read_config(config_path)\n",
    "project_directory = cfg['project_path']\n",
    "project_video_list = [vid for vid in cfg[\"video_sets\"]]\n",
    "# test_vids = os.path.join(project_video_list, \"test-videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673ec4ac",
   "metadata": {},
   "source": [
    "# If you haven't created a new project, run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select videos to train on\n",
    "remote_video_list = []\n",
    "for i in range(2):\n",
    "    remote_video_list.append(random.choice(all_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01545c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_pretrained_project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d8dee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\"\n",
      "Created \"D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\labeled-data\"\n",
      "Created \"D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\training-datasets\"\n",
      "Created \"D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\dlc-models\"\n",
      "Copying the videos\n",
      "D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\02_24_2022_12_01_36_VWheel_MM_220117_a_fixed0.avi\n",
      "D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\11_11_2022_14_39_11_VWheelWF_MM_220915_a_fixed0_gabor.avi\n",
      "Generated \"D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\config.yaml\"\n",
      "\n",
      "A new project with name vwheel_pupil_modelzoo-matt-2022-11-25 is created at D:\\DLC_projects and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Downloading weights...\n",
      "Loading.... mouse_pupil_vclose\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201e01027179496daf807cc583a01149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/178M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\dlc-models\\iteration-0\\vwheel_pupil_modelzooNov25-trainset95shuffle1\\train\\pose_cfg.yaml\n"
     ]
    }
   ],
   "source": [
    "config_path, train_config_path = dlc.create_pretrained_project(\n",
    "    project_name,\n",
    "    experimenter,\n",
    "    remote_video_list,\n",
    "    model=\"mouse_pupil_vclose\",\n",
    "    working_directory=working_dir,\n",
    "    analyzevideo=False,\n",
    "    createlabeledvideo=False,\n",
    "    copy_videos=True, #must leave copy_videos=True\n",
    ")\n",
    "\n",
    "config_path = glob.glob(os.path.join(working_dir, project_name) + \"*/config.yaml\")[0]\n",
    "cfg = dlc.auxiliaryfunctions.read_config(config_path)\n",
    "project_directory = cfg['project_path']\n",
    "project_video_list = [vid for vid in cfg[\"video_sets\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a61a9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ordereddict([('Task', 'vwheel_pupil_modelzoo'), ('scorer', 'matt'), ('date', 'Nov25'), ('multianimalproject', False), ('identity', None), ('project_path', 'D:\\\\DLC_projects\\\\vwheel_pupil_modelzoo-matt-2022-11-25'), ('video_sets', ordereddict([('D:\\\\DLC_projects\\\\vwheel_pupil_modelzoo-matt-2022-11-25\\\\videos\\\\11_11_2022_14_39_11_VWheelWF_MM_220915_a_fixed0_gabor.avi', ordereddict([('crop', '0, 1280, 0, 1024')]))])), ('bodyparts', ['Lpupil', 'LDpupil', 'Dpupil', 'DRpupil', 'Rpupil', 'RVupil', 'Vpupil', 'VLpupil', 'LED']), ('start', 0), ('stop', 1), ('numframes2pick', 20), ('skeleton', [['Lpupil', 'LDpupil', 'Dpupil', 'DRpupil', 'Rpupil', 'RVupil', 'Vpupil', 'VLpupil'], ['LED']]), ('skeleton_color', 'blackwhite'), ('pcutoff', 0.85), ('dotsize', 3), ('alphavalue', 0.7), ('colormap', 'jet'), ('TrainingFraction', [0.95]), ('iteration', 0), ('default_net_type', 'resnet_50'), ('default_augmenter', 'imgaug'), ('snapshotindex', -1), ('batch_size', 8), ('cropping', False), ('x1', 0), ('x2', 640), ('y1', 277), ('y2', 624), ('corner2move2', [50, 50]), ('move2corner', True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update some config paramters\n",
    "# Updating the plotting within the config.yaml file (without opening it ;):\n",
    "edits = {\n",
    "    'dotsize': 3,  # size of the dots!\n",
    "    'colormap': 'jet',  # any matplotlib colormap!\n",
    "    'pcutoff': 0.85,  # the higher the more conservative the plotting!\n",
    "}\n",
    "dlc.auxiliaryfunctions.edit_config(config_path, edits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf2717",
   "metadata": {},
   "source": [
    "# Extract and label frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.extract_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbcd3217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1327.16  seconds.\n",
      "Extracting and downsampling... 33179  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33179it [05:03, 109.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "# extract frames from the videos\n",
    "# will go through all of the videos on the list, so if many videos, it might take a while\n",
    "dlc.extract_frames(config_path, mode='automatic', algo='kmeans', crop=False, userfeedback=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.label_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d95110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QStatusBar::insertPermanentWidget: Index out of range (0), appending widget\n"
     ]
    }
   ],
   "source": [
    "# label frames\n",
    "# generates folders in the labeled-data folder with the video name\n",
    "dlc.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c142a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.check_labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6a836df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by matt.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# check the labels\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# generates folders in the labeled-data folder with the video name but the actual labels printed on the pics\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdlc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw_skeleton\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualizeindividuals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m;\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\trainingsetmanipulation.py:349\u001b[0m, in \u001b[0;36mcheck_labels\u001b[1;34m(config, Labels, scale, dpi, draw_skeleton, visualizeindividuals)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m     DataCombined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_hdf(\n\u001b[0;32m    347\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(folder), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollectedData_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscorer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    348\u001b[0m     )\n\u001b[1;32m--> 349\u001b[0m     \u001b[43mconversioncode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguarantee_multiindex_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataCombined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultianimalproject\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    351\u001b[0m         color_by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindividual\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualizeindividuals \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbodypart\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\utils\\conversioncode.py:247\u001b[0m, in \u001b[0;36mguarantee_multiindex_rows\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Ensure folder names are strings\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 247\u001b[0m     df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mset_levels(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m), level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\core\\indexes\\frozen.py:73\u001b[0m, in \u001b[0;36mFrozenList.__getitem__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(n))\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# check the labels\n",
    "# generates folders in the labeled-data folder with the video name but the actual labels printed on the pics\n",
    "dlc.check_labels(config_path, draw_skeleton=False, visualizeindividuals=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c698a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_training_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72d1d032",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create the training set\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# also creates the Pose.yaml in the dlc-models/train dataset, which contains the setting for training, i.e. take a look\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdlc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_training_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmenter_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimgaug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\trainingsetmanipulation.py:857\u001b[0m, in \u001b[0;36mcreate_training_dataset\u001b[1;34m(config, num_shuffles, Shuffles, windows2linux, userfeedback, trainIndices, testIndices, net_type, augmenter_type, posecfg_template)\u001b[0m\n\u001b[0;32m    850\u001b[0m trainingsetfolder \u001b[38;5;241m=\u001b[39m auxiliaryfunctions\u001b[38;5;241m.\u001b[39mget_training_set_folder(\n\u001b[0;32m    851\u001b[0m     cfg\n\u001b[0;32m    852\u001b[0m )  \u001b[38;5;66;03m# Path concatenation OS platform independent\u001b[39;00m\n\u001b[0;32m    853\u001b[0m auxiliaryfunctions\u001b[38;5;241m.\u001b[39mattempttomakefolder(\n\u001b[0;32m    854\u001b[0m     Path(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(project_path, \u001b[38;5;28mstr\u001b[39m(trainingsetfolder))), recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    855\u001b[0m )\n\u001b[1;32m--> 857\u001b[0m Data \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_annotateddatasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainingsetfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\trainingsetmanipulation.py:479\u001b[0m, in \u001b[0;36mmerge_annotateddatasets\u001b[1;34m(cfg, trainingsetfolder_full)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_hdf(file_path)\n\u001b[1;32m--> 479\u001b[0m     \u001b[43mconversioncode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguarantee_multiindex_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m     AnnotationData\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\utils\\conversioncode.py:247\u001b[0m, in \u001b[0;36mguarantee_multiindex_rows\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Ensure folder names are strings\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 247\u001b[0m     df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mset_levels(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m), level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\core\\indexes\\frozen.py:73\u001b[0m, in \u001b[0;36mFrozenList.__getitem__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(n))\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# create the training set\n",
    "# also creates the Pose.yaml in the dlc-models/train dataset, which contains the setting for training, i.e. take a look\n",
    "dlc.create_training_dataset(config_path, augmenter_type='imgaug');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ad5a2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training datafile  D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\dlc-models\\iteration-1\\vwheel_pupil_modelzooNov25-trainset95shuffle1\\train\\pose_cfg.yaml  is not present.\n",
      "Probably, the training dataset for this specific shuffle index was not created.\n",
      "Try with a different shuffle/trainingsetfraction or use function 'create_training_dataset' to create a new trainingdataset with this shuffle index.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Config D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\dlc-models\\iteration-1\\vwheel_pupil_modelzooNov25-trainset95shuffle1\\train\\pose_cfg.yaml is not found. Please make sure that the file exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# train the network\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdlc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgputouse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_snapshots_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplayiters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaveiters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50e3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py:221\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    210\u001b[0m         train(\n\u001b[0;32m    211\u001b[0m             \u001b[38;5;28mstr\u001b[39m(poseconfigfile),\n\u001b[0;32m    212\u001b[0m             displayiters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m             allow_growth\u001b[38;5;241m=\u001b[39mallow_growth,\n\u001b[0;32m    218\u001b[0m         )  \u001b[38;5;66;03m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;28mstr\u001b[39m(start_path))\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py:190\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    188\u001b[0m         os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(gputouse)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     cfg_dlc \u001b[38;5;241m=\u001b[39m \u001b[43mauxiliaryfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_plainconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposeconfigfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti-animal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cfg_dlc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose_estimation_tensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_multianimal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    193\u001b[0m             train,\n\u001b[0;32m    194\u001b[0m         )\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\utils\\auxiliaryfunctions.py:281\u001b[0m, in \u001b[0;36mread_plainconfig\u001b[1;34m(configname)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_plainconfig\u001b[39m(configname):\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(configname):\n\u001b[1;32m--> 281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    282\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfigname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not found. Please make sure that the file exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         )\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(configname) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m YAML()\u001b[38;5;241m.\u001b[39mload(file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Config D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\dlc-models\\iteration-1\\vwheel_pupil_modelzooNov25-trainset95shuffle1\\train\\pose_cfg.yaml is not found. Please make sure that the file exists."
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "dlc.train_network(config_path, gputouse=0, allow_growth=True,\n",
    "                  max_snapshots_to_keep=10, displayiters=5e3, saveiters=50e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e98935f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "dlc.evaluate_network(config_path, Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.analyze_videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf67e573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-650000 for model D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\dlc-models\\iteration-0\\vwheel_pupil_modelzooNov25-trainset95shuffle1\n",
      "Starting analysis in dynamic cropping mode with parameters: (True, 0.1, 50)\n",
      "Switching batchsize to 1, num_outputs (per animal) to 1 and TFGPUinference to False (all these features are not supported in this mode).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\test-short.mp4\n",
      "Loading  D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\test-short.mp4\n",
      "Duration of video [s]:  28.4 , recorded with  25.0 fps!\n",
      "Overall # of frames:  710  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 710/710 [04:22<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_vwheel_pupil_modelzooNov25shuffle1_650000'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.analyze_videos(config_path, [r\"D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\test-short.mp4\"], dynamic=(True, .1, 50), gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00899eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_labeled_video(config_path, [r\"D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\test-short.mp4\"], fastmode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af8cd496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccann\\Miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  jump  found  709  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "yes/noy\n",
      "Frames from video test-short  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  28.4 , recorded @  25.0 fps!\n",
      "Overall # of frames:  710 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 28.4  seconds.\n",
      "Extracting and downsampling... 709  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "709it [00:06, 109.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [358, 357, 466, 22, 153]\n",
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\test-short.mp4 moved to D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\test-short.mp4\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\test-short.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "# extract outlier frames\n",
    "# dlc.extract_outlier_frames(config_path, project_video_list, outlieralgorithm='uncertain', p_bound=0.6)\n",
    "dlc.extract_outlier_frames(config_path, [r\"D:\\DLC_projects\\vwheel_pupil_modelzoo-matt-2022-11-25\\videos\\test-short.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb6a17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QStatusBar::insertPermanentWidget: Index out of range (0), appending widget\n",
      "WARNING:vispy:QStatusBar::insertPermanentWidget: Index out of range (0), appending widget\n"
     ]
    }
   ],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "336f6274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 1.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "# Merge the dataset, then move to check labels and retrain\n",
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555e39a",
   "metadata": {},
   "source": [
    "# Add extra videos (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If adding new videos, do that here by randomly selecting some not in the original data set or the test set\n",
    "# For this particular case, we want videos that are older than March 4th 2022\n",
    "from datetime import datetime\n",
    "from os.path import sep\n",
    "valid_extras = [vid for vid in all_videos if datetime.strptime(vid.split(sep)[-1].split('_VWheel')[0], \"%m_%d_%Y_%H_%M_%S\") > datetime(2022, 3, 5)]\n",
    "\n",
    "extra_vids = []\n",
    "while(len(extra_vids) < 5):\n",
    "    vid = random.choice(valid_extras)\n",
    "    if vid not in project_video_list or test_vids:\n",
    "        extra_vids.append(vid)\n",
    "        \n",
    "dlc.add_new_videos(config_path, extra_vids, copy_videos=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
